{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2¶\n",
    "In this module, we will investigate the original raw data for the problems discussed in week 1. The ultimate goal, which will take multiple weeks to accomplish, is to build a comprehensive data analysis “dashboard” for this data set. This module is part of the process toward this goal.\n",
    "\n",
    "The main task in this module is to clean up the raw data and transform it into the form that you saw in week 1. The input is the raw data (download link below). The output should be the same as, or similar to, the HDF5 data file given in Week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Step 1-1\n",
    "Download the raw data file (text file, approximately 1.7GB):\n",
    "\n",
    "data file from https://drive.google.com/open?id=1V16kUXbWoPlK1GzVuftzyic11ntqhU7g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1-2\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to print/output all columns in dataframes\n",
    "- Setting lasts for life of kernel or until set again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Read the raw data file into Python.\n",
    "\n",
    "This data file has about 4.5 million rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data file has 45 columns. The column definitions, in the order of their appearance per row in the data file, are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['qname', 'hostname', 'group', 'owner', 'job_name',\n",
    "          'job_number', 'account', 'priority', 'submission_time', 'start_time',\n",
    "          'end_time', 'failed', 'exit_status', 'ru_wallclock', 'ru_utime',\n",
    "          'ru_stime', 'ru_maxrss', 'ru_ixrss', 'ru_ismrss', 'ru_idrss',\n",
    "          'ru_isrss', 'ru_minflt', 'ru_majflt', 'ru_nswap', 'ru_inblock',\n",
    "          'ru_oublock', 'ru_msgsnd', 'ru_msgrcv', 'ru_nsignals', 'ru_nvcsw',\n",
    "          'ru_nivcsw', 'project', 'department', 'granted_pe', 'slots',\n",
    "          'task_number', 'cpu', 'mem', 'io', 'category', 'iow', 'pe_taskid', \n",
    "          'maxvmem', 'arid', 'ar_submission_time' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "We will keep only the following columns, discarding the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usecols = ['owner', 'group', 'job_number', 'task_number', 'granted_pe',\n",
    "           'slots' ,'category', 'submission_time', 'start_time', 'end_time',\n",
    "           'failed', 'exit_status', 'maxvmem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monitoring variable and file size**\n",
    "\n",
    "Let's monitor local variables and the `.ipynb` file as we go thru this program. Earlier the file ballooned to over 100 MB causing my system to freeze and requiring multiple restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_variable_sizes(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254\n",
    "    \n",
    "    This function returns size of variables in memory.'''\n",
    "    \n",
    "    for unit in ['','K','M','G','T','P','E','Z']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def check_variable_sizes(locals_items, num=3):\n",
    "    for name,size in sorted(((name, sys.getsizeof(value)) for name,value in locals_items),\n",
    "                             key= lambda x: -x[1])[:num]:\n",
    "        print(\"{:>10}: {:>8}\".format(name, display_variable_sizes(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        _i:   705.0B\n",
      "       _i5:   705.0B\n",
      "      _iii:   688.0B\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 54 KB\n",
    "\n",
    "check_variable_sizes(locals().items()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingest_data(datafile):\n",
    "    \"\"\"Function takes one argument, `datafile`, a colon-delimited TXT file. \n",
    "    Function reads file using `read_csv` method and returns a dataframe of a \n",
    "    subset of the data as defined by `skiprows`, `nrows`, `names`, and `usecols`.\"\"\"\n",
    "\n",
    "    # the data is in a TXT file, but we can use the read_csv method with these args\n",
    "    return pd.read_csv(datafile,\n",
    "#                         skiprows=300000,         # skip first skiprows rows\n",
    "#                         nrows=500000,             # read in nrows rows starting from row skiprows \n",
    "                        sep=':',                 # fields separated by colon, not comma\n",
    "                        error_bad_lines=False,   # drop bad lines, keep reading\n",
    "                        header=None,             # I DON'T UNDERSTAND DOCUMENTATION\n",
    "                        names=fields,            # file has no header row; use these header names\n",
    "                        usecols=usecols,         # return only these cols; subset of names=fields\n",
    "                        encoding = \"ISO-8859-1\") # special character handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is there a pandas method to **randomly sample** the subset of observations selected by `read_csv`, so that they are selected from across the rows instead of all in one contiguous \"chunk\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ingest data from original txt file\n",
    "df = ingest_data('accounting-2018-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Step 11 testing\n",
    "# print(df[df.job_number == 4008055])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Step 11 testing:\n",
    "# df[(df.job_number == 3929734)  # (df.submission_time == '2018-10-02 17:03:11') & \n",
    "#      & (df.task_number == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Step 11 testing: find rows where category string contains substring\n",
    "# print(len(df[df['category'].str.contains(\"INFINITY\")]))  # 118728\n",
    "# df[df['category'].str.contains(\"INFINITY\")].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Step 11 testing\n",
    "\n",
    "# print(df[df.job_number == 3931237])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Step 4.2 testing\n",
    "# df[103616:103616+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        df:    1.7GB\n",
      "       _i7:    1.1KB\n",
      "       _i5:   705.0B\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 54 KB\n",
    "\n",
    "check_variable_sizes(locals().items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  \n",
       "0  4.040196e+09  \n",
       "1  6.098657e+08  \n",
       "2  3.326935e+09  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[df == -200].info()  # a way to get info to display '# non-null' in output; e.g.,\n",
    "#                        # df[df == -200] means XXX ??? (-200 values are null ???)\n",
    "#                        # group              0 non-null object\n",
    "#                        # none of my values are -200, so why is \"non-null\" zero ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Memory usage of 454.3+ MB is an ESTIMATE\n",
    "- By default, this follows the pandas.options.display.memory_usage setting.\n",
    "- Without deep introspection a memory estimation is made based on column dtype and number of rows assuming values consume the same memory amount for corresponding dtypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4580087 entries, 0 to 4580086\n",
      "Data columns (total 13 columns):\n",
      "group              4580087 non-null object\n",
      "owner              4580087 non-null object\n",
      "job_number         4580087 non-null int64\n",
      "submission_time    4580087 non-null int64\n",
      "start_time         4580087 non-null int64\n",
      "end_time           4580087 non-null int64\n",
      "failed             4580087 non-null int64\n",
      "exit_status        4580087 non-null int64\n",
      "granted_pe         4580087 non-null object\n",
      "slots              4580087 non-null int64\n",
      "task_number        4580087 non-null int64\n",
      "category           4580087 non-null object\n",
      "maxvmem            4580087 non-null float64\n",
      "dtypes: float64(1), int64(8), object(4)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep', null_counts=True)  # better way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- memory usage: 1.7 GB\n",
    "- With deep memory introspection, a real memory usage calculation is performed.\n",
    "- In this case the difference between the estimated memory usage and actual is ~ a factor of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4580087, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # (4580087, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group', 'owner', 'job_number', 'submission_time', 'start_time',\n",
       "       'end_time', 'failed', 'exit_status', 'granted_pe', 'slots',\n",
       "       'task_number', 'category', 'maxvmem'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "      <td>4.580087e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.014025e+06</td>\n",
       "      <td>1.539600e+09</td>\n",
       "      <td>1.535827e+09</td>\n",
       "      <td>1.535829e+09</td>\n",
       "      <td>2.348318e+00</td>\n",
       "      <td>7.109810e-01</td>\n",
       "      <td>2.678198e+00</td>\n",
       "      <td>3.045713e+04</td>\n",
       "      <td>1.784141e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.368585e+04</td>\n",
       "      <td>9.706471e+06</td>\n",
       "      <td>7.719903e+07</td>\n",
       "      <td>7.719913e+07</td>\n",
       "      <td>1.493111e+01</td>\n",
       "      <td>9.839768e+00</td>\n",
       "      <td>1.075185e+01</td>\n",
       "      <td>6.790150e+04</td>\n",
       "      <td>5.443269e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.302070e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.972381e+06</td>\n",
       "      <td>1.539068e+09</td>\n",
       "      <td>1.539126e+09</td>\n",
       "      <td>1.539127e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.590000e+02</td>\n",
       "      <td>3.609313e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.021101e+06</td>\n",
       "      <td>1.539850e+09</td>\n",
       "      <td>1.539863e+09</td>\n",
       "      <td>1.539864e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.071700e+04</td>\n",
       "      <td>4.769833e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.052699e+06</td>\n",
       "      <td>1.540106e+09</td>\n",
       "      <td>1.540132e+09</td>\n",
       "      <td>1.540132e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.556200e+04</td>\n",
       "      <td>1.350545e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.115951e+06</td>\n",
       "      <td>1.541059e+09</td>\n",
       "      <td>1.541059e+09</td>\n",
       "      <td>1.541059e+09</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>4.320000e+02</td>\n",
       "      <td>1.995001e+06</td>\n",
       "      <td>9.651603e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job_number  submission_time    start_time      end_time  \\\n",
       "count  4.580087e+06  4.580087e+06     4.580087e+06  4.580087e+06   \n",
       "mean   4.014025e+06  1.539600e+09     1.535827e+09  1.535829e+09   \n",
       "std    5.368585e+04  9.706471e+06     7.719903e+07  7.719913e+07   \n",
       "min    1.302070e+05  0.000000e+00     0.000000e+00  0.000000e+00   \n",
       "25%    3.972381e+06  1.539068e+09     1.539126e+09  1.539127e+09   \n",
       "50%    4.021101e+06  1.539850e+09     1.539863e+09  1.539864e+09   \n",
       "75%    4.052699e+06  1.540106e+09     1.540132e+09  1.540132e+09   \n",
       "max    4.115951e+06  1.541059e+09     1.541059e+09  1.541059e+09   \n",
       "\n",
       "             failed   exit_status         slots   task_number       maxvmem  \n",
       "count  4.580087e+06  4.580087e+06  4.580087e+06  4.580087e+06  4.580087e+06  \n",
       "mean   2.348318e+00  7.109810e-01  2.678198e+00  3.045713e+04  1.784141e+09  \n",
       "std    1.493111e+01  9.839768e+00  1.075185e+01  6.790150e+04  5.443269e+09  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  1.000000e+00  3.590000e+02  3.609313e+08  \n",
       "50%    0.000000e+00  0.000000e+00  1.000000e+00  1.071700e+04  4.769833e+08  \n",
       "75%    0.000000e+00  0.000000e+00  1.000000e+00  4.556200e+04  1.350545e+09  \n",
       "max    1.000000e+02  2.550000e+02  4.320000e+02  1.995001e+06  9.651603e+11  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()  # shows only cols with a numeric data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary Findings (on 1% of the data)**:\n",
    "- Both `start_time` and `end_time` have some \"0\" values (01-01-1970 00:00:00)\n",
    "- But most other time values are within recent months\n",
    " - Current Unix Epoch Time is 1548050786 per https://www.epochconverter.com, and 1st quartile and max in data set are between 1538483000 and 1538500000 (11-02-2018 between 12:23:20 and 17:06:40)\n",
    "- `failed` seems to be either 0 or 100\n",
    "- `exit_status` seems to be either 0 or 255\n",
    "- `slots` shows 0, 1, and 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group              object \n",
       "owner              object \n",
       "job_number         int64  \n",
       "submission_time    int64  \n",
       "start_time         int64  \n",
       "end_time           int64  \n",
       "failed             int64  \n",
       "exit_status        int64  \n",
       "granted_pe         object \n",
       "slots              int64  \n",
       "task_number        int64  \n",
       "category           object \n",
       "maxvmem            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unique values\n",
    "\n",
    "# REWRITTEN BELOW\n",
    "\n",
    "groups =        df['group'].unique()\n",
    "users =         df['owner'].unique()\n",
    "job_numbers =   df['job_number'].unique()\n",
    "task_numbers =  df['task_number'].unique()\n",
    "start_times =   df['start_time'].unique()\n",
    "end_times =     df['end_time'].unique()\n",
    "faileds =       df['failed'].unique()\n",
    "exit_statuses = df['exit_status'].unique()\n",
    "granted_pes =   df['granted_pe'].unique()\n",
    "slots =         df['slots'].unique()\n",
    "categories =    df['category'].unique()\n",
    "        \n",
    "print(\"FEATURE SET         # UNIQ VALUES IN\", df.shape[0], \"ROWS\", \n",
    "      \"\\ngroups:            \", len(groups), \n",
    "      \"\\nusers:             \", len(users),\n",
    "      \"\\njob_numbers:       \", len(job_numbers),\n",
    "      \"\\ntask_numbers:      \", len(task_numbers),\n",
    "      \"\\nstart_times:       \", len(start_times),\n",
    "      \"\\nend_times:         \", len(end_times),\n",
    "      \"\\nfaileds:           \", len(faileds),\n",
    "      \"\\nexit_statuses:     \", len(exit_statuses),\n",
    "      \"\\ngranted_pes:       \", len(granted_pes),\n",
    "      \"\\nslots:             \", len(slots),\n",
    "      \"\\ncategories:        \", len(categories)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Many task numbers are repeated. Is this allowed or are these duplicates?\n",
    "- There are 3 times as many end times as start times. Can a job or task end more than once?!\n",
    "- Which is measured by start/end: jobs or tasks? \n",
    "- There are 3 times as many start times as there are jobs, but 6 times as many tasks as start times.\n",
    "- There are 2 times as many tasks as end times. This is plausible, since tasks in my sample (or in the entire data set) could have started and not ended.\n",
    "- It's true that a start time does not necessarily uniquely identify a job or task. But it often would, so the disparity in the figures is curious.\n",
    "\n",
    "**Next**: So what are the different values for slot, granted_pe, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\"failed\" (', len(faileds), '):  ', sorted(faileds), sep='', end='\\n\\n')\n",
    "print('\"exit_status\" (', len(exit_statuses), '):  ', sorted(exit_statuses), sep='', end='\\n\\n')\n",
    "print('\"granted_pe\" (', len(granted_pes), '):  ', sorted(granted_pes), sep='', end='\\n\\n')\n",
    "print('\"slot\" (', len(slots), '):  ', sorted(slots), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('EXAMPLES OF CATEGORY VALUES\\n\\n', categories[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore further**\n",
    "\n",
    "**Jobs by user**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_jobs_by_user():\n",
    "    df_jobs_by_user = df.drop_duplicates(subset=['owner', 'job_number'], keep='first')\n",
    "    df_jobs_by_user = df_jobs_by_user.copy()\n",
    "    df_jobs_by_user = df_jobs_by_user.groupby(['owner'])['owner'].size() \n",
    "    df_jobs_by_user = pd.DataFrame(df_jobs_by_user)  # convert back to a Dataframe\n",
    "    print('Number of users with unique jobs:', len(df_jobs_by_user))\n",
    "    return df_jobs_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_jobs_by_user = count_unique_jobs_by_user()\n",
    "unique_jobs_by_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jobs by group**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_jobs_by_group():\n",
    "    df_jobs_by_group = df.drop_duplicates(subset=['group', 'job_number'], keep='first')  # drop dupes\n",
    "    df_jobs_by_group = df_jobs_by_group.copy()  # copy to avoid assigning to a slice\n",
    "    df_jobs_by_group = df_jobs_by_group.groupby(['group'])['group'].size()  # Converts df to a series\n",
    "    df_jobs_by_group = pd.DataFrame(df_jobs_by_group)  # convert back to a Dataframe\n",
    "    print('Number of groups with unique jobs:', len(df_jobs_by_group))\n",
    "    return df_jobs_by_group\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_jobs_by_group = count_unique_jobs_by_group()\n",
    "unique_jobs_by_group.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each group, list the number of users, and list each groups' users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_every_groups_users():\n",
    "\n",
    "    # define LIST to hold (group,user) TUPLES, e.g., [(g1,u1),(g1,u49),(g2,u33),...]\n",
    "    group_users = []\n",
    "\n",
    "    # remove unneeded cols in df\n",
    "    df2 = df[['group', 'owner']]\n",
    "\n",
    "    # create LIST of all **unique** group-user TUPLES (weed out duplicates)\n",
    "    for index, row in df2.iterrows():\n",
    "        # check that tuple doesn't already exist in the list\n",
    "        if not (row['group'], row['owner']) in group_users:  \n",
    "            group_users.append((row['group'], row['owner']))\n",
    "\n",
    "    del df2, index, row\n",
    "\n",
    "    # create dict where k:v is group#:[all_users], e.g.:\n",
    "    # {'g1': ['u1', 'u145'], 'g2': ['u2', 'u77', 'u154', 'u187', 'u210', 'u274', \n",
    "    # 'u276', 'u285', 'u367', 'u420', 'u468'], 'g3': ['u3',...}\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for t in group_users:  # t = group-user tuple, e.g., (1, 3)\n",
    "        if not t[0] in d.keys():       # key is NOT in dict ...\n",
    "            d.update({t[0]: []})           # (empty list 1st bc otherwise lists chars of str)\n",
    "            d[t[0]].append(str(t[1]))  # ... so add it with value.\n",
    "        elif not t[1] in d[t[0]]:      # key IS in dict but t[1] is not in value list ...\n",
    "            d[t[0]].append(str(t[1]))  # ... so append it to value list.\n",
    "\n",
    "    del t, group_users\n",
    "\n",
    "    # Print\n",
    "    # sample output: group 1 (4 users): user2, user32, user41, user56\n",
    "    \n",
    "    group_users = []\n",
    "\n",
    "    for k,v in d.items():        \n",
    "        if len(v) == 1:  # singular \"user\"\n",
    "#             print('group ', k[1:], ' (', len(v), ' user): ', ', '.join(v), sep = '')\n",
    "            group_users.append('group ' \n",
    "                               + k[0:] \n",
    "                               + ' ('\n",
    "                               + str(len(v)) \n",
    "                               + ' user): ' \n",
    "                               + ', '.join(v))\n",
    "        else:            # plural \"users\"\n",
    "#             print('group ', k[1:], ' (', len(v), ' users): ', ', '.join(v), sep = '')\n",
    "            group_users.append('group ' \n",
    "                               + k[0:] \n",
    "                               + ' ('\n",
    "                               + str(len(v)) \n",
    "                               + ' users): ' \n",
    "                               + ', '.join(v))\n",
    "            \n",
    "    del k,v,d\n",
    "\n",
    "    # group eskin (10 users): joelmeff, phung428, jiangyua, ruthjohn, sungoohw, skwon94, sarahjs3, rebwalke, cmarsden, zhanly81\n",
    "    # group duquant (1 user): shuang92\n",
    "    # group asaniuc (1 user): kangchen \n",
    "    # ...\n",
    "    \n",
    "#     return print('\\nLOCAL VARIABLES\\n\\n', locals())  # TESTING: view variables\n",
    "    \n",
    "    # print variable names without values\n",
    "    print('\\nLOCAL VARIABLES:\\n\\n', \n",
    "          [name for name, val in locals().items()], \n",
    "          '\\n')  \n",
    "    \n",
    "    return group_users\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_by_group = list_every_groups_users()\n",
    "print('ROWS OF USERS BY GROUP (PARTIAL):\\n')\n",
    "for i in users_by_group[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the CPU-hours, defined as `(h\\_rt)\\*(slots)`, used by each group by generating a diagram similar to the following.**\n",
    "- Sort the results in decreasing order. Your plot should look like the following in which the labels of the vertical axis are the names of the groups and the labels of the horizontal axis are the CPU-hour values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Won't be able to do this until I break out the combined features in \"category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete 5 vars\n",
    "del end_times,start_times,job_numbers,task_numbers,categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This info will be useful in later analysis (Step 11).\n",
    "\n",
    "indexes_to_maybe_drop = []\n",
    "df_droplog = pd.DataFrame()\n",
    "\n",
    "def record_df_droplog(indexes_to_drop):\n",
    "    \"\"\"This function updates df_droplog with rows as they are dropped from df.\"\"\"\n",
    "    \n",
    "    print(\"Milestone 7, record_df_droplog, index ?\")\n",
    "    \n",
    "#     mask = df.duplicated(subset=['owner', 'job_number'], keep='first')\n",
    "#     df_droplog = df_droplog.append(df.loc[mask])  # record drops **before** dropping rows\n",
    "\n",
    "#     for i in indexes_to_maybe_drop:\n",
    "#         df_droplog = df_droplog.append(df.loc[i])  # want to add entire row to df_droplog\n",
    "\n",
    "    if not 'df_droplog' in locals():\n",
    "        df_droplog = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        print(\"TEST record_df_droplog LINE 22:\", len(df_droplog), df_droplog)\n",
    "        df_droplog = df_droplog.append(df.loc[indexes_to_drop])\n",
    "        print(\"TEST record_df_droplog  LINE 22:\", len(df_droplog), df_droplog)\n",
    "    except KeyError:\n",
    "        print(\"'None of index number passed to this function are in the [index]'.\")\n",
    "        print(\"This may mean that you already ran the cell/function to drop rows \\\n",
    "              and they have already been dropped.\")\n",
    "    \n",
    "    print(\"Milestone 8, record_df_droplog finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def should_we_drop_bad_values(indexes_to_maybe_drop):\n",
    "    \"\"\"This function queries the user to determine whether to drop rows that\n",
    "    have been flagged as possibly bad data.\"\"\"\n",
    "    \n",
    "    print(\"Milestone 4a, should_we_drop_bad_values, index ?\")\n",
    "    \n",
    "    if ('indexes_to_maybe_drop' in locals() \n",
    "        and len(indexes_to_maybe_drop) > 0):\n",
    "        print(\"Milestone 4b if, should_we_drop_bad_values, index ?\")\n",
    "        # convert indexes_to_maybe_drop list of tuples to a string\n",
    "        indexes_to_drop = ''\n",
    "        for i in range(len(indexes_to_maybe_drop)):\n",
    "            # index still in (index, string) tuple format\n",
    "            try:\n",
    "                indexes_to_drop += (str(indexes_to_maybe_drop[i][0]) + ', ' \n",
    "                                    + str(indexes_to_maybe_drop[i][1]) + '\\n')\n",
    "            # index in index only format\n",
    "            except TypeError: # 'int' object is not subscriptable\n",
    "                indexes_to_drop += (str(indexes_to_maybe_drop[i]) + ', ?\\n')\n",
    "\n",
    "#         response = input(\"PROBLEMATIC VALUES:\\n\\n\" \n",
    "#                          + indexes_to_drop\n",
    "#                          + \"Should these rows be dropped from the dataframe? y/n\")\n",
    "        response = 'y'\n",
    "        return response\n",
    "    \n",
    "    else:\n",
    "        print(\"Milestone 4b else, should_we_drop_bad_values, index ?\")\n",
    "        print(\"There are no rows to drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop bad values: \n",
    "\n",
    "def drop_bad_values(indexes_to_drop):\n",
    "    print(\"Milestone 6, drop_bad_values, index ?\")\n",
    "    before_rows = df.shape[0]\n",
    "\n",
    "    record_df_droplog(indexes_to_drop)  # NEW\n",
    "    df.drop(df.index[indexes_to_drop], inplace=True)\n",
    "    \n",
    "    print(\"Milestone 9, drop_bad_values, index ?\")\n",
    "\n",
    "    print(\"Number of rows before:\", before_rows)\n",
    "    print(\"Number of rows expected to be dropped:\", len(indexes_to_drop))\n",
    "    print(\"Number of rows actually dropped:\", before_rows - df.shape[0])\n",
    "    print(\"Number of rows after:\", df.shape[0])\n",
    "    print()\n",
    "    print('df_droplog.shape[0]', df_droplog.shape[0])\n",
    "\n",
    "\n",
    "def drop_bad_values_setup(indexes_to_maybe_drop): \n",
    "    print(\"Milestone 3, drop_bad_values_setup, index ?\")\n",
    "    if should_we_drop_bad_values(indexes_to_maybe_drop) == \"y\":  \n",
    "        print(\"Milestone 5, drop_bad_values_setup, index ?\")\n",
    "        indexes_to_drop = []\n",
    "        \n",
    "        for i in range(len(indexes_to_maybe_drop)):\n",
    "            indexes_to_drop.append(indexes_to_maybe_drop[i][0])\n",
    "            \n",
    "        drop_bad_values(indexes_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_rows_with_bad_Timestamps(row_indexes=[]):\n",
    "    \"\"\"This function drops rows with bad Timestamps if user directs to do so.\"\"\"\n",
    "\n",
    "    # Use the datetime accessor dt to access the strftime method. You can pass a \n",
    "    # format string to strftime and it will return a formatted string. When used \n",
    "    # with the dt accessor you will get a series of strings.\n",
    "\n",
    "    # df.submission_time.dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # MAYBE use list of bad indexes, or use row by row logic below. The latter\n",
    "    # is more expensive, and redundant, but I prefer it and it teaches me the dt\n",
    "    # datetime accessor. \n",
    "    \n",
    "    # ADD user INPUT FX HERE ???\n",
    "    yn = should_we_drop_bad_values(indexes_to_maybe_drop)  # pass in list???\n",
    "    \n",
    "    if not yn == 'y':  # proceed only if user indicated to delete rows\n",
    "        return\n",
    "\n",
    "    indexes_to_drop = []\n",
    "    for i in range(len(indexes_to_maybe_drop)):\n",
    "        indexes_to_drop.append(indexes_to_maybe_drop[i][0])\n",
    "    \n",
    "    print(\"Before:\", df.shape)\n",
    "    before_rows = df.shape[0]\n",
    "\n",
    "    # I am deleting rows by condition, NOT by index from analysis above. \n",
    "    if cnt_submission_bad > 0:\n",
    "        record_df_droplog(indexes_to_drop)  \n",
    "        df = df.drop(df[df.submission_time.dt.strftime('%Y') != '2018'].index)\n",
    "    if cnt_start_bad > 0:   \n",
    "        record_df_droplog(indexes_to_drop)  \n",
    "        df = df.drop(df[df.start_time.dt.strftime('%Y') != '2018'].index)\n",
    "    if cnt_end_bad > 0:\n",
    "        record_df_droplog(indexes_to_drop) \n",
    "        df = df.drop(df[df.end_time.dt.strftime('%Y') != '2018'].index)\n",
    "\n",
    "    print(\"After:\", df.shape, '\\n')\n",
    "    print(\"Rows dropped:\", str(before_rows - df.shape[0]))\n",
    "    print()\n",
    "    print('df_droplog.shape[0]', df_droplog.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THIS FX REPLACED BY REMOVING \"0\" TIMES EARLIER\n",
    "\n",
    "def find_bad_Timestamps(indexes_to_maybe_drop):\n",
    "    cnt_submission_bad, cnt_start_bad, cnt_end_bad = 0, 0, 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if not '2018' in str(row.submission_time):\n",
    "            print(\"submission_time --> \", row.submission_time, \"at index\", i)\n",
    "            indexes_to_maybe_drop.append((i, str(row.submission_time)))\n",
    "            cnt_submission_bad += 1\n",
    "        # check that i was not just added before checking start_time\n",
    "        if i in [x[0] for x in indexes_to_maybe_drop]:\n",
    "            pass \n",
    "        else:\n",
    "            if not '2018' in str(row.start_time):\n",
    "                print(\"start_time --> \", row.start_time, \"at index\", i)\n",
    "                indexes_to_maybe_drop.append((i, str(row.submission_time)))\n",
    "                cnt_start_bad += 1\n",
    "        # check that i was not already added before checking end_time\n",
    "        if i in [x[0] for x in indexes_to_maybe_drop]:\n",
    "            pass\n",
    "        else:\n",
    "            if not '2018' in str(row.end_time):\n",
    "                print(\"end_time --> \", row.end_time, \"at index\", i)\n",
    "                indexes_to_maybe_drop.append((i, str(row.submission_time)))\n",
    "                cnt_end_bad += 1\n",
    "            \n",
    "    if cnt_submission_bad == 0 and cnt_start_bad == 0 and cnt_end_bad == 0:\n",
    "        print(\"No bad dates found.\")\n",
    "    else:\n",
    "        if cnt_submission_bad > 0:\n",
    "            print('cnt_submission_bad:', cnt_submission_bad)\n",
    "        if cnt_start_bad > 0:\n",
    "            print('cnt_start_bad:', cnt_start_bad)\n",
    "        if cnt_end_bad > 0:\n",
    "            print('cnt_end_bad:', cnt_end_bad)\n",
    "            \n",
    "    indexes_to_maybe_drop = list(set(sorted(indexes_to_maybe_drop)))\n",
    "            \n",
    "    return indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_duplicate_rows(df, col_names=[], row_indexes=[]):\n",
    "    \"\"\"This function accepts 2 of 3 possible args: a dataframe \n",
    "    and a col_names **or** row_indexes list.\n",
    "    \n",
    "    The function drops duplicate rows in the dataframe using the col_names list \n",
    "    to subset the dataframe.\"\"\"\n",
    "    \n",
    "    # Uniq rows are ID'd by\n",
    "    # subset=['job_number', 'task_number', 'submission_time']\n",
    "\n",
    "    print(\"Num rows before drop duplicates:\", df.shape[0])\n",
    "\n",
    "    # determine whether col_names or row_indexes was passed and process\n",
    "    if len(col_names) > 0:\n",
    "        indexes_to_drop = []\n",
    "        for i in range(len(indexes_to_maybe_drop)):\n",
    "            indexes_to_drop.append(indexes_to_maybe_drop[i][0])\n",
    "\n",
    "        record_df_droplog(indexes_to_drop)\n",
    "        \n",
    "        # use built-in fx\n",
    "        df = df.drop_duplicates(subset=col_names, keep='first')  # NEW NEW NEW\n",
    "        \n",
    "    elif len(row_indexes) > 0:\n",
    "        # record_df_droplog() handled by drop_rows_with_bad_Timestamps()\n",
    "        \n",
    "        # use custom fx\n",
    "        drop_rows_with_bad_Timestamps(row_indexes)   \n",
    "        \n",
    "    else:\n",
    "        print('Invalid or missing data passed to drop_duplicate_rows() function.')\n",
    "        \n",
    "    print(\"Num rows after drop duplicates:\", df.shape[0])\n",
    "    print()\n",
    "    print('df_droplog.shape[0]', df_droplog.shape[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "### Step 4-1\n",
    "A typical **`category`** field looks like:\n",
    "\n",
    "```\n",
    "...:-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1:...\n",
    "```\n",
    "```\n",
    "    :\n",
    "    -U campus \n",
    "    -u stevendu \n",
    "    -l \n",
    "    h_data=4G,\n",
    "    h_rt=86400,\n",
    "    h_vmem=4G \n",
    "    -pe single 1\n",
    "    :```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `category` field, extract the `h_data` data, convert the value to gigabytes (see below for explanation) and make it a new column.\n",
    "\n",
    "If the value of `h_data` ends with a “`G`” or “`g`”, the data is in the unit of gigabytes. If the value ends with “`m`” or “`M`”, the data is in the unit of megabytes:\n",
    "```\n",
    "20M or 20m  : 20 megabytes\n",
    "4G or 4g    : 4 gigabytes\n",
    "1024        : 1024 bytes\n",
    "```\n",
    "For example, if the category field has `h_data=2048M,h_rt=86400,exclusive=TRUE`, extract the `2048M`, and convert it to `2048 / 1024 = 2 (gigabytes)`. (Recall: `1G = 1024M`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_category_data_insert_new_col(col_name='', search_str='', \n",
    "                                         fnd=None, not_fnd=None, \n",
    "                                         suffix=''):\n",
    "    \"\"\"This function accepts zero or more arguments. The function extracts a \n",
    "    substring from the category column, parses the relevant values, and adds \n",
    "    these values to a new column.\n",
    "\n",
    "    IN PROCESS OF BEING ABSTRACTED/GENERICIZED/GENERALIZED TO HANDLE SEVERAL\n",
    "    OF THE STEP 4 CASES. HOWEVER, WHAT WAS BEFORE A CLEAN SET OF SEMI-SIMILAR\n",
    "    FUNCTIONS IS BECOMING AN UNWIELDY BEHEMOTH DUE TO ALL THE DISSIMILARITIES \n",
    "    IN THE CASES. REQUIRES MORE WORK.\n",
    "    \n",
    "    BUT I NEED TO FOCUS ON STEP 11, COMPARING WK1 DF TO RESULT OF WK2 DF.\"\"\"\n",
    "\n",
    "    # var to build list of values for new col\n",
    "    new_col_list = []\n",
    "#     catch_ValueError = []\n",
    "    catch_found_error = []\n",
    "    found_size = 0  # initialize to avoid UnboundLocalError\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "#         print('Index:', i)  # TEST\n",
    "#         print('Line 20: ', j)  # TEST\n",
    "        # 1. regex: extract all or part of search_str as one or more groups\n",
    "        try:\n",
    "            # use .groups() instead of .group(1) so match object found is a \n",
    "            # tuple (to handle 1 or 2 match strings)\n",
    "            found = re.search(search_str, j).groups()\n",
    "            # ? modifies the + to be non-greedy, i.e., to match as few as possible\n",
    "            if not fnd == None: # if fnd has a value, we've passed a value to use\n",
    "                found = fnd\n",
    "        except AttributeError:\n",
    "            # search_str not found\n",
    "            found = not_fnd  # cast as string to aid conditional eval below\n",
    "            found_size = 1   # BUT IF NOT_FND NOT PASSED, EQUALS NONE, NOT A STR\n",
    "                             # for h_data, this assigns -1 to found\n",
    "\n",
    "#         print(found, ' ', end='')  # Testing\n",
    "        \n",
    "        # 2. Determine how many groups were found:\n",
    "            # If try succeeds, there are 2 match objects to process.\n",
    "            # If it fails, there is 1 match object.\n",
    "\n",
    "        try:  # must try most restrictive case (that there is a second element) \n",
    "              # first, even tho it's less likely to be true\n",
    "            # Exclude string '-1', otherwise found[1][:] splits '-1' \n",
    "            # into '-' and '1', as if found contained 2 groups\n",
    "            \n",
    "#             print('Line 49: found', found)  # Testing\n",
    "            if not found == '-1':  # if something was found\n",
    "#                 try:\n",
    "                if found[1][:]:  # explicitly seek tuple element 1 (2nd element), all chars\n",
    "                    # there are 2 strings in found\n",
    "                    print('Line 51: there are (supposedly) 2 strings in found.')\n",
    "                    print('found[0][:]:', found[0][:])\n",
    "                    print('found[1][:]:', found[1][:])\n",
    "                    print('found:', found)\n",
    "                    found_size = 2  # 2 groups for _pe/slot case only\n",
    "#                 except TypeError as e:  # 'NoneType' object is not subscriptable\n",
    "# #                     pass\n",
    "#                     print('Stuck on line 58:', e)\n",
    "#                 except IndexError as e: # tuple index out of range\n",
    "#                     pass  # this just means that there are not 2 groups\n",
    "# #                     print('Stuck on line 60', e)\n",
    "#                 except UnboundLocalError as e: # local variable 'found_size' referenced before assignment\n",
    "#                     print('Stuck on line 62', e)\n",
    "            \n",
    "        except IndexError:  # tuple index out of range\n",
    "#             print('Line 70: \"except IndexError\" Step 1, index/found', i, found)\n",
    "            if found[0][:]:  # 1st element\n",
    "#                 print('Line 72: \"except IndexError\" Step 2, index/found', i, found)\n",
    "                # there is 1 string in found\n",
    "#                 print('Line 57: found[0][:] / found', found[0][:], found)\n",
    "                try:\n",
    "#                     print('Line 76: \"except IndexError\" Step 3-try, index/found', i, found)\n",
    "#                     print('Line 59: type(found[0][:]), found[0][:] :', type(found[0][:]), found[0][:])\n",
    "                    found = float(found[0][:])  # not sure why we're casting as float here,\n",
    "                    found = str(found)          # but in Line 76 is must be str to subscript\n",
    "                except ValueError:  # could not convert string to float: e.g., mixed str '2G'\n",
    "#                     print('Line 81: \"except IndexError\" Step 3-except, index/found', i, found)\n",
    "#                     print('Line 62: type(found[0][:]), found[0][:] :', type(found[0][:]), found[0][:])\n",
    "                    found = found[0][:]\n",
    "#                 print('Line 84: \"except IndexError\" Step 4, index/found', i, found)\n",
    "                found_size = 1  # 1 group for all cases except _pe/slot case\n",
    "        except TypeError:  # 'int' object is not subscriptable\n",
    "            # changed all passed fnd, not_fnd values to strings to solve this\n",
    "            print(\"Line 67: Another TypeError: 'int' object is not subscriptable\")\n",
    "            \n",
    "#         print('index: found_size |', i, ':', found_size)  # Testing: must be -1, 1, or 2\n",
    "\n",
    "        # 3. Transform and append to new_col_list \n",
    "        if found_size == 1:  # found_size == 1 should apply to all cases of \n",
    "                             # found and not found except _pe/slot case\n",
    "#             print(\"Milestone 1, index\", i)\n",
    "            \n",
    "#             print('Line 72: found_size == 1:   found:', found)  # Testing\n",
    "            \n",
    "            if col_name == 'h_data':\n",
    "                # convert the value to gigabytes if necessary & append to list\n",
    "                if found[-1] == suffix[0] or found[-1] == suffix[1]:\n",
    "                    found = float(found[:-1])\n",
    "                    new_col_list.append(round(float(found), 6))\n",
    "                    # figure out where new_col_list is going wrong\n",
    "#                     catch_ValueError.append((i+1, len(new_col_list)))\n",
    "#                     print('Mismatch line 94:', catch_ValueError[-1])\n",
    "#                     if not catch_ValueError[-1][0] == catch_ValueError[-1][0]:\n",
    "#                         print('Mismatch:', catch_ValueError[-1])\n",
    "#                     print('^^^ found', found, 'Index:', i, 'len(new_col_list)', len(new_col_list))  # TEST\n",
    "                elif found[-1] == suffix[2] or found[-1] == suffix[3]:\n",
    "                    found = float(found[:-1])\n",
    "                    new_col_list.append(round(float(found) / 1024, 6))   \n",
    "                    # figure out where new_col_list is going wrong\n",
    "#                     catch_ValueError.append((i+1, len(new_col_list)))\n",
    "#                     print('Mismatch line 103:', catch_ValueError[-1])\n",
    "#                     if not catch_ValueError[-1][0] == catch_ValueError[-1][0]:\n",
    "#                         print('Mismatch:', catch_ValueError[-1])\n",
    "#                     print('^^^ found', found, 'Index:', i, 'len(new_col_list)', len(new_col_list))  # TEST\n",
    "                elif isinstance(found, (int, float)):  \n",
    "                    new_col_list.append(round(float(found) / 1024**2, 6))  \n",
    "                    # figure out where new_col_list is going wrong\n",
    "#                     catch_ValueError.append((i+1, len(new_col_list)))\n",
    "#                     print('Mismatch line 111:', catch_ValueError[-1])\n",
    "#                     if not catch_ValueError[-1][0] == catch_ValueError[-1][0]:\n",
    "#                         print('Mismatch:', catch_ValueError[-1])\n",
    "#                     print('^^^ found', found, 'Index:', i, 'len(new_col_list)', len(new_col_list))  # TEST\n",
    "                elif found == -1 or found == '-1':  # from first try/except above; cahnged from '-1'\n",
    "                    new_col_list.append(round(float(0.0), 6))  \n",
    "                    # figure out where new_col_list is going wrong\n",
    "#                     catch_ValueError.append((i+1, len(new_col_list)))\n",
    "#                     print('Mismatch line 119:', catch_ValueError[-1])\n",
    "#                     if not catch_ValueError[-1][0] == catch_ValueError[-1][0]:\n",
    "#                         print('Mismatch:', catch_ValueError[-1])\n",
    "#                     print('^^^ found', found, 'Index:', i, 'len(new_col_list)', len(new_col_list))  # TEST\n",
    "                else:\n",
    "#                     print(\"Line 91: There's something wrong with this value:\", found, 'at index', i)\n",
    "                    print(\"Milestone 2 (h_data prob), index\", i)\n",
    "                    indexes_to_maybe_drop.append((i, found))\n",
    "                    new_col_list.append(round(float(-100), 6))\n",
    "                    # figure out where new_col_list is going wrong\n",
    "#                     catch_ValueError.append((i+1, len(new_col_list)))\n",
    "#                     print('Mismatch line 129:', catch_ValueError[-1])\n",
    "#                     if not catch_ValueError[-1][0] == catch_ValueError[-1][0]:\n",
    "#                         print('Mismatch:', catch_ValueError[-1])\n",
    "#                     print('^^^ found', found, 'Index:', i, 'len(new_col_list)', len(new_col_list))  # TEST\n",
    "\n",
    "#             else:\n",
    "#                 catch_found_error.append(('index & found not appended to new_col_list:', i, found))\n",
    "            \n",
    "            \n",
    "            if col_name == 'h_rt':\n",
    "                # convert the value (num of seconds) to hours & append to list\n",
    "                if isinstance(found, (int, float)): \n",
    "#                     print('if isinstance(found, (int, float)):', found)\n",
    "                    new_col_list.append(round(float(found) / (3600), 6))\n",
    "                elif isinstance(found,(str)) and not found == '-1':  # NEW. All cases were going to else\n",
    "                    new_col_list.append(round(float(found) / (3600), 6))\n",
    "                elif found == '-1':  # from first try/except above\n",
    "#                     print(\"elif found == '-1':\", found)\n",
    "                    new_col_list.append(round(float(0.0), 6))  \n",
    "                else:\n",
    "#                     print('else:')\n",
    "#                     print(\"Line 105: Problem with\", found)\n",
    "                    print(\"Milestone 2 (h_rt prob), index\", i)\n",
    "                    indexes_to_maybe_drop.append((i, found))\n",
    "                    new_col_list.append(round(float(-100), 6))\n",
    "                    \n",
    "            if col_name == 'highp':\n",
    "                if (found == 0 or found == 1\n",
    "                    or found == 0.0 or found == 1.0):\n",
    "                    new_col_list.append(int(found))\n",
    "                elif (found == '0' or found == '1'):\n",
    "                    new_col_list.append(int(found))\n",
    "                elif (found == '0.0' or found == '1.0'):\n",
    "                    new_col_list.append(int(found[0]))\n",
    "                else:\n",
    "#                     print(\"Line 112: Problem with\", found, \"at index\", i)\n",
    "                    print(\"Milestone 2 (highp prob), index\", i, found)\n",
    "                    indexes_to_maybe_drop.append((i, found))\n",
    "                    new_col_list.append(int(-100)) \n",
    "            \n",
    "            if col_name == '':  # TO-DO FOR ADDTL FXS BELOW\n",
    "                pass\n",
    "            \n",
    "        elif found_size == 2:\n",
    "            # add in when get to this case\n",
    "            print('Line 120: found_size == 2:   found:', found)  # Testing\n",
    "            print(\"Time to build this case? No updates made to df.\\n\")\n",
    "            print(\"found -->\", found)\n",
    "            print(\"\\nnew_col_list: partial, before fx early exit at ...\\n\")\n",
    "            print(\"def extract_category_data_insert_new_col(col_name=`\" + col_name \n",
    "                  + \"`, search_str=`\" + str(search_str) \n",
    "                  + \"`, fnd=`\" + str(fnd) \n",
    "                  + \"`, not_fnd=`\" + str(not_fnd) \n",
    "                  + \"`, suffix=`\" + str(suffix) \n",
    "                  + \"`):\")\n",
    "            print(\"\"\"    for i,j in enumerate(df.category):\"\"\")\n",
    "            print(\"\"\"        # 3. Transform and append to new_col_list\"\"\")\n",
    "            print(\"\"\"            elif found_size == 2\"\"\")\n",
    "            print(\"\\n\\nlen(new_col_list):\", len(new_col_list))\n",
    "            print(\"^^^ this is index of problem found value\")\n",
    "            \n",
    "            print(\"Milestone 2 (found_size == 2 prob), index\", i)\n",
    "            indexes_to_maybe_drop.append((i, found))\n",
    "            \n",
    "            return\n",
    "        \n",
    "        elif found_size == -1 or found_size == '-1':  # if found_size != 1 or 2 (i.e., search_str wasn't found)\n",
    "            if col_name == 'highp':\n",
    "                new_col_list.append(int(0))\n",
    "            else:\n",
    "                new_col_list.append(round(float(0.0), 6))\n",
    "\n",
    "        else:  # if found_size != -1, 1, or 2, which are the only valid values\n",
    "            catch_found_error.append(('Line 214: index & found prob', i, found))\n",
    "                # 23 values of -1 account for missing rows. Why -1? not_fnd='-1'\n",
    "            new_col_list.append(round(float(0.0), 6))\n",
    "            \n",
    "    # make it a new column\n",
    "#     print(catch_ValueError)  # Testing\n",
    "    if not len(df) == len(new_col_list):\n",
    "        print('len(df), len(new_col_list) discrepency:', len(df), len(new_col_list))  # Testing\n",
    "    # 4580087 4580064   Discrepency of 23\n",
    "    if len(catch_found_error) > 0:\n",
    "        print('len(catch_found_error) & catch_found_error', len(catch_found_error), catch_found_error)  # Testing\n",
    "    # 0 []\n",
    "    df[col_name] = new_col_list  # ValueError: Length of values does not match length of index\n",
    "    del new_col_list, catch_found_error\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `h_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestone 2 (h_data prob), index 366018\n",
      "Milestone 2 (h_data prob), index 396059\n",
      "Milestone 2 (h_data prob), index 422616\n",
      "Milestone 2 (h_data prob), index 937191\n",
      "Milestone 2 (h_data prob), index 937192\n",
      "Milestone 2 (h_data prob), index 1892248\n",
      "Milestone 2 (h_data prob), index 1928516\n",
      "Milestone 2 (h_data prob), index 3576109\n",
      "Milestone 2 (h_data prob), index 3652308\n",
      "Milestone 2 (h_data prob), index 3658409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  \n",
       "0  4.040196e+09  4.0     \n",
       "1  6.098657e+08  4.0     \n",
       "2  3.326935e+09  4.0     "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_category_data_insert_new_col(col_name='h_data',\n",
    "                                          search_str='h_data=(.+?),', \n",
    "                                          not_fnd='-1',\n",
    "                                          suffix='GgMm')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly bad values:  \n",
    "index 366018  \n",
    "index 396059  \n",
    "index 422616  \n",
    "index 937191  \n",
    "index 937192  \n",
    "index 1892248  \n",
    "index 1928516  \n",
    "index 3576109  \n",
    "index 3652308  \n",
    "index 3658409  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect bad values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(366018, '16.0'),\n",
       " (396059, '24.0'),\n",
       " (422616, '16.0'),\n",
       " (937191, '4.0'),\n",
       " (937192, '4.0'),\n",
       " (1892248, 'TRUE'),\n",
       " (1928516, '12.0'),\n",
       " (3576109, '4.0'),\n",
       " (3652308, 'TRUE'),\n",
       " (3658409, '24.0')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop  # list of (i, found) tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[(366018, '16.0'),  \n",
    " (396059, '24.0'),  \n",
    " (422616, '16.0'),  \n",
    " (937191, '4.0'),  \n",
    " (937192, '4.0'),  \n",
    " (1892248, 'TRUE'),  \n",
    " (1928516, '12.0'),  \n",
    " (3576109, '4.0'),  \n",
    " (3652308, 'TRUE'),  \n",
    " (3658409, '24.0')]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Findings**:\n",
    "- The numerical values are too low to be KB. They are probably GB, but per the instructions they seem to be invalid. \n",
    "- The \"TRUE\" values should be dropped (unless \"True\" equals 1, 1 GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestone 3, drop_bad_values_setup, index ?\n",
      "Milestone 4a, should_we_drop_bad_values, index ?\n",
      "Milestone 4b if, should_we_drop_bad_values, index ?\n",
      "Milestone 5, drop_bad_values_setup, index ?\n",
      "Milestone 6, drop_bad_values, index ?\n",
      "Milestone 7, record_df_droplog, index ?\n",
      "TEST record_df_droplog LINE 22: 0 Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "TEST record_df_droplog  LINE 22: 10            group     owner  job_number  submission_time  start_time  \\\n",
      "366018   mpfitz   parriaga  3937422     1538610359       1538610515   \n",
      "396059   matteop  sorel     3939666     1538630542       1538630678   \n",
      "422616   mpfitz   parriaga  3937432     1538610474       1538610580   \n",
      "937191   rwayne   rsmeyer   3971239     1539040715       1539040817   \n",
      "937192   rwayne   rsmeyer   3971238     1539040688       1539040817   \n",
      "1892248  kmartin  jachiro   4008009     1539640706       1539640812   \n",
      "1928516  elondon  tomimizu  4010169     1539661540       1539661582   \n",
      "3576109  kruegg   kellybar  4058455     1540181808       1540181852   \n",
      "3652308  jcykao   johannes  4065298     1540325327       1540333222   \n",
      "3658409  eeskin   zhanly81  4066046     1540339436       1540339485   \n",
      "\n",
      "           end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
      "366018   1538610515  100     0            shared     8      0             \n",
      "396059   1538630678  100     0            shared     4      0             \n",
      "422616   1538655601  37      0            shared     8      0             \n",
      "937191   1539040818  15      127          NONE       1      0             \n",
      "937192   1539040818  15      127          NONE       1      0             \n",
      "1892248  1539640813  0       0            single     1      0             \n",
      "1928516  1539661834  0       0            single     1      0             \n",
      "3576109  1540189203  37      0            single     1      0             \n",
      "3652308  1540333224  0       0            single     1      0             \n",
      "3658409  1540339486  100     0            single     1      0             \n",
      "\n",
      "                                                                                                                 category  \\\n",
      "366018   -U mpfitz -u parriaga -l h_data=16,h_rt=43200,interactive=true -pe shared 8                                        \n",
      "396059   -U cnsi,mcdb,mcdb2,cnsi_running,mcdb_running,msa_running -u sorel -l h_data=24,h_rt=86400,h_vmem=24 -pe shared 4   \n",
      "422616   -U mpfitz -u parriaga -l h_data=16,h_rt=43200,interactive=true -pe shared 8                                        \n",
      "937191   -U mcdb,rwayne,mcdb_running -u rsmeyer -l h_data=4,h_rt=86400,h_vmem=4,highp=TRUE                                  \n",
      "937192   -U mcdb,rwayne,mcdb_running -u rsmeyer -l h_data=4,h_rt=86400,h_vmem=4,highp=TRUE                                  \n",
      "1892248  -U cnsi -u jachiro -l h_data=TRUE,h_rt=7200,interactive=true -pe single 1                                          \n",
      "1928516  -U cnsi,mscohen -u tomimizu -l h_data=12,h_rt=43200,interactive=true -pe single 1                                  \n",
      "3576109  -U kruegg -u kellybar -l h_data=4,h_rt=7200,interactive=true -pe single 1                                          \n",
      "3652308  -U campus -u johannes -l h_data=TRUE,h_rt=7200,interactive=true -pe single 1                                       \n",
      "3658409  -U eeskin -u zhanly81 -l h_data=24,h_rt=7200,interactive=true -pe single 1                                         \n",
      "\n",
      "            maxvmem  h_data  \n",
      "366018   0.0        -100.0   \n",
      "396059   19251200.0 -100.0   \n",
      "422616   0.0        -100.0   \n",
      "937191   0.0        -100.0   \n",
      "937192   0.0        -100.0   \n",
      "1892248  0.0        -100.0   \n",
      "1928516  0.0        -100.0   \n",
      "3576109  0.0        -100.0   \n",
      "3652308  0.0        -100.0   \n",
      "3658409  0.0        -100.0   \n",
      "Milestone 8, record_df_droplog finished\n",
      "Milestone 9, drop_bad_values, index ?\n",
      "Number of rows before: 4580087\n",
      "Number of rows expected to be dropped: 10\n",
      "Number of rows actually dropped: 10\n",
      "Number of rows after: 4580077\n",
      "\n",
      "df_droplog.shape[0] 0\n"
     ]
    }
   ],
   "source": [
    "# Drop bad values\n",
    "drop_bad_values_setup(indexes_to_maybe_drop)  # handles case of no bad values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- KeyError: 'None of [[266018, 296059, 322616, 837191, 837192]] are in the [index]'\n",
    "- This is good news! It means that the way I have this coded (maybe b/c I'm not reindexing after each operation) pandas will not delete the \"same index\" twice as I had thought might happen if I ran the same cell twice in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_droplog.shape[0] 0**\n",
    "- should  be len 10\n",
    "\n",
    "**FIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        df:    1.8GB\n",
      "      _i43:   12.8KB\n",
      "       ___:    2.8KB\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 146 KB\n",
    "\n",
    "check_variable_sizes(locals().items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-2\n",
    "In the `category` field, extract the `h_rt` data, which is in seconds. Make a new column for `h_rt` in the unit of hours. For example, if the `h_rt` value is `86400`, convert it to `86400/(3600*24) = 24` (hours). In this case, the row value in the new `h_rt` column will be `24`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `h_rt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  \n",
       "0  4.040196e+09  4.0     24.0  \n",
       "1  6.098657e+08  4.0     6.0   \n",
       "2  3.326935e+09  4.0     24.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "extract_category_data_insert_new_col(col_name='h_rt', \n",
    "                                          search_str='h_rt=(.+?),', \n",
    "#                                           search_str='h_rt=(.+?),|\\s', # not always a comma?\n",
    "#                                           search_str='h_rt=(.+),',    # greedy. ValueError: could not convert string to float: '172800,h_vmem=1024M'\n",
    "                                          not_fnd='-1')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103616</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3924233</td>\n",
       "      <td>1538436236</td>\n",
       "      <td>1538476459</td>\n",
       "      <td>1538476646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>2057</td>\n",
       "      <td>-U campus,c2_running -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.491082e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "103616  sudip  stevendu  3924233     1538436236       1538476459  1538476646   \n",
       "\n",
       "        failed  exit_status granted_pe  slots  task_number  \\\n",
       "103616  0       0            single     1      2057          \n",
       "\n",
       "                                                                               category  \\\n",
       "103616  -U campus,c2_running -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1   \n",
       "\n",
       "             maxvmem  h_data  h_rt  \n",
       "103616  3.491082e+09  4.0     24.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[103616:103616+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Encountered this issue:\n",
    "\n",
    "```\n",
    "IOPub data rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_data_rate_limit`.\n",
    "```\n",
    "\n",
    "- Possbily resolved by creating `jupyter_notebook_config.py` in `C:\\Users\\karls\\.jupyter`\n",
    " - Set `c.NotebookApp.iopub_data_rate_limit = 1000000000` (default/previous value was 10e7 or 8)\n",
    " - (bytes/sec) Maximum rate at which messages can be sent on iopub before they are limited.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-3\n",
    "Create a new column called `highp`. In the `category` field, if `highp=TRUE` or `highp=true` is identified, the row value of `highp` would be `1`. Otherwise `highp` is `0` in the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def extract_highp_to_new_col():\n",
    "#     \"\"\"This function extracts a value from the category column and adds a\n",
    "#     related value to a new column.\"\"\"\n",
    "\n",
    "#     highp = []\n",
    "\n",
    "#     for i,j in enumerate(df.category):\n",
    "# #         print(j)  # Testing\n",
    "        \n",
    "#         # 1. use regex to extract the `highp` data\n",
    "#         try:\n",
    "#             found = re.search('highp=(TRUE|True|true)', j).group(1)\n",
    "# #             print(i, ':', found, end=' ')  # Testing\n",
    "#             # if succeeds, change 'found' to 1; if fails, will jump to except\n",
    "#             found = 1\n",
    "# #             print(found, end=' ')  # Testing\n",
    "#         except AttributeError:\n",
    "#             # 'highp=TRUE|True|true' not found in the original string\n",
    "#             found = 0\n",
    "# #             print(i, ':', found, end=' ')  # Testing\n",
    "\n",
    "#         # should be left with a positive or negative result:\n",
    "#         # Positive: found == 1 or found.lower() == 'true'\n",
    "#         # Negative: found == 0\n",
    "        \n",
    "# #         print(found, ' ', end='')  # Testing\n",
    "\n",
    "#         # 2. append to list\n",
    "#         if found == 0 or found == 1:\n",
    "#             highp.append(found)\n",
    "#         else:\n",
    "#             print(\"Problem with\", found, \"at index\", i)\n",
    "#             highp.append(-100) \n",
    "\n",
    "# #         print(highp[-1])  # during testing\n",
    "\n",
    "#     # make it a new column\n",
    "#     df['highp'] = highp  \n",
    "# #     del highp\n",
    "#     return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `highp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  \n",
       "0  4.040196e+09  4.0     24.0  0      \n",
       "1  6.098657e+08  4.0     6.0   0      \n",
       "2  3.326935e+09  4.0     24.0  0      "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "extract_category_data_insert_new_col(col_name='highp', \n",
    "                                          search_str='highp=(TRUE|True|true)',\n",
    "                                          fnd='1', not_fnd='0')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-4\n",
    "Create a new column called `exclusive`. In the `category` field, if `exclusive=TRUE` or `exclusive=true` is identified, the row value of `exclusive` would be `1`. Otherwise `exclusive` is `0` in the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_exclusive_to_new_col():\n",
    "    \"\"\"This function extracts a value from the category column and adds a\n",
    "    related value to a new column.\"\"\"\n",
    "\n",
    "    exclusive = []\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "#         print(j)  # Testing\n",
    "        try:\n",
    "            found = re.search('exclusive=(TRUE|True|true)', j).group(1)\n",
    "#             print(i, ':', found, end=' ')  # Testing\n",
    "            found = 1\n",
    "#             print(found, end=' ')  # Testing\n",
    "        except AttributeError:\n",
    "            found = 0\n",
    "#             print(i, ':', found, end=' ')  # Testing\n",
    "\n",
    "        if found == 0 or found == 1:\n",
    "            exclusive.append(found)\n",
    "        else:\n",
    "            print(\"Problem with\", found, \"at index\", i)\n",
    "            exclusive.append(-100) \n",
    "\n",
    "    # make it a new column\n",
    "    df['exclusive'] = exclusive  \n",
    "    del exclusive\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `exclusive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  \n",
       "0  4.040196e+09  4.0     24.0  0      0          \n",
       "1  6.098657e+08  4.0     6.0   0      0          \n",
       "2  3.326935e+09  4.0     24.0  0      0          "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "df = extract_exclusive_to_new_col()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-5\n",
    "Create a new column called `h_vmem`. Look for its value in the category field. Similar to `h_data`, convert the values to gigabytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Has an 'INFINITY' value as well as Gg and Mm values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_h_vmem_to_new_col():\n",
    "    \"\"\"This function extracts a substring from the category column, parses \n",
    "    the relevant values, and adds these values to a new column.\n",
    "    \n",
    "    Missing values are assigned string '-1', bad values are assigned float -100.\"\"\"\n",
    "\n",
    "    h_vmem = []\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "        try:\n",
    "            found = re.search('h_vmem=(\\d+\\.?\\d?\\w?|INFINITY)', j).group(1)  \n",
    "        except AttributeError:\n",
    "            found = '-1'\n",
    "            \n",
    "#         print('index', i, ':', found, end='-->')\n",
    "\n",
    "        # 2. convert the value to gigabytes if necessary & append to list\n",
    "    \n",
    "        # Evaluate stringy values first:\n",
    "        if found[-1] == 'G' or found[-1] == 'g':\n",
    "#             h_vmem.append(round(float(found[:-1]), 1))\n",
    "            h_vmem.append(float(found[:-1]))\n",
    "        elif found[-1] == 'M' or found[-1] == 'm':\n",
    "            # convert mb to gb\n",
    "            h_vmem.append(float(found[:-1]) / 1024)     # NO ROUND   \n",
    "        elif (found.upper() == 'INFINITY' or found.lower() == 'INFINITY'\n",
    "              or found.upper() == 'INF' or found.lower() == 'INF'\n",
    "              or found == np.inf): # NEW 2/6\n",
    "            h_vmem.append(np.inf) # NEW 2/6\n",
    "        elif found == '-1':\n",
    "            h_vmem.append(float(0.0))\n",
    "\n",
    "        # Then evaluate numeric values with no letter suffix.\n",
    "        elif isinstance(found, (int, float)):\n",
    "            # convert kb to gb\n",
    "            h_vmem.append(float(found) / 1024**2)\n",
    "\n",
    "        # Finally evaluate anomolies.\n",
    "        else:\n",
    "            print(\"Bad `found` value\", found, 'at index', i)\n",
    "            indexes_to_maybe_drop.append((i,found))\n",
    "            h_vmem.append(float(-100))\n",
    "\n",
    "        # print(h_vmem[-1])  # during testing\n",
    "\n",
    "    # make it a new column\n",
    "    df['h_vmem'] = h_vmem  \n",
    "    del h_vmem\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `h_vmem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "df = extract_h_vmem_to_new_col()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm np.inf values exist in h_vmem\n",
    "\n",
    "any(df[df.h_vmem == np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538379921</td>\n",
       "      <td>1538379921</td>\n",
       "      <td>1538380802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>3887250</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>1538380915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ana</td>\n",
       "      <td>dreilley</td>\n",
       "      <td>3913041</td>\n",
       "      <td>1538244824</td>\n",
       "      <td>1538335499</td>\n",
       "      <td>1538381021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16</td>\n",
       "      <td>1.468427e+11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913288</td>\n",
       "      <td>1538375028</td>\n",
       "      <td>1538375028</td>\n",
       "      <td>1538381132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913288</td>\n",
       "      <td>1538375028</td>\n",
       "      <td>1538375028</td>\n",
       "      <td>1538381132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538380803</td>\n",
       "      <td>1538380803</td>\n",
       "      <td>1538381252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538380803</td>\n",
       "      <td>1538380803</td>\n",
       "      <td>1538381252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538380713</td>\n",
       "      <td>1538380713</td>\n",
       "      <td>1538381275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538380713</td>\n",
       "      <td>1538380713</td>\n",
       "      <td>1538381275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913743</td>\n",
       "      <td>1538379831</td>\n",
       "      <td>1538379831</td>\n",
       "      <td>1538381293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>3909637</td>\n",
       "      <td>1538381332</td>\n",
       "      <td>1538381332</td>\n",
       "      <td>1538381390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3916885</td>\n",
       "      <td>1538380125</td>\n",
       "      <td>1538380125</td>\n",
       "      <td>1538381437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3916885</td>\n",
       "      <td>1538380125</td>\n",
       "      <td>1538380125</td>\n",
       "      <td>1538381437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>ana</td>\n",
       "      <td>jtfuller</td>\n",
       "      <td>3909458</td>\n",
       "      <td>1538169221</td>\n",
       "      <td>1538340321</td>\n",
       "      <td>1538381449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U ana,cnsi,c2_running -u jtfuller -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16</td>\n",
       "      <td>1.679982e+11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>3909642</td>\n",
       "      <td>1538381505</td>\n",
       "      <td>1538381505</td>\n",
       "      <td>1538381564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538381253</td>\n",
       "      <td>1538381253</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538381253</td>\n",
       "      <td>1538381253</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538381275</td>\n",
       "      <td>1538381276</td>\n",
       "      <td>1538381833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538381275</td>\n",
       "      <td>1538381276</td>\n",
       "      <td>1538381833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3916847</td>\n",
       "      <td>1538355836</td>\n",
       "      <td>1538355836</td>\n",
       "      <td>1538381858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3916847</td>\n",
       "      <td>1538341196</td>\n",
       "      <td>1538355836</td>\n",
       "      <td>1538381858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>3.127501e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>1538381912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>1538381683</td>\n",
       "      <td>1538381912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913631</td>\n",
       "      <td>1538380297</td>\n",
       "      <td>1538380297</td>\n",
       "      <td>1538382140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913631</td>\n",
       "      <td>1538380297</td>\n",
       "      <td>1538380297</td>\n",
       "      <td>1538382140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538381834</td>\n",
       "      <td>1538381834</td>\n",
       "      <td>1538382271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913293</td>\n",
       "      <td>1538381834</td>\n",
       "      <td>1538381834</td>\n",
       "      <td>1538382271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gengsun</td>\n",
       "      <td>3915276</td>\n",
       "      <td>1538326886</td>\n",
       "      <td>1538326886</td>\n",
       "      <td>1538382349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>node_pod</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-U gpu,sautet,msa_running -u gengsun -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe node* 1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gengsun</td>\n",
       "      <td>3915276</td>\n",
       "      <td>1538318012</td>\n",
       "      <td>1538326883</td>\n",
       "      <td>1538382349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>node_pod</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-U gpu,sautet,msa_running -u gengsun -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe node* 1</td>\n",
       "      <td>9.270067e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3918382</td>\n",
       "      <td>1538380339</td>\n",
       "      <td>1538380339</td>\n",
       "      <td>1538382549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578949</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4070882</td>\n",
       "      <td>1541057782</td>\n",
       "      <td>1541057782</td>\n",
       "      <td>1541057782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578959</th>\n",
       "      <td>ana</td>\n",
       "      <td>dreilley</td>\n",
       "      <td>4112618</td>\n",
       "      <td>1541012422</td>\n",
       "      <td>1541056926</td>\n",
       "      <td>1541057823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16</td>\n",
       "      <td>1.971237e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579000</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4064993</td>\n",
       "      <td>1541057843</td>\n",
       "      <td>1541057843</td>\n",
       "      <td>1541057910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579034</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114700</td>\n",
       "      <td>1541056398</td>\n",
       "      <td>1541056398</td>\n",
       "      <td>1541057965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579039</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4109499</td>\n",
       "      <td>1541057390</td>\n",
       "      <td>1541057390</td>\n",
       "      <td>1541057966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579060</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114590</td>\n",
       "      <td>1541055384</td>\n",
       "      <td>1541055384</td>\n",
       "      <td>1541058013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579075</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114588</td>\n",
       "      <td>1541056873</td>\n",
       "      <td>1541056873</td>\n",
       "      <td>1541058045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579166</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4109767</td>\n",
       "      <td>1541058111</td>\n",
       "      <td>1541058111</td>\n",
       "      <td>1541058176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579168</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541057737</td>\n",
       "      <td>1541057737</td>\n",
       "      <td>1541058176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579169</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541057737</td>\n",
       "      <td>1541057737</td>\n",
       "      <td>1541058176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579172</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114585</td>\n",
       "      <td>1541057657</td>\n",
       "      <td>1541057657</td>\n",
       "      <td>1541058180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579187</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114589</td>\n",
       "      <td>1541057550</td>\n",
       "      <td>1541057550</td>\n",
       "      <td>1541058200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579496</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4109499</td>\n",
       "      <td>1541057966</td>\n",
       "      <td>1541057967</td>\n",
       "      <td>1541058568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579569</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541058177</td>\n",
       "      <td>1541058177</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579570</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541058177</td>\n",
       "      <td>1541058177</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579612</th>\n",
       "      <td>miao</td>\n",
       "      <td>shikamar</td>\n",
       "      <td>4115876</td>\n",
       "      <td>1541058513</td>\n",
       "      <td>1541058563</td>\n",
       "      <td>1541058687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shared</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U cnsi,miao -u shikamar -q *@g306 -l h_data=16G,h_rt=72000,h_vmem=INFINITY,highmem_forced=TRUE,highp=TRUE -pe shared 16</td>\n",
       "      <td>5.356061e+09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579627</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114700</td>\n",
       "      <td>1541057965</td>\n",
       "      <td>1541057965</td>\n",
       "      <td>1541058704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579684</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114585</td>\n",
       "      <td>1541058181</td>\n",
       "      <td>1541058181</td>\n",
       "      <td>1541058767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579720</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114586</td>\n",
       "      <td>1541057688</td>\n",
       "      <td>1541057688</td>\n",
       "      <td>1541058811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579727</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4109767</td>\n",
       "      <td>1541058758</td>\n",
       "      <td>1541058758</td>\n",
       "      <td>1541058819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579739</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114590</td>\n",
       "      <td>1541058013</td>\n",
       "      <td>1541058013</td>\n",
       "      <td>1541058840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579760</th>\n",
       "      <td>miao</td>\n",
       "      <td>shikamar</td>\n",
       "      <td>4115877</td>\n",
       "      <td>1541058521</td>\n",
       "      <td>1541058737</td>\n",
       "      <td>1541058855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shared</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U cnsi,miao -u shikamar -q *@g306 -l h_data=16G,h_rt=72000,h_vmem=INFINITY,highmem_forced=TRUE,highp=TRUE -pe shared 16</td>\n",
       "      <td>5.356057e+09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579801</th>\n",
       "      <td>ana</td>\n",
       "      <td>dreilley</td>\n",
       "      <td>4112070</td>\n",
       "      <td>1541008518</td>\n",
       "      <td>1541051421</td>\n",
       "      <td>1541058898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16</td>\n",
       "      <td>1.652640e+11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579924</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114589</td>\n",
       "      <td>1541058200</td>\n",
       "      <td>1541058200</td>\n",
       "      <td>1541059035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579979</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4071120</td>\n",
       "      <td>1541058991</td>\n",
       "      <td>1541058991</td>\n",
       "      <td>1541059057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579986</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>1541059070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579990</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114772</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>1541058642</td>\n",
       "      <td>1541059070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580029</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4114588</td>\n",
       "      <td>1541058045</td>\n",
       "      <td>1541058045</td>\n",
       "      <td>1541059123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580045</th>\n",
       "      <td>bauchy</td>\n",
       "      <td>hanliu</td>\n",
       "      <td>4067644</td>\n",
       "      <td>1541059074</td>\n",
       "      <td>1541059074</td>\n",
       "      <td>1541059143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580046</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>4109499</td>\n",
       "      <td>1541058569</td>\n",
       "      <td>1541058569</td>\n",
       "      <td>1541059145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118728 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          group     owner  job_number  submission_time  start_time  \\\n",
       "19       sautet  gxy235    3913291     1538379921       1538379921   \n",
       "77       bauchy  hanliu    3887250     1538380856       1538380856   \n",
       "168      ana     dreilley  3913041     1538244824       1538335499   \n",
       "277      sautet  gxy235    3913288     1538375028       1538375028   \n",
       "278      sautet  gxy235    3913288     1538375028       1538375028   \n",
       "395      sautet  gxy235    3913291     1538380803       1538380803   \n",
       "396      sautet  gxy235    3913291     1538380803       1538380803   \n",
       "407      sautet  gxy235    3913293     1538380713       1538380713   \n",
       "410      sautet  gxy235    3913293     1538380713       1538380713   \n",
       "443      sautet  gxy235    3913743     1538379831       1538379831   \n",
       "531      bauchy  hanliu    3909637     1538381332       1538381332   \n",
       "570      sautet  gxy235    3916885     1538380125       1538380125   \n",
       "571      sautet  gxy235    3916885     1538380125       1538380125   \n",
       "579      ana     jtfuller  3909458     1538169221       1538340321   \n",
       "675      bauchy  hanliu    3909642     1538381505       1538381505   \n",
       "782      sautet  gxy235    3913291     1538381253       1538381253   \n",
       "783      sautet  gxy235    3913291     1538381253       1538381253   \n",
       "934      sautet  gxy235    3913293     1538381275       1538381276   \n",
       "935      sautet  gxy235    3913293     1538381275       1538381276   \n",
       "954      sautet  gxy235    3916847     1538355836       1538355836   \n",
       "955      sautet  gxy235    3916847     1538341196       1538355836   \n",
       "1011     sautet  gxy235    3913291     1538381683       1538381683   \n",
       "1012     sautet  gxy235    3913291     1538381683       1538381683   \n",
       "1182     sautet  gxy235    3913631     1538380297       1538380297   \n",
       "1183     sautet  gxy235    3913631     1538380297       1538380297   \n",
       "1276     sautet  gxy235    3913293     1538381834       1538381834   \n",
       "1277     sautet  gxy235    3913293     1538381834       1538381834   \n",
       "1335     sautet  gengsun   3915276     1538326886       1538326886   \n",
       "1338     sautet  gengsun   3915276     1538318012       1538326883   \n",
       "1497     sautet  gxy235    3918382     1538380339       1538380339   \n",
       "...         ...     ...        ...            ...              ...   \n",
       "4578949  bauchy  hanliu    4070882     1541057782       1541057782   \n",
       "4578959  ana     dreilley  4112618     1541012422       1541056926   \n",
       "4579000  bauchy  hanliu    4064993     1541057843       1541057843   \n",
       "4579034  sautet  gxy235    4114700     1541056398       1541056398   \n",
       "4579039  sautet  gxy235    4109499     1541057390       1541057390   \n",
       "4579060  sautet  gxy235    4114590     1541055384       1541055384   \n",
       "4579075  sautet  gxy235    4114588     1541056873       1541056873   \n",
       "4579166  bauchy  hanliu    4109767     1541058111       1541058111   \n",
       "4579168  sautet  gxy235    4114772     1541057737       1541057737   \n",
       "4579169  sautet  gxy235    4114772     1541057737       1541057737   \n",
       "4579172  sautet  gxy235    4114585     1541057657       1541057657   \n",
       "4579187  sautet  gxy235    4114589     1541057550       1541057550   \n",
       "4579496  sautet  gxy235    4109499     1541057966       1541057967   \n",
       "4579569  sautet  gxy235    4114772     1541058177       1541058177   \n",
       "4579570  sautet  gxy235    4114772     1541058177       1541058177   \n",
       "4579612  miao    shikamar  4115876     1541058513       1541058563   \n",
       "4579627  sautet  gxy235    4114700     1541057965       1541057965   \n",
       "4579684  sautet  gxy235    4114585     1541058181       1541058181   \n",
       "4579720  sautet  gxy235    4114586     1541057688       1541057688   \n",
       "4579727  bauchy  hanliu    4109767     1541058758       1541058758   \n",
       "4579739  sautet  gxy235    4114590     1541058013       1541058013   \n",
       "4579760  miao    shikamar  4115877     1541058521       1541058737   \n",
       "4579801  ana     dreilley  4112070     1541008518       1541051421   \n",
       "4579924  sautet  gxy235    4114589     1541058200       1541058200   \n",
       "4579979  bauchy  hanliu    4071120     1541058991       1541058991   \n",
       "4579986  sautet  gxy235    4114772     1541058642       1541058642   \n",
       "4579990  sautet  gxy235    4114772     1541058642       1541058642   \n",
       "4580029  sautet  gxy235    4114588     1541058045       1541058045   \n",
       "4580045  bauchy  hanliu    4067644     1541059074       1541059074   \n",
       "4580046  sautet  gxy235    4109499     1541058569       1541058569   \n",
       "\n",
       "           end_time  failed  exit_status   granted_pe  slots  task_number  \\\n",
       "19       1538380802  0       0            dc_pod_ib56  24     0             \n",
       "77       1538380915  0       0            dc_pod       16     0             \n",
       "168      1538381021  0       0            dc_pod_ib56  16     0             \n",
       "277      1538381132  0       0            dc_pod_ib56  24     0             \n",
       "278      1538381132  0       0            dc_pod_ib56  24     0             \n",
       "395      1538381252  0       0            dc_pod_ib56  24     0             \n",
       "396      1538381252  0       0            dc_pod_ib56  24     0             \n",
       "407      1538381275  0       0            dc_pod_ib56  24     0             \n",
       "410      1538381275  0       0            dc_pod_ib56  24     0             \n",
       "443      1538381293  0       0            dc_pod_ib56  24     0             \n",
       "531      1538381390  0       0            dc_pod       16     0             \n",
       "570      1538381437  0       0            dc_pod_ib56  24     0             \n",
       "571      1538381437  0       0            dc_pod_ib56  24     0             \n",
       "579      1538381449  0       0            dc_pod_ib56  16     0             \n",
       "675      1538381564  0       0            dc_pod       16     0             \n",
       "782      1538381683  0       0            dc_pod_ib56  24     0             \n",
       "783      1538381683  0       0            dc_pod_ib56  24     0             \n",
       "934      1538381833  0       0            dc_pod_ib56  24     0             \n",
       "935      1538381833  0       0            dc_pod_ib56  24     0             \n",
       "954      1538381858  0       0            dc_pod_ib56  24     0             \n",
       "955      1538381858  0       0            dc_pod_ib56  24     0             \n",
       "1011     1538381912  0       0            dc_pod_ib56  24     0             \n",
       "1012     1538381912  0       0            dc_pod_ib56  24     0             \n",
       "1182     1538382140  0       0            dc_pod_ib56  24     0             \n",
       "1183     1538382140  0       0            dc_pod_ib56  24     0             \n",
       "1276     1538382271  0       0            dc_pod_ib56  24     0             \n",
       "1277     1538382271  0       0            dc_pod_ib56  24     0             \n",
       "1335     1538382349  0       0            node_pod     1      0             \n",
       "1338     1538382349  0       0            node_pod     1      0             \n",
       "1497     1538382549  0       0            dc_pod       24     0             \n",
       "...             ... ..      ..               ...       ..    ..             \n",
       "4578949  1541057782  0       0            dc_pod       16     0             \n",
       "4578959  1541057823  0       0            dc_pod_ib56  16     0             \n",
       "4579000  1541057910  0       0            dc_pod       16     0             \n",
       "4579034  1541057965  0       0            dc_pod_ib56  24     0             \n",
       "4579039  1541057966  0       0            dc_pod_ib56  24     0             \n",
       "4579060  1541058013  0       0            dc_pod       24     0             \n",
       "4579075  1541058045  0       0            dc_pod       24     0             \n",
       "4579166  1541058176  0       0            dc_pod       16     0             \n",
       "4579168  1541058176  0       0            dc_pod_ib56  24     0             \n",
       "4579169  1541058176  0       0            dc_pod_ib56  24     0             \n",
       "4579172  1541058180  0       0            dc_pod       24     0             \n",
       "4579187  1541058200  0       0            dc_pod       24     0             \n",
       "4579496  1541058568  0       0            dc_pod_ib56  24     0             \n",
       "4579569  1541058642  0       0            dc_pod_ib56  24     0             \n",
       "4579570  1541058642  0       0            dc_pod_ib56  24     0             \n",
       "4579612  1541058687  0       0            shared       16     0             \n",
       "4579627  1541058704  0       0            dc_pod_ib56  24     0             \n",
       "4579684  1541058767  0       0            dc_pod       24     0             \n",
       "4579720  1541058811  0       0            dc_pod       24     0             \n",
       "4579727  1541058819  0       0            dc_pod       16     0             \n",
       "4579739  1541058840  0       0            dc_pod       24     0             \n",
       "4579760  1541058855  0       0            shared       16     0             \n",
       "4579801  1541058898  0       0            dc_pod_ib56  16     0             \n",
       "4579924  1541059035  0       0            dc_pod       24     0             \n",
       "4579979  1541059057  0       0            dc_pod       16     0             \n",
       "4579986  1541059070  0       0            dc_pod_ib56  24     0             \n",
       "4579990  1541059070  0       0            dc_pod_ib56  24     0             \n",
       "4580029  1541059123  0       0            dc_pod       24     0             \n",
       "4580045  1541059143  0       0            dc_pod       16     0             \n",
       "4580046  1541059145  0       0            dc_pod_ib56  24     0             \n",
       "\n",
       "                                                                                                                         category  \\\n",
       "19       -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "77       -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "168      -U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16                                  \n",
       "277      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "278      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "395      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "396      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "407      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "410      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "443      -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "531      -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "570      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "571      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "579      -U ana,cnsi,c2_running -u jtfuller -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16                       \n",
       "675      -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "782      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "783      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "934      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "935      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "954      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "955      -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "1011     -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "1012     -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "1182     -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "1183     -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "1276     -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "1277     -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "1335     -U gpu,sautet,msa_running -u gengsun -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe node* 1                    \n",
       "1338     -U gpu,sautet,msa_running -u gengsun -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe node* 1                    \n",
       "1497     -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "...                                                                                                      ...                        \n",
       "4578949  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4578959  -U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16                                  \n",
       "4579000  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4579034  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579039  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "4579060  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579075  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579166  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4579168  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579169  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579172  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579187  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579496  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "4579569  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579570  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579612  -U cnsi,miao -u shikamar -q *@g306 -l h_data=16G,h_rt=72000,h_vmem=INFINITY,highmem_forced=TRUE,highp=TRUE -pe shared 16   \n",
       "4579627  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579684  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579720  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579727  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4579739  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579760  -U cnsi,miao -u shikamar -q *@g306 -l h_data=16G,h_rt=72000,h_vmem=INFINITY,highmem_forced=TRUE,highp=TRUE -pe shared 16   \n",
       "4579801  -U ana,cnsi -u dreilley -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 16                                  \n",
       "4579924  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4579979  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4579986  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4579990  -U sautet,sautet_gxy235 -u gxy235 -q pod-par-ib56.q -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24      \n",
       "4580029  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=345600,h_vmem=INFINITY,highp=TRUE -pe dc* 24            \n",
       "4580045  -U bauchy -u hanliu -l exclusive=TRUE,h_data=2G,h_rt=1080000,h_vmem=INFINITY,highp=TRUE -pe dc* 16                         \n",
       "4580046  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24                        \n",
       "\n",
       "              maxvmem  h_data   h_rt  highp  exclusive  h_vmem  \n",
       "19       0.000000e+00  4.0     24.0   0      1          inf     \n",
       "77       0.000000e+00  2.0     300.0  1      1          inf     \n",
       "168      1.468427e+11  4.0     24.0   0      1          inf     \n",
       "277      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "278      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "395      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "396      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "407      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "410      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "443      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "531      0.000000e+00  2.0     300.0  1      1          inf     \n",
       "570      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "571      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "579      1.679982e+11  4.0     24.0   0      1          inf     \n",
       "675      0.000000e+00  2.0     300.0  1      1          inf     \n",
       "782      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "783      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "934      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "935      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "954      0.000000e+00  4.0     24.0   0      1          inf     \n",
       "955      3.127501e+08  4.0     24.0   0      1          inf     \n",
       "1011     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1012     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1182     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1183     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1276     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1277     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1335     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "1338     9.270067e+08  4.0     24.0   0      1          inf     \n",
       "1497     0.000000e+00  4.0     24.0   0      1          inf     \n",
       "...               ...  ...      ...  ..     ..          ...     \n",
       "4578949  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4578959  1.971237e+09  4.0     24.0   0      1          inf     \n",
       "4579000  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4579034  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579039  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579060  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579075  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579166  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4579168  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579169  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579172  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579187  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579496  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579569  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579570  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579612  5.356061e+09  16.0    20.0   1      0          inf     \n",
       "4579627  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579684  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579720  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579727  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4579739  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579760  5.356057e+09  16.0    20.0   1      0          inf     \n",
       "4579801  1.652640e+11  4.0     24.0   0      1          inf     \n",
       "4579924  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4579979  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4579986  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4579990  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "4580029  0.000000e+00  4.0     96.0   1      1          inf     \n",
       "4580045  0.000000e+00  2.0     300.0  1      1          inf     \n",
       "4580046  0.000000e+00  4.0     24.0   0      1          inf     \n",
       "\n",
       "[118728 rows x 18 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df[df.h_vmem == np.inf]))\n",
    "df[df.h_vmem == np.inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- `any()` says inf exists\n",
    "- but `len` and `df` say no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gxy235</td>\n",
       "      <td>3913291</td>\n",
       "      <td>1538379921</td>\n",
       "      <td>1538379921</td>\n",
       "      <td>1538380802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group   owner  job_number  submission_time  start_time    end_time  \\\n",
       "19  sautet  gxy235  3913291     1538379921       1538379921  1538380802   \n",
       "\n",
       "    failed  exit_status   granted_pe  slots  task_number  \\\n",
       "19  0       0            dc_pod_ib56  24     0             \n",
       "\n",
       "                                                                                               category  \\\n",
       "19  -U sautet,sautet_gxy235 -u gxy235 -l exclusive=TRUE,h_data=4G,h_rt=86400,h_vmem=INFINITY -pe dc* 24   \n",
       "\n",
       "    maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \n",
       "19  0.0      4.0     24.0  0      1          inf     "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check indexes 19 77 168 (from testing done just after data ingenstion)\n",
    "\n",
    "df[19:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Aha. -1.0 means the string was not found, probably b/c it was looking for digits, not letters  \n",
    "**Fixed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect bad values:\n",
    "\n",
    "indexes_to_maybe_drop\n",
    "\n",
    "# print(df.category[396059])  # 24 at index 396059\n",
    "# print(df.category[937191])  # 4 at index 937191\n",
    "# print(df.category[937192])  # 4 at index 937192\n",
    "\n",
    "# too small to be KB, prob GB mislabeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Why is it not flagging the values shown above anymore???\n",
    "\n",
    "**Fix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestone 3, drop_bad_values_setup, index ?\n",
      "Milestone 4a, should_we_drop_bad_values, index ?\n",
      "Milestone 4b else, should_we_drop_bad_values, index ?\n",
      "There are no rows to drop.\n"
     ]
    }
   ],
   "source": [
    "# Drop bad values\n",
    "drop_bad_values_setup(indexes_to_maybe_drop)  # handles if there are no bad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        df:    1.9GB\n",
      "       ___:   53.0MB\n",
      "       _64:   53.0MB\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 361 KB\n",
    "\n",
    "check_variable_sizes(locals().items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-6\n",
    "Create a new column called `gpu`. Look for the value in the `category` field. If `required_gpu` is identified, set the row value to `1`. Otherwise the row value is `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**: Some category fields contain a **`gpu_XXX`** string, which may be what is meant by \"if the `required_gpu` is identified\" in the instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_gpu_to_new_col():\n",
    "    \"\"\"This function extracts a value from the category column and adds a\n",
    "    related value to a new column.\"\"\"\n",
    "\n",
    "    gpu = []\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "#         print(j)  # Testing\n",
    "        \n",
    "        # 1. use regex to extract the `gpu` data\n",
    "        try:\n",
    "            found = re.search('gpu_(\\w+)', j).group(1)\n",
    "#             print('index', i, ':', found, end='--> ')  # Testing\n",
    "            # if succeeds, change 'found' to 1; if fails, will jump to except\n",
    "            found = 1\n",
    "#             print(found)  # Testing\n",
    "        except AttributeError:\n",
    "            # 'gpu=TRUE|True|true' not found in the original string\n",
    "            found = 0\n",
    "#             print('index', i, ':', found)  # Testing\n",
    "\n",
    "        # 2. append to list\n",
    "        if found == 0 or found == 1:\n",
    "            gpu.append(found)\n",
    "        else:\n",
    "            print(\"Problem with\", found, \"at index\", i)\n",
    "            gpu.append(-100) \n",
    "\n",
    "    # make it a new column\n",
    "    df['gpu'] = gpu  \n",
    "    del gpu\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu  \n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     0    \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     0    "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "df = extract_gpu_to_new_col()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-7\n",
    "Create two new columns. One is named `pe`. Another one is `slot`. In the `category` field, look for the `-pe` data, e.g. `-pe single 1`. In this case, put the `single` (string) in the new `pe` column, and the value `1` (integer) in the new `slot` column.\n",
    "\n",
    "If no `pe` data is found in the `category` field, enter `none` (string) for the `pe` column, and `1` (int) for the `slot` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_pe_and_slot_to_new_cols():\n",
    "    \"\"\"This function extracts 2 values from the category column and adds them\n",
    "    to 2 new columns.\"\"\"\n",
    "\n",
    "    pe = []\n",
    "    slot = []\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "#         print(j)  # Testing\n",
    "        \n",
    "        # 1. extract the `pe` and `slot` data\n",
    "        try:\n",
    "#             found = re.search('-pe\\s(\\w+\\*?)\\s(\\d+)', j).groups()  # THIS MISSES -pe * 8\n",
    "            found = re.search('-pe\\s(\\w*\\*?)\\s(\\d+)', j).groups()  # NEED TO MATCH -pe * 8\n",
    "#             print(found[0], found[1], found[3])  # IndexError: tuple index out of range \n",
    "#             print('index', i, ':', found, end=' --> ')  # Testing            \n",
    "        except AttributeError:\n",
    "            found = ('none', 1)  # -pe is 'none', slot is 1 (slot is always 1 if not specified)\n",
    "#             print('index', i, ':', found, end=' --> ')  # Testing\n",
    "\n",
    "        # 2a. found[0] is pe. Append to list\n",
    "        if (found[0] == 'single' or found[0] == 'shared' or \n",
    "            found[0] == 'dc*' or found[0] == 'node*' or\n",
    "            found[0] == 'matlab' or found[0] == '*'):\n",
    "#             print(found[0])  # testing\n",
    "            pe.append(found[0])\n",
    "        elif found[0] == 'none':\n",
    "#             print(found[0])  # testing\n",
    "            pe.append(found[0])\n",
    "        else:  # doing this to catch any other values I didn't see\n",
    "#             print(found[0])  # testing\n",
    "            print(\"New pe value --> \", found[0], \" <-- at index\", i)\n",
    "            pe.append(found[0])\n",
    "        \n",
    "        # 2b. found[1] is slot. Append to list\n",
    "        if isinstance(found[1], (int, float)):\n",
    "#             print('slot value is numeric:', found[1])  # TESTING\n",
    "            slot.append(int(found[1]))\n",
    "#             print('numeric slot value appended as float:', found[1])  # TESTING\n",
    "        elif not isinstance(found[1], (int, float)):  # num may be formatted as string\n",
    "#             print('slot value is not numeric:', found[1])  # TESTING\n",
    "            try:\n",
    "#                 print('string (not numeric) slot value appended as float:', found[1])  # TESTING\n",
    "                slot.append(int(found[1])) \n",
    "            except:\n",
    "                slot.append(found[1])\n",
    "#                 print('string slot value appended as string:', found[1])  # TESTING\n",
    "        else:\n",
    "#             print(1)\n",
    "            print(\"Problem with slot --> \", found[1], \" <-- at index\", i)\n",
    "            slot.append(int(1))\n",
    "\n",
    "    # make new columns\n",
    "    df['pe'] = pe\n",
    "    df['slot'] = slot\n",
    "    del pe, slot\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `pe` and `slot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1     \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     0    single  1     \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     0    single  1     "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "df = extract_pe_and_slot_to_new_cols()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-8\n",
    "Create a new column `campus`. In the `category` field, if the value following `-U` is `campus`, set the value to `1` (integer). Otherwise, set it to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_campus_to_new_col():\n",
    "    \"\"\"This function extracts a value from the category column and adds it\n",
    "    to a new column.\"\"\"\n",
    "\n",
    "    campus = []\n",
    "\n",
    "    for i,j in enumerate(df.category):\n",
    "#         print(j)  # Testing\n",
    "        \n",
    "        # 1. extract the `campus` data\n",
    "        try:\n",
    "            found = re.search('(-U\\scampus)', j).group(1)\n",
    "#             print('index', i, ':', found, end=' --> ')  # Testing\n",
    "            found = 1\n",
    "        except AttributeError:\n",
    "            found = 0\n",
    "#             print('index', i, ':', found, end=' --> ')  # Testing\n",
    "\n",
    "        # 2. append to list\n",
    "        if isinstance(found, (int)):\n",
    "            campus.append(found)\n",
    "        else:  \n",
    "#             print(found[0])\n",
    "            print(\"Problem with campus\", found, \"at index\", i)\n",
    "            campus.append(found)\n",
    "\n",
    "    # make new column\n",
    "    df['campus'] = campus\n",
    "    del campus\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `campus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>category</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>-U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number  \\\n",
       "0  0       0            single     1      1338          \n",
       "1  0       0            single     1      55696         \n",
       "2  0       0            single     1      1368          \n",
       "\n",
       "                                                                  category  \\\n",
       "0  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "1  -U gpu,yxing -u yidazhan -l h_data=4G,h_rt=21600,h_vmem=4G -pe single 1   \n",
       "2  -U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1      \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \\\n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     0    single  1      \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "\n",
       "   campus  \n",
       "0  1       \n",
       "1  0       \n",
       "2  1       "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop = []  # reinitialize var\n",
    "\n",
    "df = extract_campus_to_new_col()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        df:    2.3GB\n",
      "       _64:   53.0MB\n",
      "      _i43:   12.8KB\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 11586 KB\n",
    "\n",
    "check_variable_sizes(locals().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380407</td>\n",
       "      <td>1538380818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>1538084286</td>\n",
       "      <td>1538378678</td>\n",
       "      <td>1538380842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>1538237029</td>\n",
       "      <td>1538380722</td>\n",
       "      <td>1538380856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number  submission_time  start_time    end_time  \\\n",
       "0  sudip  stevendu  3912841     1538237029       1538380407  1538380818   \n",
       "1  yxing  yidazhan  3902779     1538084286       1538378678  1538380842   \n",
       "2  sudip  stevendu  3912841     1538237029       1538380722  1538380856   \n",
       "\n",
       "   failed  exit_status granted_pe  slots  task_number       maxvmem  h_data  \\\n",
       "0  0       0            single     1      1338         4.040196e+09  4.0      \n",
       "1  0       0            single     1      55696        6.098657e+08  4.0      \n",
       "2  0       0            single     1      1368         3.326935e+09  4.0      \n",
       "\n",
       "   h_rt  highp  exclusive  h_vmem  gpu      pe  slot  campus  \n",
       "0  24.0  0      0          4.0     0    single  1     1       \n",
       "1  6.0   0      0          4.0     0    single  1     0       \n",
       "2  24.0  0      0          4.0     0    single  1     1       "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete category column\n",
    "del df['category']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        df:    1.7GB\n",
      "       _64:   53.0MB\n",
      "      _i43:   12.8KB\n"
     ]
    }
   ],
   "source": [
    "# Assign2.ipynb 11593 KB\n",
    "\n",
    "check_variable_sizes(locals().items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "The raw data in the `start_time`, `end_time` and `submission_time` are the UNIX epoch time. **Convert the data strings to Pandas (or Python) data objects.** The **`Timestamp` function** in Pandas can do this easily. See its documentation for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, drop any rows with '0' Unix epoch times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_droplog) 0\n",
      "(4580077, 21)\n",
      "(4579896, 21)\n",
      "(4568535, 21)\n",
      "(4568535, 21)\n",
      "len(df_droplog) 11542\n"
     ]
    }
   ],
   "source": [
    "print('len(df_droplog)', len(df_droplog))\n",
    "\n",
    "# Can I update df_droplog w/o using record_df_droplog fx ?? Is this better way?\n",
    "print(df.shape)\n",
    "df_droplog = df_droplog.append(df[df.submission_time == 0])\n",
    "df = df[df.submission_time != 0]\n",
    "\n",
    "print(df.shape)\n",
    "df_droplog = df_droplog.append(df[df.start_time == 0])\n",
    "df = df[df.start_time != 0] \n",
    "\n",
    "print(df.shape)\n",
    "df_droplog = df_droplog.append(df[df.end_time == 0])\n",
    "df = df[df.end_time != 0] \n",
    "\n",
    "print(df.shape)\n",
    "print('len(df_droplog)', len(df_droplog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^^^ df_droplog should not be zero to start. \n",
    "- Look at how it's working here and replicat above\n",
    "\n",
    "**FIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_unix_epoch_to_Timestamp():\n",
    "    \"\"\"This function converts Python strings that represent UNIX epoch\n",
    "    time to Pandas `Timestamp` objects.\"\"\"\n",
    "    \n",
    "    # Use `pd.Timestamp` or `pd.to_datetime` to convert the int time data values\n",
    "    # to Pandas (Python) data objects.\n",
    "\n",
    "    print('Before:', type(df.start_time[0]))  # CAN I CHECK TYPE OF ALL ELEMENTS AT ONCE???\n",
    "    \n",
    "    # check that row 1 values are np.int64\n",
    "    # WOULD BE BETTER TO CHECK IF **ALL** COL VALS ARE INT64\n",
    "    # COULD CHECK EACH ROW BEFORE CONVERT, CREATE LIST OF PROBLEMS.\n",
    "    if (isinstance(df.start_time[0], np.int64) and \n",
    "        isinstance(df.end_time[0], np.int64) and\n",
    "        isinstance(df.submission_time[0], np.int64)):\n",
    "        # overwrite int values with Timestamp values\n",
    "        df.start_time = pd.to_datetime(df.start_time, unit = 's')\n",
    "        df.end_time = pd.to_datetime(df.end_time, unit = 's')\n",
    "        df.submission_time = pd.to_datetime(df.submission_time, unit = 's')\n",
    "    elif (isinstance(df.start_time[0], pd._libs.tslib.Timestamp) and \n",
    "          isinstance(df.end_time[0], pd._libs.tslib.Timestamp) and\n",
    "          isinstance(df.submission_time[0], pd._libs.tslib.Timestamp)):\n",
    "        exit()  # exit if block if values are already Timestamps\n",
    "    else:\n",
    "        print(\"What data type is the unix epoch time in?\")\n",
    "        # CREATE LIST OF BAD VALUES\n",
    "        \n",
    "    print('After:', type(df.start_time[0]))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <class 'numpy.int64'>\n",
      "After: <class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "df = convert_unix_epoch_to_Timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:53:27</td>\n",
       "      <td>2018-10-01 08:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>2018-09-27 21:38:06</td>\n",
       "      <td>2018-10-01 07:24:38</td>\n",
       "      <td>2018-10-01 08:00:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:58:42</td>\n",
       "      <td>2018-10-01 08:00:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number     submission_time          start_time  \\\n",
       "0  sudip  stevendu  3912841    2018-09-29 16:03:49 2018-10-01 07:53:27   \n",
       "1  yxing  yidazhan  3902779    2018-09-27 21:38:06 2018-10-01 07:24:38   \n",
       "2  sudip  stevendu  3912841    2018-09-29 16:03:49 2018-10-01 07:58:42   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:00:18  0       0            single     1      1338          \n",
       "1 2018-10-01 08:00:42  0       0            single     1      55696         \n",
       "2 2018-10-01 08:00:56  0       0            single     1      1368          \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \\\n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     0    single  1      \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "\n",
       "   campus  \n",
       "0  1       \n",
       "1  0       \n",
       "2  1       "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "Create a new column `wait_time` whose value is the difference of `start_time - submission_time`.\n",
    "\n",
    "Create a new column `wtime` (short for “wall-clock time”) whose value is the difference of `end_time - start_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['wait_time'] = df.start_time - df.submission_time\n",
    "df['wtime'] = df.end_time - df.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:53:27</td>\n",
       "      <td>2018-10-01 08:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 15:49:38</td>\n",
       "      <td>00:06:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxing</td>\n",
       "      <td>yidazhan</td>\n",
       "      <td>3902779</td>\n",
       "      <td>2018-09-27 21:38:06</td>\n",
       "      <td>2018-10-01 07:24:38</td>\n",
       "      <td>2018-10-01 08:00:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>55696</td>\n",
       "      <td>6.098657e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3 days 09:46:32</td>\n",
       "      <td>00:36:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:58:42</td>\n",
       "      <td>2018-10-01 08:00:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>3.326935e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 15:54:53</td>\n",
       "      <td>00:02:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number     submission_time          start_time  \\\n",
       "0  sudip  stevendu  3912841    2018-09-29 16:03:49 2018-10-01 07:53:27   \n",
       "1  yxing  yidazhan  3902779    2018-09-27 21:38:06 2018-10-01 07:24:38   \n",
       "2  sudip  stevendu  3912841    2018-09-29 16:03:49 2018-10-01 07:58:42   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:00:18  0       0            single     1      1338          \n",
       "1 2018-10-01 08:00:42  0       0            single     1      55696         \n",
       "2 2018-10-01 08:00:56  0       0            single     1      1368          \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \\\n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "1  6.098657e+08  4.0     6.0   0      0          4.0     0    single  1      \n",
       "2  3.326935e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "\n",
       "   campus       wait_time    wtime  \n",
       "0  1      1 days 15:49:38 00:06:51  \n",
       "1  0      3 days 09:46:32 00:36:04  \n",
       "2  1      1 days 15:54:53 00:02:14  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "Identify duplicates and merge them. \n",
    "\n",
    "A “job” can be uniquely identified by the combination of “job_number”, “task_number” and “submission_time”. However, there are duplicated lines for some (job_number, task_number, submission_time) pairs. Identify them and remove the duplicates. For example, if you have:\n",
    "```\n",
    "job_number task_number submission_time      end_time ...\n",
    "10            1          2018-10-03          ...\n",
    "10            1          2018-10-03          ...\n",
    "10            1          2018-10-03          ...\n",
    "13            1          2018-10-04          ...\n",
    "```\n",
    "\n",
    "The two duplicated lines with (jobnumber, task)=(10,1) should be merged. After the merge, you should have something like:\n",
    "```\n",
    "job_number task_number submission_time      end_time ...\n",
    "10            1        2018-10-03          ...\n",
    "13            1        2018-10-04          ...```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows before drop duplicates: 4568535\n",
      "Milestone 7, record_df_droplog, index ?\n",
      "TEST record_df_droplog LINE 22: 0 Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "TEST record_df_droplog  LINE 22: 0 Empty DataFrame\n",
      "Columns: [group, owner, job_number, submission_time, start_time, end_time, failed, exit_status, granted_pe, slots, task_number, maxvmem, h_data, h_rt, highp, exclusive, h_vmem, gpu, pe, slot, campus, wait_time, wtime]\n",
      "Index: []\n",
      "Milestone 8, record_df_droplog finished\n",
      "Num rows after drop duplicates: 4468051\n",
      "\n",
      "df_droplog.shape[0] 11542\n"
     ]
    }
   ],
   "source": [
    "df = drop_duplicate_rows(df, col_names=['job_number', 'task_number', 'submission_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8\n",
    "You may or may not find some values in `submission_time`, `start_time` or `end_time` contain dates before year 2018. Drop (delete) these rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SKIP. HANDLED IN STEP 5\n",
    "\n",
    "# # Programmatically, then visually, inspect bad dates\n",
    "\n",
    "# indexes_to_maybe_drop = []\n",
    "\n",
    "# indexes_to_maybe_drop = find_bad_Timestamps(indexes_to_maybe_drop)\n",
    "\n",
    "# for i,j in enumerate(indexes_to_maybe_drop):\n",
    "#     indexes_to_maybe_drop = [j[0]]\n",
    "\n",
    "# start_time -->  1970-01-01 00:00:00 at index 223\n",
    "# end_time -->  1970-01-01 00:00:00 at index 223\n",
    "# submission_time -->  1970-01-01 00:00:00 at index 4645\n",
    "# start_time -->  1970-01-01 00:00:00 at index 4645\n",
    "# end_time -->  1970-01-01 00:00:00 at index 4645\n",
    "# ...\n",
    "# submission_time -->  1970-01-01 00:00:00 at index 22038\n",
    "# start_time -->  1970-01-01 00:00:00 at index 22038\n",
    "# end_time -->  1970-01-01 00:00:00 at index 22038\n",
    "# cnt_submission_bad: 9 XXX\n",
    "# cnt_start_bad: 10 XXX\n",
    "# cnt_end_bad: 10 XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^ This takes a long time (~150 min).\n",
    "\n",
    "If I trust the function, would be faster not to print results for visual inspection. Or print only a sample of results. But the evaluation itself is costly. \n",
    "\n",
    "**Can it be written to be more efficient?**\n",
    "1. YES: Remove all unix epoch == 0 rows before convert to Timestamp. DONE\n",
    "1. What else???\n",
    "1. Skip this step since \"0\" times already removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indexes_to_maybe_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop_rows_with_bad_Timestamps(indexes_to_maybe_drop)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for bad dates again just to be sure we deleted the right rows\n",
    "\n",
    "# find_bad_Timestamps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "- Too much redundancy??? These checks are time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9\n",
    "Remove these columns that we will not need: `['category', 'qname', 'job_name', 'account', 'project']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'category' already removed\n",
    "# the others were never ingested to begin with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10\n",
    "If you have reached this step, congratulations, you **now have a clean data set ready for analysis**. The data set should have 23 columns:\n",
    "```\n",
    "['group', 'owner', 'job_number', 'submission_time', 'start_time',\n",
    "   'end_time', 'failed', 'exit_status', 'granted_pe', 'slots',\n",
    "   'task_number', 'maxvmem', 'h_data', 'h_rt', 'highp', 'exclusive',\n",
    "   'h_vmem', 'gpu', 'pe', 'slot', 'wait_time', 'wtime', 'campus']\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that df cols match list provided above\n",
    "\n",
    "should_have_cols = ['group', 'owner', 'job_number', 'submission_time', 'start_time',\n",
    "   'end_time', 'failed', 'exit_status', 'granted_pe', 'slots',\n",
    "   'task_number', 'maxvmem', 'h_data', 'h_rt', 'highp', 'exclusive',\n",
    "   'h_vmem', 'gpu', 'pe', 'slot', 'wait_time', 'wtime', 'campus']\n",
    "\n",
    "df.columns == should_have_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Last 3 cols don't match. Fix below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the data in `HDF5` format** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_hdf('accounting-2018-10_wk2.h5', key='df', mode='w')  \n",
    "\n",
    "# PerformanceWarning: \n",
    "# your performance may suffer as PyTables will pickle object types that it cannot\n",
    "# map directly to c-types [inferred_type->mixed,key->block3_values] \n",
    "# [items->['group', 'owner', 'granted_pe', 'h_vmem', 'pe']]\n",
    "#   return pytables.to_hdf(path_or_buf, key, self, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "- Performance (memory use, disk space, speed) is a key issue I have focussed on in this program.\n",
    "- What does the PerformanceWarning mean and what can/should I do in response?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11\n",
    "**Compare** the `HDF5` file you saved and the one from Week 1. Discuss your observations and their differences. If there are differences, how would you make yours closer (if not identical) to Week 1’s `HDF5` file. Or if you think yours is more correct or better, justify your version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your observations and their differences. If there are differences, how would you make yours closer (if not identical) to Week 1’s HDF5 file. Or if you think yours is more correct or better, justify your version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read week 1 H5 to df_1\n",
    "df_1 = pd.read_hdf('..\\\\wk1\\\\accounting-2018-10-deid.h5', 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make obvious which is the week 2 df, assign to df_2\n",
    "df_2 = df\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4468061 entries, 0 to 4580086\n",
      "Data columns (total 23 columns):\n",
      "group              object\n",
      "owner              object\n",
      "job_number         int64\n",
      "submission_time    datetime64[ns]\n",
      "start_time         datetime64[ns]\n",
      "end_time           datetime64[ns]\n",
      "failed             int64\n",
      "exit_status        int64\n",
      "granted_pe         object\n",
      "slots              int64\n",
      "task_number        int64\n",
      "maxvmem            float64\n",
      "h_data             float64\n",
      "h_rt               float64\n",
      "highp              int64\n",
      "exclusive          int64\n",
      "h_vmem             float64\n",
      "gpu                int64\n",
      "pe                 object\n",
      "slot               int64\n",
      "wait_time          timedelta64[ns]\n",
      "wtime              timedelta64[ns]\n",
      "campus             int64\n",
      "dtypes: datetime64[ns](3), float64(4), int64(10), object(4), timedelta64[ns](2)\n",
      "memory usage: 818.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4468051 entries, 0 to 4580086\n",
      "Data columns (total 23 columns):\n",
      "group              object\n",
      "owner              object\n",
      "job_number         int64\n",
      "submission_time    datetime64[ns]\n",
      "start_time         datetime64[ns]\n",
      "end_time           datetime64[ns]\n",
      "failed             int64\n",
      "exit_status        int64\n",
      "granted_pe         object\n",
      "slots              int64\n",
      "task_number        int64\n",
      "maxvmem            float64\n",
      "h_data             float64\n",
      "h_rt               float64\n",
      "highp              int64\n",
      "exclusive          int64\n",
      "h_vmem             float64\n",
      "gpu                int64\n",
      "pe                 object\n",
      "slot               int64\n",
      "campus             int64\n",
      "wait_time          timedelta64[ns]\n",
      "wtime              timedelta64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), int64(10), object(4), timedelta64[ns](2)\n",
      "memory usage: 818.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.info() == df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. `h5diff` comparison command:\n",
    "```\n",
    "$ h5diff -v accounting-2018-10_short_A.h5 accounting-2018-10_short_B.h5 > diff.txt\n",
    "```\n",
    "#### Output: \n",
    "- See diff.txt (uninterpretable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. File size\n",
    " - week1 h5: 787558 KB\n",
    " - week2 h5: 802682 KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. Compare column number, names, order, dtype\n",
    "- Example to set data type for a col: df1.Chr = df1.Chr.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2.columns) == len(df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns == df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Last 3 cols in diff order\n",
    "\n",
    "**Fix**:\n",
    "- Set df_1 cols to same order as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_1.reindex(columns=df_2.columns)\n",
    "all(df_2.columns == df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>u1</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:53:27</td>\n",
       "      <td>2018-10-01 08:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 15:49:38</td>\n",
       "      <td>00:06:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group owner  job_number     submission_time          start_time  \\\n",
       "0  g1    u1    3912841    2018-09-29 16:03:49 2018-10-01 07:53:27   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:00:18  0       0            single     1      1338          \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \\\n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "\n",
       "   campus       wait_time    wtime  \n",
       "0  1      1 days 15:49:38 00:06:51  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_1.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudip</td>\n",
       "      <td>stevendu</td>\n",
       "      <td>3912841</td>\n",
       "      <td>2018-09-29 16:03:49</td>\n",
       "      <td>2018-10-01 07:53:27</td>\n",
       "      <td>2018-10-01 08:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>4.040196e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 15:49:38</td>\n",
       "      <td>00:06:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     owner  job_number     submission_time          start_time  \\\n",
       "0  sudip  stevendu  3912841    2018-09-29 16:03:49 2018-10-01 07:53:27   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:00:18  0       0            single     1      1338          \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu      pe  slot  \\\n",
       "0  4.040196e+09  4.0     24.0  0      0          4.0     0    single  1      \n",
       "\n",
       "   campus       wait_time    wtime  \n",
       "0  1      1 days 15:49:38 00:06:51  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_2.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4468061, 23) (4468051, 23)\n"
     ]
    }
   ],
   "source": [
    "print(df_1.shape,df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['group', 'owner', 'job_number', 'submission_time', 'start_time',\n",
      "       'end_time', 'failed', 'exit_status', 'granted_pe', 'slots',\n",
      "       'task_number', 'maxvmem', 'h_data', 'h_rt', 'highp', 'exclusive',\n",
      "       'h_vmem', 'gpu', 'pe', 'slot', 'campus', 'wait_time', 'wtime'],\n",
      "      dtype='object') Index(['group', 'owner', 'job_number', 'submission_time', 'start_time',\n",
      "       'end_time', 'failed', 'exit_status', 'granted_pe', 'slots',\n",
      "       'task_number', 'maxvmem', 'h_data', 'h_rt', 'highp', 'exclusive',\n",
      "       'h_vmem', 'gpu', 'pe', 'slot', 'campus', 'wait_time', 'wtime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_1.columns, df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_df1_df2_col_types(verbose=False):\n",
    "    \"\"\"This function compares the type of each corresponding column pair in df1 \n",
    "    and df2. In silent mode (verbose=False), resuts are printed only for column \n",
    "    pairs with a type mismatch. If all column pairs match, nothing is printed. \n",
    "    In verbose mode, a message is printed for every column pair. Silent mode by \n",
    "    default.\"\"\"\n",
    "    \n",
    "    for i, (col1, col2) in enumerate(zip(df_1.columns, df_2.columns)):\n",
    "        if not type(col1) == type(col2):\n",
    "            print(type(col1), ':', col1, '|', type(col2), ':', col2)\n",
    "        else:\n",
    "            if verbose == True:\n",
    "                print('All is copacetic with', col1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_df1_df2_col_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the data types the same for parallel values in each df?  \n",
    "\n",
    "# 1. Create a sample list for each df\n",
    "df_1_types = []\n",
    "for i in np.arange(0, df_1.shape[0], 100000):\n",
    "    for col in df_1.columns:\n",
    "#         df_1_types.append(str(\"type df_1.col[i] \" + col + str(i) + \":\" + str(type(df_1[col][i]))))\n",
    "        df_1_types.append(col + \" \" + str(i) + \" \" + str(type(df_1[col][i])))\n",
    "\n",
    "df_2_types = []\n",
    "for i in np.arange(0, df_2.shape[0], 100000):\n",
    "    for col in df_2.columns:\n",
    "#         df_2_types.append(str(\"type df_2.col[i] \" + col + str(i) + \":\" + str(type(df_2[col][i]))))\n",
    "        df_2_types.append(col + \" \" + str(i) + \" \" + str(type(df_2[col][i])))\n",
    "        \n",
    "# 2. compare lists\n",
    "df_1_types == df_2_types\n",
    "\n",
    "# ^^^ YES, the data types are the same for this small sample of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the/any differences\n",
    "\n",
    "dfs_types_zip = zip(df_1_types, df_2_types)\n",
    "\n",
    "for t in dfs_types_zip:\n",
    "    if not t[0] == t[1]:  # print only pairs with differences\n",
    "        print(t)\n",
    "        \n",
    "# All differences fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (df_1): 4468061\n",
      "Rows (df_2): 4468051\n",
      "Rows +/-: -10\n"
     ]
    }
   ],
   "source": [
    "print('Rows (df_1):', df_1.shape[0])\n",
    "print('Rows (df_2):', df_2.shape[0])\n",
    "\n",
    "# Compare number of rows in df's\n",
    "print(\"Rows +/-:\", (df_1.shape[0] - df_2.shape[0]) * -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Hey, only 10 rows different! These could be the 10 rows I deleted in Step 4.1 above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. Compare uniq values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNIQUE values\n",
    "\n",
    "def print_unique_value_counts(df_1, df_2):\n",
    "    \n",
    "    # Print header\n",
    "\n",
    "    sp = ' '\n",
    "    h12 = 'WEEK 1 DF'\n",
    "    h13 = 'WEEK 2 DF'\n",
    "    h14 = 'WEEK 2 DIFF'\n",
    "    h21 = 'FEATURE/ATTRIBUTE'\n",
    "    h22 = '# UNIQ VALUES'\n",
    "    pos_neg = '+/-'\n",
    "    nl = '\\n'\n",
    "    rows = 'Rows'\n",
    "    df1_rows = df_1.shape[0]\n",
    "    df2_rows = df_2.shape[0]\n",
    "    diff = -1 * (df1_rows - df2_rows)\n",
    "    \n",
    "    print(f\"{sp :26}{h12 :<13} {h13 :<12} {h14 :<12}\")\n",
    "    print(f\"{h21 :<22} {h22 : <12} {h22 : <12} {pos_neg :^16} {nl}\")\n",
    "    print(f\" {rows :<22} {df1_rows :>10} {df2_rows :>15} {diff :>12}\")\n",
    "\n",
    "    # Compare the number of uniq values for each column in both dfs\n",
    "    for i,j in enumerate(df_1.columns):\n",
    "        #   col_name     uniq values      # uniq values\n",
    "#         print(f\"Hello, My name is {name :<10s} and I'm {age :>4d} years old.\")\n",
    "#         print(j, len(df_1[j].unique()), len(df_2[j].unique()))  # df['group'].unique()\n",
    "\n",
    "        df1_len_col_uniq = len(df_1[j].unique())\n",
    "        df2_len_col_uniq = len(df_2[j].unique())\n",
    "        diff = -1 * (df1_len_col_uniq - df2_len_col_uniq)\n",
    "\n",
    "        print(f\" {j :<20} {df1_len_col_uniq :>12}    {df2_len_col_uniq :>12} {diff :>12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          WEEK 1 DF     WEEK 2 DF    WEEK 2 DIFF \n",
      "FEATURE/ATTRIBUTE      # UNIQ VALUES # UNIQ VALUES       +/-        \n",
      "\n",
      " Rows                      4468061         4468051          -10\n",
      " group                         203             203            0\n",
      " owner                         699             699            0\n",
      " job_number                 184688          184678          -10\n",
      " submission_time            260016          260007           -9\n",
      " start_time                 469299          469291           -8\n",
      " end_time                  1347025         1347361          336\n",
      " failed                          7               7            0\n",
      " exit_status                    28              27           -1\n",
      " granted_pe                     17              17            0\n",
      " slots                          43              43            0\n",
      " task_number                156538          156538            0\n",
      " maxvmem                    397528          397528            0\n",
      " h_data                        151             143           -8\n",
      " h_rt                          172             172            0\n",
      " highp                           2               2            0\n",
      " exclusive                       2               2            0\n",
      " h_vmem                        130             130            0\n",
      " gpu                             2               2            0\n",
      " pe                              7               7            0\n",
      " slot                           43              43            0\n",
      " campus                          2               2            0\n",
      " wait_time                  188952          188953            1\n",
      " wtime                       54571           54579            8\n"
     ]
    }
   ],
   "source": [
    "print_unique_value_counts(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID the actual values that are \"extra\" or \"missing\" for these features**:\n",
    "```\n",
    "                            WEEK 1 DF       WEEK 2 DF    WEEK 2 DIFF \n",
    "FEATURE                  # UNIQ VALUES   # UNIQ VALUES       +/-\n",
    "\n",
    " job_number                 184688          184678          -10\n",
    " submission_time            260016          260007           -9\n",
    " start_time                 469299          469291           -8\n",
    " end_time                  1347025         1347361          336\n",
    " exit_status                    28              27           -1\n",
    " h_data                        151             143           -8\n",
    " wait_time                  188952          188953            1\n",
    " wtime                       54571           54579            8\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['job_number', 'submission_time', 'start_time', 'end_time', \n",
    "          'exit_status', 'h_data', 'wait_time', 'wtime']\n",
    "\n",
    "def print_extra_missing_values_in_df2(fields):\n",
    "    for i,field in enumerate(fields):\n",
    "\n",
    "        A = set(df_1[field].unique())\n",
    "        B = set(df_2[field].unique())\n",
    "\n",
    "        df2_extra = sorted(B.difference(A))\n",
    "        df2_missing = sorted(A.difference(B))\n",
    "\n",
    "        print(fields[i] + ':')\n",
    "        print('   df2_extra (', len(df2_extra), '):', df2_extra)\n",
    "        print('\\n')\n",
    "        print('   df2_missing (', len(df2_missing), '):', df2_missing)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. job_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_number:\n",
      "   df2_extra ( 0 ): []\n",
      "\n",
      "\n",
      "   df2_missing ( 10 ): [3937422, 3937432, 3939666, 3971238, 3971239, 4008009, 4010169, 4058455, 4065298, 4066046]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Yes, these 10 job numbers were deleted when I dropped errant `h_data` values in Step 4.1 b/c they were too small to be KB values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. submission_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_time:\n",
      "   df2_extra ( 0 ): []\n",
      "\n",
      "\n",
      "   df2_missing ( 9 ): [numpy.datetime64('2018-10-03T23:45:59.000000000'), numpy.datetime64('2018-10-03T23:47:54.000000000'), numpy.datetime64('2018-10-04T05:22:22.000000000'), numpy.datetime64('2018-10-08T23:18:08.000000000'), numpy.datetime64('2018-10-08T23:18:35.000000000'), numpy.datetime64('2018-10-15T21:58:26.000000000'), numpy.datetime64('2018-10-16T03:45:40.000000000'), numpy.datetime64('2018-10-23T20:08:47.000000000'), numpy.datetime64('2018-10-24T00:03:56.000000000')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Yes, these 9 submission times were deleted when I dropped errant h_data values in Step 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time:\n",
      "   df2_extra ( 509 ): [numpy.datetime64('2018-10-01T01:24:41.000000000'), numpy.datetime64('2018-10-01T06:09:34.000000000'), numpy.datetime64('2018-10-01T10:18:56.000000000'), numpy.datetime64('2018-10-01T11:03:59.000000000'), numpy.datetime64('2018-10-01T12:26:46.000000000'), numpy.datetime64('2018-10-01T18:08:35.000000000'), numpy.datetime64('2018-10-01T22:05:54.000000000'), numpy.datetime64('2018-10-01T22:36:33.000000000'), numpy.datetime64('2018-10-02T01:24:30.000000000'), numpy.datetime64('2018-10-02T02:46:15.000000000'), numpy.datetime64('2018-10-02T04:23:00.000000000'), numpy.datetime64('2018-10-02T08:10:58.000000000'), numpy.datetime64('2018-10-02T08:53:45.000000000'), numpy.datetime64('2018-10-02T10:01:26.000000000'), numpy.datetime64('2018-10-03T00:39:11.000000000'), numpy.datetime64('2018-10-03T03:10:49.000000000'), numpy.datetime64('2018-10-03T12:02:32.000000000'), numpy.datetime64('2018-10-03T18:18:09.000000000'), numpy.datetime64('2018-10-03T22:47:49.000000000'), numpy.datetime64('2018-10-03T22:59:42.000000000'), numpy.datetime64('2018-10-04T01:13:19.000000000'), numpy.datetime64('2018-10-04T03:34:27.000000000'), numpy.datetime64('2018-10-04T03:40:40.000000000'), numpy.datetime64('2018-10-04T05:00:42.000000000'), numpy.datetime64('2018-10-04T06:34:40.000000000'), numpy.datetime64('2018-10-04T07:54:40.000000000'), numpy.datetime64('2018-10-04T08:03:16.000000000'), numpy.datetime64('2018-10-04T08:20:59.000000000'), numpy.datetime64('2018-10-04T08:34:03.000000000'), numpy.datetime64('2018-10-04T12:45:38.000000000'), numpy.datetime64('2018-10-04T13:54:09.000000000'), numpy.datetime64('2018-10-04T18:51:50.000000000'), numpy.datetime64('2018-10-05T02:21:41.000000000'), numpy.datetime64('2018-10-05T04:12:43.000000000'), numpy.datetime64('2018-10-05T07:01:35.000000000'), numpy.datetime64('2018-10-05T10:31:17.000000000'), numpy.datetime64('2018-10-05T10:42:19.000000000'), numpy.datetime64('2018-10-05T18:39:40.000000000'), numpy.datetime64('2018-10-05T20:54:24.000000000'), numpy.datetime64('2018-10-05T20:56:55.000000000'), numpy.datetime64('2018-10-05T21:32:19.000000000'), numpy.datetime64('2018-10-06T00:22:34.000000000'), numpy.datetime64('2018-10-06T02:04:01.000000000'), numpy.datetime64('2018-10-06T02:04:59.000000000'), numpy.datetime64('2018-10-06T04:50:54.000000000'), numpy.datetime64('2018-10-06T05:07:57.000000000'), numpy.datetime64('2018-10-06T05:21:49.000000000'), numpy.datetime64('2018-10-06T05:23:35.000000000'), numpy.datetime64('2018-10-06T05:29:38.000000000'), numpy.datetime64('2018-10-06T05:29:41.000000000'), numpy.datetime64('2018-10-06T06:24:45.000000000'), numpy.datetime64('2018-10-06T16:35:24.000000000'), numpy.datetime64('2018-10-06T18:47:01.000000000'), numpy.datetime64('2018-10-06T22:21:49.000000000'), numpy.datetime64('2018-10-07T02:24:43.000000000'), numpy.datetime64('2018-10-07T02:40:56.000000000'), numpy.datetime64('2018-10-07T03:03:04.000000000'), numpy.datetime64('2018-10-07T03:05:45.000000000'), numpy.datetime64('2018-10-07T03:24:16.000000000'), numpy.datetime64('2018-10-07T11:16:22.000000000'), numpy.datetime64('2018-10-07T13:16:55.000000000'), numpy.datetime64('2018-10-07T13:25:16.000000000'), numpy.datetime64('2018-10-07T16:50:01.000000000'), numpy.datetime64('2018-10-07T21:17:49.000000000'), numpy.datetime64('2018-10-08T00:08:34.000000000'), numpy.datetime64('2018-10-08T04:41:54.000000000'), numpy.datetime64('2018-10-08T05:27:47.000000000'), numpy.datetime64('2018-10-08T05:33:15.000000000'), numpy.datetime64('2018-10-08T05:38:43.000000000'), numpy.datetime64('2018-10-08T05:57:57.000000000'), numpy.datetime64('2018-10-08T05:58:00.000000000'), numpy.datetime64('2018-10-08T06:01:19.000000000'), numpy.datetime64('2018-10-08T06:07:44.000000000'), numpy.datetime64('2018-10-08T06:10:05.000000000'), numpy.datetime64('2018-10-08T06:10:52.000000000'), numpy.datetime64('2018-10-08T06:13:00.000000000'), numpy.datetime64('2018-10-08T06:17:38.000000000'), numpy.datetime64('2018-10-08T06:18:07.000000000'), numpy.datetime64('2018-10-08T06:22:15.000000000'), numpy.datetime64('2018-10-08T06:53:35.000000000'), numpy.datetime64('2018-10-08T08:32:41.000000000'), numpy.datetime64('2018-10-08T08:37:34.000000000'), numpy.datetime64('2018-10-08T08:39:27.000000000'), numpy.datetime64('2018-10-08T10:01:41.000000000'), numpy.datetime64('2018-10-08T10:02:09.000000000'), numpy.datetime64('2018-10-08T13:25:34.000000000'), numpy.datetime64('2018-10-08T13:52:11.000000000'), numpy.datetime64('2018-10-08T15:55:17.000000000'), numpy.datetime64('2018-10-08T16:02:13.000000000'), numpy.datetime64('2018-10-08T23:22:32.000000000'), numpy.datetime64('2018-10-09T01:45:38.000000000'), numpy.datetime64('2018-10-09T02:03:44.000000000'), numpy.datetime64('2018-10-09T02:03:46.000000000'), numpy.datetime64('2018-10-09T03:04:39.000000000'), numpy.datetime64('2018-10-09T03:07:31.000000000'), numpy.datetime64('2018-10-09T04:36:03.000000000'), numpy.datetime64('2018-10-09T04:44:27.000000000'), numpy.datetime64('2018-10-09T06:34:54.000000000'), numpy.datetime64('2018-10-09T07:51:34.000000000'), numpy.datetime64('2018-10-09T09:34:49.000000000'), numpy.datetime64('2018-10-09T10:01:24.000000000'), numpy.datetime64('2018-10-09T11:56:34.000000000'), numpy.datetime64('2018-10-09T12:34:39.000000000'), numpy.datetime64('2018-10-09T15:34:50.000000000'), numpy.datetime64('2018-10-09T15:43:13.000000000'), numpy.datetime64('2018-10-09T16:36:04.000000000'), numpy.datetime64('2018-10-09T16:36:36.000000000'), numpy.datetime64('2018-10-09T17:01:12.000000000'), numpy.datetime64('2018-10-09T18:44:46.000000000'), numpy.datetime64('2018-10-09T20:40:45.000000000'), numpy.datetime64('2018-10-09T21:59:39.000000000'), numpy.datetime64('2018-10-09T22:02:52.000000000'), numpy.datetime64('2018-10-09T23:33:09.000000000'), numpy.datetime64('2018-10-10T00:56:33.000000000'), numpy.datetime64('2018-10-10T01:20:40.000000000'), numpy.datetime64('2018-10-10T01:21:08.000000000'), numpy.datetime64('2018-10-10T03:19:54.000000000'), numpy.datetime64('2018-10-10T04:14:09.000000000'), numpy.datetime64('2018-10-10T05:26:19.000000000'), numpy.datetime64('2018-10-10T05:48:54.000000000'), numpy.datetime64('2018-10-10T09:44:36.000000000'), numpy.datetime64('2018-10-10T12:58:42.000000000'), numpy.datetime64('2018-10-11T05:46:19.000000000'), numpy.datetime64('2018-10-11T06:22:46.000000000'), numpy.datetime64('2018-10-11T07:39:23.000000000'), numpy.datetime64('2018-10-11T09:46:22.000000000'), numpy.datetime64('2018-10-11T13:01:45.000000000'), numpy.datetime64('2018-10-11T14:10:16.000000000'), numpy.datetime64('2018-10-11T14:50:53.000000000'), numpy.datetime64('2018-10-11T17:57:28.000000000'), numpy.datetime64('2018-10-11T18:28:54.000000000'), numpy.datetime64('2018-10-11T19:11:53.000000000'), numpy.datetime64('2018-10-11T20:05:26.000000000'), numpy.datetime64('2018-10-11T20:34:29.000000000'), numpy.datetime64('2018-10-11T22:45:09.000000000'), numpy.datetime64('2018-10-11T23:10:34.000000000'), numpy.datetime64('2018-10-12T01:39:42.000000000'), numpy.datetime64('2018-10-12T05:00:58.000000000'), numpy.datetime64('2018-10-12T11:15:38.000000000'), numpy.datetime64('2018-10-12T12:38:11.000000000'), numpy.datetime64('2018-10-12T16:30:01.000000000'), numpy.datetime64('2018-10-12T19:00:23.000000000'), numpy.datetime64('2018-10-12T20:17:45.000000000'), numpy.datetime64('2018-10-12T20:33:38.000000000'), numpy.datetime64('2018-10-13T01:38:30.000000000'), numpy.datetime64('2018-10-13T02:47:06.000000000'), numpy.datetime64('2018-10-13T07:49:31.000000000'), numpy.datetime64('2018-10-13T12:18:19.000000000'), numpy.datetime64('2018-10-13T17:52:26.000000000'), numpy.datetime64('2018-10-13T18:44:02.000000000'), numpy.datetime64('2018-10-13T19:00:04.000000000'), numpy.datetime64('2018-10-14T01:53:59.000000000'), numpy.datetime64('2018-10-14T02:42:19.000000000'), numpy.datetime64('2018-10-14T03:24:33.000000000'), numpy.datetime64('2018-10-14T06:51:28.000000000'), numpy.datetime64('2018-10-14T09:03:40.000000000'), numpy.datetime64('2018-10-14T14:26:22.000000000'), numpy.datetime64('2018-10-14T14:53:36.000000000'), numpy.datetime64('2018-10-14T16:23:13.000000000'), numpy.datetime64('2018-10-14T18:06:31.000000000'), numpy.datetime64('2018-10-14T23:57:47.000000000'), numpy.datetime64('2018-10-15T09:01:29.000000000'), numpy.datetime64('2018-10-15T12:02:44.000000000'), numpy.datetime64('2018-10-15T17:06:07.000000000'), numpy.datetime64('2018-10-15T20:40:56.000000000'), numpy.datetime64('2018-10-16T00:24:38.000000000'), numpy.datetime64('2018-10-16T02:29:12.000000000'), numpy.datetime64('2018-10-16T02:52:21.000000000'), numpy.datetime64('2018-10-16T04:05:27.000000000'), numpy.datetime64('2018-10-16T09:03:03.000000000'), numpy.datetime64('2018-10-16T15:04:11.000000000'), numpy.datetime64('2018-10-16T19:57:25.000000000'), numpy.datetime64('2018-10-16T21:38:27.000000000'), numpy.datetime64('2018-10-16T22:49:32.000000000'), numpy.datetime64('2018-10-16T23:38:23.000000000'), numpy.datetime64('2018-10-16T23:49:52.000000000'), numpy.datetime64('2018-10-17T00:27:19.000000000'), numpy.datetime64('2018-10-17T01:32:16.000000000'), numpy.datetime64('2018-10-17T04:54:36.000000000'), numpy.datetime64('2018-10-17T05:44:54.000000000'), numpy.datetime64('2018-10-17T05:45:05.000000000'), numpy.datetime64('2018-10-17T05:50:05.000000000'), numpy.datetime64('2018-10-17T06:12:50.000000000'), numpy.datetime64('2018-10-17T06:13:54.000000000'), numpy.datetime64('2018-10-17T06:31:31.000000000'), numpy.datetime64('2018-10-17T06:53:25.000000000'), numpy.datetime64('2018-10-17T08:00:21.000000000'), numpy.datetime64('2018-10-17T09:43:48.000000000'), numpy.datetime64('2018-10-17T10:15:45.000000000'), numpy.datetime64('2018-10-17T10:23:52.000000000'), numpy.datetime64('2018-10-17T12:27:15.000000000'), numpy.datetime64('2018-10-17T15:53:07.000000000'), numpy.datetime64('2018-10-17T18:28:43.000000000'), numpy.datetime64('2018-10-17T20:10:30.000000000'), numpy.datetime64('2018-10-18T05:50:05.000000000'), numpy.datetime64('2018-10-18T08:14:44.000000000'), numpy.datetime64('2018-10-18T11:07:48.000000000'), numpy.datetime64('2018-10-18T14:26:29.000000000'), numpy.datetime64('2018-10-18T17:10:40.000000000'), numpy.datetime64('2018-10-18T19:00:11.000000000'), numpy.datetime64('2018-10-18T22:08:39.000000000'), numpy.datetime64('2018-10-18T22:33:22.000000000'), numpy.datetime64('2018-10-19T01:32:44.000000000'), numpy.datetime64('2018-10-19T06:40:46.000000000'), numpy.datetime64('2018-10-19T06:47:19.000000000'), numpy.datetime64('2018-10-19T10:01:27.000000000'), numpy.datetime64('2018-10-19T10:38:10.000000000'), numpy.datetime64('2018-10-19T13:33:56.000000000'), numpy.datetime64('2018-10-19T14:56:57.000000000'), numpy.datetime64('2018-10-19T16:14:58.000000000'), numpy.datetime64('2018-10-19T17:38:08.000000000'), numpy.datetime64('2018-10-19T19:40:06.000000000'), numpy.datetime64('2018-10-19T19:49:42.000000000'), numpy.datetime64('2018-10-19T21:18:22.000000000'), numpy.datetime64('2018-10-19T21:41:33.000000000'), numpy.datetime64('2018-10-19T21:44:28.000000000'), numpy.datetime64('2018-10-19T22:29:06.000000000'), numpy.datetime64('2018-10-19T23:21:09.000000000'), numpy.datetime64('2018-10-20T01:01:38.000000000'), numpy.datetime64('2018-10-20T01:06:20.000000000'), numpy.datetime64('2018-10-20T01:23:43.000000000'), numpy.datetime64('2018-10-20T02:06:43.000000000'), numpy.datetime64('2018-10-20T02:17:57.000000000'), numpy.datetime64('2018-10-20T02:36:49.000000000'), numpy.datetime64('2018-10-20T03:31:55.000000000'), numpy.datetime64('2018-10-20T03:55:26.000000000'), numpy.datetime64('2018-10-20T04:04:18.000000000'), numpy.datetime64('2018-10-20T04:10:30.000000000'), numpy.datetime64('2018-10-20T04:44:20.000000000'), numpy.datetime64('2018-10-20T05:55:14.000000000'), numpy.datetime64('2018-10-20T06:51:45.000000000'), numpy.datetime64('2018-10-20T08:47:56.000000000'), numpy.datetime64('2018-10-20T09:32:49.000000000'), numpy.datetime64('2018-10-20T10:43:13.000000000'), numpy.datetime64('2018-10-20T14:38:56.000000000'), numpy.datetime64('2018-10-20T15:26:10.000000000'), numpy.datetime64('2018-10-20T16:01:29.000000000'), numpy.datetime64('2018-10-20T16:19:22.000000000'), numpy.datetime64('2018-10-20T16:30:39.000000000'), numpy.datetime64('2018-10-20T16:37:45.000000000'), numpy.datetime64('2018-10-20T17:04:49.000000000'), numpy.datetime64('2018-10-20T18:04:46.000000000'), numpy.datetime64('2018-10-20T19:00:35.000000000'), numpy.datetime64('2018-10-20T19:07:19.000000000'), numpy.datetime64('2018-10-20T19:55:20.000000000'), numpy.datetime64('2018-10-20T21:03:31.000000000'), numpy.datetime64('2018-10-20T21:08:59.000000000'), numpy.datetime64('2018-10-20T23:06:19.000000000'), numpy.datetime64('2018-10-21T00:26:25.000000000'), numpy.datetime64('2018-10-21T04:35:37.000000000'), numpy.datetime64('2018-10-21T06:08:58.000000000'), numpy.datetime64('2018-10-21T08:06:05.000000000'), numpy.datetime64('2018-10-21T09:36:41.000000000'), numpy.datetime64('2018-10-21T09:46:45.000000000'), numpy.datetime64('2018-10-21T10:57:24.000000000'), numpy.datetime64('2018-10-21T15:15:11.000000000'), numpy.datetime64('2018-10-21T20:10:43.000000000'), numpy.datetime64('2018-10-22T02:23:17.000000000'), numpy.datetime64('2018-10-22T05:16:36.000000000'), numpy.datetime64('2018-10-22T05:41:22.000000000'), numpy.datetime64('2018-10-22T07:06:31.000000000'), numpy.datetime64('2018-10-22T07:59:15.000000000'), numpy.datetime64('2018-10-22T13:41:33.000000000'), numpy.datetime64('2018-10-22T14:48:15.000000000'), numpy.datetime64('2018-10-22T14:59:47.000000000'), numpy.datetime64('2018-10-22T18:10:35.000000000'), numpy.datetime64('2018-10-22T19:26:18.000000000'), numpy.datetime64('2018-10-22T21:42:16.000000000'), numpy.datetime64('2018-10-22T23:46:17.000000000'), numpy.datetime64('2018-10-23T02:13:00.000000000'), numpy.datetime64('2018-10-23T03:52:08.000000000'), numpy.datetime64('2018-10-23T04:43:30.000000000'), numpy.datetime64('2018-10-23T09:11:46.000000000'), numpy.datetime64('2018-10-23T09:49:37.000000000'), numpy.datetime64('2018-10-23T09:58:27.000000000'), numpy.datetime64('2018-10-23T10:17:08.000000000'), numpy.datetime64('2018-10-23T12:39:44.000000000'), numpy.datetime64('2018-10-23T14:50:27.000000000'), numpy.datetime64('2018-10-23T18:30:19.000000000'), numpy.datetime64('2018-10-23T19:07:53.000000000'), numpy.datetime64('2018-10-23T20:17:12.000000000'), numpy.datetime64('2018-10-23T21:25:00.000000000'), numpy.datetime64('2018-10-23T23:21:24.000000000'), numpy.datetime64('2018-10-24T00:23:59.000000000'), numpy.datetime64('2018-10-24T00:25:14.000000000'), numpy.datetime64('2018-10-24T00:48:16.000000000'), numpy.datetime64('2018-10-24T00:49:58.000000000'), numpy.datetime64('2018-10-24T00:55:55.000000000'), numpy.datetime64('2018-10-24T01:11:37.000000000'), numpy.datetime64('2018-10-24T02:56:58.000000000'), numpy.datetime64('2018-10-24T03:36:17.000000000'), numpy.datetime64('2018-10-24T04:32:03.000000000'), numpy.datetime64('2018-10-24T05:11:24.000000000'), numpy.datetime64('2018-10-24T06:34:51.000000000'), numpy.datetime64('2018-10-24T07:58:57.000000000'), numpy.datetime64('2018-10-24T09:02:44.000000000'), numpy.datetime64('2018-10-24T09:18:52.000000000'), numpy.datetime64('2018-10-24T11:42:39.000000000'), numpy.datetime64('2018-10-24T12:04:48.000000000'), numpy.datetime64('2018-10-24T12:20:57.000000000'), numpy.datetime64('2018-10-24T14:26:27.000000000'), numpy.datetime64('2018-10-24T15:07:18.000000000'), numpy.datetime64('2018-10-24T15:40:23.000000000'), numpy.datetime64('2018-10-24T17:39:29.000000000'), numpy.datetime64('2018-10-24T17:45:34.000000000'), numpy.datetime64('2018-10-24T19:48:59.000000000'), numpy.datetime64('2018-10-24T22:16:59.000000000'), numpy.datetime64('2018-10-25T01:28:56.000000000'), numpy.datetime64('2018-10-25T02:46:12.000000000'), numpy.datetime64('2018-10-25T07:43:51.000000000'), numpy.datetime64('2018-10-25T07:49:13.000000000'), numpy.datetime64('2018-10-25T08:01:10.000000000'), numpy.datetime64('2018-10-25T08:19:40.000000000'), numpy.datetime64('2018-10-25T10:01:38.000000000'), numpy.datetime64('2018-10-25T10:36:43.000000000'), numpy.datetime64('2018-10-25T11:04:28.000000000'), numpy.datetime64('2018-10-25T11:58:32.000000000'), numpy.datetime64('2018-10-25T13:02:04.000000000'), numpy.datetime64('2018-10-25T13:58:37.000000000'), numpy.datetime64('2018-10-25T15:07:16.000000000'), numpy.datetime64('2018-10-25T15:08:32.000000000'), numpy.datetime64('2018-10-25T15:10:00.000000000'), numpy.datetime64('2018-10-25T15:31:22.000000000'), numpy.datetime64('2018-10-25T16:21:06.000000000'), numpy.datetime64('2018-10-25T17:22:29.000000000'), numpy.datetime64('2018-10-25T17:49:35.000000000'), numpy.datetime64('2018-10-25T19:07:42.000000000'), numpy.datetime64('2018-10-25T21:20:24.000000000'), numpy.datetime64('2018-10-25T23:18:17.000000000'), numpy.datetime64('2018-10-26T00:03:53.000000000'), numpy.datetime64('2018-10-26T00:21:16.000000000'), numpy.datetime64('2018-10-26T00:32:17.000000000'), numpy.datetime64('2018-10-26T00:45:33.000000000'), numpy.datetime64('2018-10-26T01:00:25.000000000'), numpy.datetime64('2018-10-26T01:54:16.000000000'), numpy.datetime64('2018-10-26T02:22:10.000000000'), numpy.datetime64('2018-10-26T02:31:19.000000000'), numpy.datetime64('2018-10-26T03:35:59.000000000'), numpy.datetime64('2018-10-26T03:52:00.000000000'), numpy.datetime64('2018-10-26T04:25:38.000000000'), numpy.datetime64('2018-10-26T04:54:44.000000000'), numpy.datetime64('2018-10-26T05:07:18.000000000'), numpy.datetime64('2018-10-26T05:16:40.000000000'), numpy.datetime64('2018-10-26T05:28:39.000000000'), numpy.datetime64('2018-10-26T06:02:10.000000000'), numpy.datetime64('2018-10-26T06:09:45.000000000'), numpy.datetime64('2018-10-26T06:27:43.000000000'), numpy.datetime64('2018-10-26T07:20:40.000000000'), numpy.datetime64('2018-10-26T08:22:06.000000000'), numpy.datetime64('2018-10-26T09:10:03.000000000'), numpy.datetime64('2018-10-26T10:01:50.000000000'), numpy.datetime64('2018-10-26T10:45:55.000000000'), numpy.datetime64('2018-10-26T11:50:55.000000000'), numpy.datetime64('2018-10-26T12:22:32.000000000'), numpy.datetime64('2018-10-26T12:38:18.000000000'), numpy.datetime64('2018-10-26T14:38:45.000000000'), numpy.datetime64('2018-10-26T15:14:03.000000000'), numpy.datetime64('2018-10-26T16:52:03.000000000'), numpy.datetime64('2018-10-26T16:58:19.000000000'), numpy.datetime64('2018-10-26T18:53:56.000000000'), numpy.datetime64('2018-10-26T20:34:54.000000000'), numpy.datetime64('2018-10-26T22:21:51.000000000'), numpy.datetime64('2018-10-26T22:27:17.000000000'), numpy.datetime64('2018-10-26T23:04:19.000000000'), numpy.datetime64('2018-10-26T23:47:26.000000000'), numpy.datetime64('2018-10-27T02:27:03.000000000'), numpy.datetime64('2018-10-27T02:40:18.000000000'), numpy.datetime64('2018-10-27T02:46:18.000000000'), numpy.datetime64('2018-10-27T02:47:55.000000000'), numpy.datetime64('2018-10-27T03:13:05.000000000'), numpy.datetime64('2018-10-27T05:28:11.000000000'), numpy.datetime64('2018-10-27T06:22:55.000000000'), numpy.datetime64('2018-10-27T06:58:09.000000000'), numpy.datetime64('2018-10-27T09:06:12.000000000'), numpy.datetime64('2018-10-27T09:45:10.000000000'), numpy.datetime64('2018-10-27T10:01:17.000000000'), numpy.datetime64('2018-10-27T10:39:28.000000000'), numpy.datetime64('2018-10-27T10:48:05.000000000'), numpy.datetime64('2018-10-27T10:57:15.000000000'), numpy.datetime64('2018-10-27T11:10:15.000000000'), numpy.datetime64('2018-10-27T12:31:41.000000000'), numpy.datetime64('2018-10-27T13:18:24.000000000'), numpy.datetime64('2018-10-27T13:25:04.000000000'), numpy.datetime64('2018-10-27T13:29:46.000000000'), numpy.datetime64('2018-10-27T14:31:28.000000000'), numpy.datetime64('2018-10-27T14:46:11.000000000'), numpy.datetime64('2018-10-27T15:35:32.000000000'), numpy.datetime64('2018-10-27T17:27:38.000000000'), numpy.datetime64('2018-10-27T18:39:26.000000000'), numpy.datetime64('2018-10-27T21:10:26.000000000'), numpy.datetime64('2018-10-27T21:31:00.000000000'), numpy.datetime64('2018-10-27T21:31:47.000000000'), numpy.datetime64('2018-10-27T21:51:58.000000000'), numpy.datetime64('2018-10-27T21:55:25.000000000'), numpy.datetime64('2018-10-27T22:38:11.000000000'), numpy.datetime64('2018-10-27T23:19:59.000000000'), numpy.datetime64('2018-10-28T00:44:30.000000000'), numpy.datetime64('2018-10-28T00:54:57.000000000'), numpy.datetime64('2018-10-28T00:55:05.000000000'), numpy.datetime64('2018-10-28T01:10:22.000000000'), numpy.datetime64('2018-10-28T02:06:56.000000000'), numpy.datetime64('2018-10-28T04:05:41.000000000'), numpy.datetime64('2018-10-28T05:28:47.000000000'), numpy.datetime64('2018-10-28T05:42:47.000000000'), numpy.datetime64('2018-10-28T06:14:03.000000000'), numpy.datetime64('2018-10-28T06:20:12.000000000'), numpy.datetime64('2018-10-28T07:07:45.000000000'), numpy.datetime64('2018-10-28T07:29:04.000000000'), numpy.datetime64('2018-10-28T08:17:02.000000000'), numpy.datetime64('2018-10-28T08:34:36.000000000'), numpy.datetime64('2018-10-28T09:00:53.000000000'), numpy.datetime64('2018-10-28T09:09:00.000000000'), numpy.datetime64('2018-10-28T09:09:04.000000000'), numpy.datetime64('2018-10-28T09:24:24.000000000'), numpy.datetime64('2018-10-28T09:44:05.000000000'), numpy.datetime64('2018-10-28T10:01:20.000000000'), numpy.datetime64('2018-10-28T10:11:18.000000000'), numpy.datetime64('2018-10-28T10:35:45.000000000'), numpy.datetime64('2018-10-28T10:38:05.000000000'), numpy.datetime64('2018-10-28T10:45:56.000000000'), numpy.datetime64('2018-10-28T11:34:57.000000000'), numpy.datetime64('2018-10-28T12:29:13.000000000'), numpy.datetime64('2018-10-28T12:50:40.000000000'), numpy.datetime64('2018-10-28T13:08:45.000000000'), numpy.datetime64('2018-10-28T16:18:24.000000000'), numpy.datetime64('2018-10-28T16:37:06.000000000'), numpy.datetime64('2018-10-28T17:10:25.000000000'), numpy.datetime64('2018-10-28T18:47:33.000000000'), numpy.datetime64('2018-10-28T20:03:31.000000000'), numpy.datetime64('2018-10-28T20:39:49.000000000'), numpy.datetime64('2018-10-28T21:48:48.000000000'), numpy.datetime64('2018-10-28T22:19:00.000000000'), numpy.datetime64('2018-10-28T22:43:33.000000000'), numpy.datetime64('2018-10-28T23:13:44.000000000'), numpy.datetime64('2018-10-29T00:30:25.000000000'), numpy.datetime64('2018-10-29T00:55:27.000000000'), numpy.datetime64('2018-10-29T01:19:22.000000000'), numpy.datetime64('2018-10-29T01:43:33.000000000'), numpy.datetime64('2018-10-29T01:48:14.000000000'), numpy.datetime64('2018-10-29T02:02:34.000000000'), numpy.datetime64('2018-10-29T03:06:35.000000000'), numpy.datetime64('2018-10-29T04:25:14.000000000'), numpy.datetime64('2018-10-29T04:32:25.000000000'), numpy.datetime64('2018-10-29T06:52:07.000000000'), numpy.datetime64('2018-10-29T07:10:23.000000000'), numpy.datetime64('2018-10-29T08:49:54.000000000'), numpy.datetime64('2018-10-29T09:50:15.000000000'), numpy.datetime64('2018-10-29T12:31:30.000000000'), numpy.datetime64('2018-10-29T12:47:40.000000000'), numpy.datetime64('2018-10-29T13:03:08.000000000'), numpy.datetime64('2018-10-29T14:21:35.000000000'), numpy.datetime64('2018-10-29T16:15:46.000000000'), numpy.datetime64('2018-10-29T16:31:45.000000000'), numpy.datetime64('2018-10-29T16:40:21.000000000'), numpy.datetime64('2018-10-29T18:41:03.000000000'), numpy.datetime64('2018-10-29T20:15:28.000000000'), numpy.datetime64('2018-10-29T22:13:16.000000000'), numpy.datetime64('2018-10-29T22:31:04.000000000'), numpy.datetime64('2018-10-29T22:33:28.000000000'), numpy.datetime64('2018-10-29T22:51:44.000000000'), numpy.datetime64('2018-10-29T23:07:25.000000000'), numpy.datetime64('2018-10-29T23:35:56.000000000'), numpy.datetime64('2018-10-30T01:58:35.000000000'), numpy.datetime64('2018-10-30T02:07:16.000000000'), numpy.datetime64('2018-10-30T06:28:35.000000000'), numpy.datetime64('2018-10-30T07:10:53.000000000'), numpy.datetime64('2018-10-30T07:47:03.000000000'), numpy.datetime64('2018-10-30T09:14:04.000000000'), numpy.datetime64('2018-10-30T11:47:14.000000000'), numpy.datetime64('2018-10-30T12:12:03.000000000'), numpy.datetime64('2018-10-30T13:11:47.000000000'), numpy.datetime64('2018-10-30T14:16:05.000000000'), numpy.datetime64('2018-10-30T16:36:52.000000000'), numpy.datetime64('2018-10-30T16:40:12.000000000'), numpy.datetime64('2018-10-30T17:42:39.000000000'), numpy.datetime64('2018-10-30T18:29:42.000000000'), numpy.datetime64('2018-10-30T18:45:56.000000000'), numpy.datetime64('2018-10-30T18:53:04.000000000'), numpy.datetime64('2018-10-30T20:04:01.000000000'), numpy.datetime64('2018-10-30T20:08:11.000000000'), numpy.datetime64('2018-10-30T21:47:19.000000000'), numpy.datetime64('2018-10-31T00:07:09.000000000'), numpy.datetime64('2018-10-31T01:04:26.000000000'), numpy.datetime64('2018-10-31T01:05:28.000000000'), numpy.datetime64('2018-10-31T01:25:47.000000000'), numpy.datetime64('2018-10-31T02:11:16.000000000'), numpy.datetime64('2018-10-31T02:43:39.000000000'), numpy.datetime64('2018-10-31T02:46:55.000000000'), numpy.datetime64('2018-10-31T02:49:22.000000000'), numpy.datetime64('2018-10-31T03:46:26.000000000'), numpy.datetime64('2018-10-31T04:06:49.000000000'), numpy.datetime64('2018-10-31T06:01:39.000000000'), numpy.datetime64('2018-10-31T06:01:42.000000000'), numpy.datetime64('2018-10-31T06:48:01.000000000'), numpy.datetime64('2018-10-31T08:17:32.000000000'), numpy.datetime64('2018-10-31T10:15:48.000000000'), numpy.datetime64('2018-10-31T10:59:11.000000000'), numpy.datetime64('2018-10-31T12:16:09.000000000'), numpy.datetime64('2018-10-31T12:30:40.000000000'), numpy.datetime64('2018-10-31T15:12:45.000000000'), numpy.datetime64('2018-10-31T19:37:53.000000000'), numpy.datetime64('2018-10-31T19:45:41.000000000'), numpy.datetime64('2018-10-31T20:37:17.000000000'), numpy.datetime64('2018-10-31T21:17:33.000000000'), numpy.datetime64('2018-11-01T03:06:02.000000000'), numpy.datetime64('2018-11-01T04:09:42.000000000'), numpy.datetime64('2018-11-01T04:14:45.000000000'), numpy.datetime64('2018-11-01T06:40:48.000000000'), numpy.datetime64('2018-11-01T07:55:03.000000000')]\n",
      "\n",
      "\n",
      "   df2_missing ( 517 ): [numpy.datetime64('2018-10-01T01:24:39.000000000'), numpy.datetime64('2018-10-01T02:01:53.000000000'), numpy.datetime64('2018-10-01T06:09:33.000000000'), numpy.datetime64('2018-10-01T10:56:39.000000000'), numpy.datetime64('2018-10-01T11:03:57.000000000'), numpy.datetime64('2018-10-01T11:03:58.000000000'), numpy.datetime64('2018-10-01T15:04:38.000000000'), numpy.datetime64('2018-10-01T18:08:36.000000000'), numpy.datetime64('2018-10-01T22:05:53.000000000'), numpy.datetime64('2018-10-02T01:24:29.000000000'), numpy.datetime64('2018-10-02T03:39:13.000000000'), numpy.datetime64('2018-10-02T04:22:59.000000000'), numpy.datetime64('2018-10-02T08:53:44.000000000'), numpy.datetime64('2018-10-02T10:01:25.000000000'), numpy.datetime64('2018-10-03T00:39:12.000000000'), numpy.datetime64('2018-10-03T03:10:50.000000000'), numpy.datetime64('2018-10-03T12:02:33.000000000'), numpy.datetime64('2018-10-03T18:18:08.000000000'), numpy.datetime64('2018-10-03T22:47:48.000000000'), numpy.datetime64('2018-10-03T22:59:43.000000000'), numpy.datetime64('2018-10-04T01:13:18.000000000'), numpy.datetime64('2018-10-04T03:34:26.000000000'), numpy.datetime64('2018-10-04T03:40:41.000000000'), numpy.datetime64('2018-10-04T05:00:41.000000000'), numpy.datetime64('2018-10-04T05:24:38.000000000'), numpy.datetime64('2018-10-04T06:34:41.000000000'), numpy.datetime64('2018-10-04T07:54:39.000000000'), numpy.datetime64('2018-10-04T08:34:04.000000000'), numpy.datetime64('2018-10-04T12:45:37.000000000'), numpy.datetime64('2018-10-04T13:54:08.000000000'), numpy.datetime64('2018-10-04T18:51:49.000000000'), numpy.datetime64('2018-10-04T21:33:36.000000000'), numpy.datetime64('2018-10-05T02:21:42.000000000'), numpy.datetime64('2018-10-05T04:12:42.000000000'), numpy.datetime64('2018-10-05T05:45:47.000000000'), numpy.datetime64('2018-10-05T10:42:20.000000000'), numpy.datetime64('2018-10-05T21:32:18.000000000'), numpy.datetime64('2018-10-05T22:11:06.000000000'), numpy.datetime64('2018-10-05T22:35:03.000000000'), numpy.datetime64('2018-10-06T00:22:35.000000000'), numpy.datetime64('2018-10-06T02:04:02.000000000'), numpy.datetime64('2018-10-06T02:05:00.000000000'), numpy.datetime64('2018-10-06T04:50:53.000000000'), numpy.datetime64('2018-10-06T05:07:58.000000000'), numpy.datetime64('2018-10-06T05:21:50.000000000'), numpy.datetime64('2018-10-06T05:23:34.000000000'), numpy.datetime64('2018-10-06T05:25:02.000000000'), numpy.datetime64('2018-10-06T05:29:39.000000000'), numpy.datetime64('2018-10-06T05:32:00.000000000'), numpy.datetime64('2018-10-06T05:37:44.000000000'), numpy.datetime64('2018-10-06T05:39:06.000000000'), numpy.datetime64('2018-10-06T06:24:46.000000000'), numpy.datetime64('2018-10-06T16:35:23.000000000'), numpy.datetime64('2018-10-06T22:21:50.000000000'), numpy.datetime64('2018-10-07T01:50:47.000000000'), numpy.datetime64('2018-10-07T02:24:42.000000000'), numpy.datetime64('2018-10-07T02:40:55.000000000'), numpy.datetime64('2018-10-07T03:03:05.000000000'), numpy.datetime64('2018-10-07T03:05:46.000000000'), numpy.datetime64('2018-10-07T03:24:17.000000000'), numpy.datetime64('2018-10-07T11:16:23.000000000'), numpy.datetime64('2018-10-07T13:16:54.000000000'), numpy.datetime64('2018-10-07T13:25:17.000000000'), numpy.datetime64('2018-10-07T16:50:02.000000000'), numpy.datetime64('2018-10-07T17:01:55.000000000'), numpy.datetime64('2018-10-07T21:17:50.000000000'), numpy.datetime64('2018-10-08T00:08:35.000000000'), numpy.datetime64('2018-10-08T04:41:55.000000000'), numpy.datetime64('2018-10-08T04:44:23.000000000'), numpy.datetime64('2018-10-08T05:27:37.000000000'), numpy.datetime64('2018-10-08T05:29:36.000000000'), numpy.datetime64('2018-10-08T05:29:59.000000000'), numpy.datetime64('2018-10-08T05:32:14.000000000'), numpy.datetime64('2018-10-08T05:35:21.000000000'), numpy.datetime64('2018-10-08T05:37:08.000000000'), numpy.datetime64('2018-10-08T05:38:08.000000000'), numpy.datetime64('2018-10-08T05:38:42.000000000'), numpy.datetime64('2018-10-08T05:56:18.000000000'), numpy.datetime64('2018-10-08T05:57:58.000000000'), numpy.datetime64('2018-10-08T05:58:30.000000000'), numpy.datetime64('2018-10-08T06:07:45.000000000'), numpy.datetime64('2018-10-08T06:10:04.000000000'), numpy.datetime64('2018-10-08T06:10:32.000000000'), numpy.datetime64('2018-10-08T06:11:37.000000000'), numpy.datetime64('2018-10-08T06:13:01.000000000'), numpy.datetime64('2018-10-08T06:17:39.000000000'), numpy.datetime64('2018-10-08T06:19:09.000000000'), numpy.datetime64('2018-10-08T06:22:16.000000000'), numpy.datetime64('2018-10-08T06:22:19.000000000'), numpy.datetime64('2018-10-08T06:46:00.000000000'), numpy.datetime64('2018-10-08T06:46:19.000000000'), numpy.datetime64('2018-10-08T06:47:03.000000000'), numpy.datetime64('2018-10-08T06:50:32.000000000'), numpy.datetime64('2018-10-08T06:51:36.000000000'), numpy.datetime64('2018-10-08T08:37:33.000000000'), numpy.datetime64('2018-10-08T08:38:16.000000000'), numpy.datetime64('2018-10-08T10:01:42.000000000'), numpy.datetime64('2018-10-08T13:19:32.000000000'), numpy.datetime64('2018-10-08T13:25:33.000000000'), numpy.datetime64('2018-10-08T13:52:10.000000000'), numpy.datetime64('2018-10-08T16:02:12.000000000'), numpy.datetime64('2018-10-09T01:45:39.000000000'), numpy.datetime64('2018-10-09T02:03:45.000000000'), numpy.datetime64('2018-10-09T03:07:32.000000000'), numpy.datetime64('2018-10-09T04:36:04.000000000'), numpy.datetime64('2018-10-09T04:44:28.000000000'), numpy.datetime64('2018-10-09T06:34:53.000000000'), numpy.datetime64('2018-10-09T07:51:33.000000000'), numpy.datetime64('2018-10-09T09:34:48.000000000'), numpy.datetime64('2018-10-09T10:01:23.000000000'), numpy.datetime64('2018-10-09T11:56:35.000000000'), numpy.datetime64('2018-10-09T12:34:40.000000000'), numpy.datetime64('2018-10-09T15:34:51.000000000'), numpy.datetime64('2018-10-09T15:43:12.000000000'), numpy.datetime64('2018-10-09T16:36:05.000000000'), numpy.datetime64('2018-10-09T16:36:37.000000000'), numpy.datetime64('2018-10-09T17:01:13.000000000'), numpy.datetime64('2018-10-09T20:40:44.000000000'), numpy.datetime64('2018-10-09T21:59:40.000000000'), numpy.datetime64('2018-10-09T22:02:51.000000000'), numpy.datetime64('2018-10-09T22:45:29.000000000'), numpy.datetime64('2018-10-09T23:33:10.000000000'), numpy.datetime64('2018-10-10T00:56:34.000000000'), numpy.datetime64('2018-10-10T01:20:39.000000000'), numpy.datetime64('2018-10-10T01:21:07.000000000'), numpy.datetime64('2018-10-10T03:19:53.000000000'), numpy.datetime64('2018-10-10T04:14:10.000000000'), numpy.datetime64('2018-10-10T05:26:20.000000000'), numpy.datetime64('2018-10-10T05:48:53.000000000'), numpy.datetime64('2018-10-10T06:57:45.000000000'), numpy.datetime64('2018-10-10T09:44:37.000000000'), numpy.datetime64('2018-10-10T12:58:41.000000000'), numpy.datetime64('2018-10-10T21:49:20.000000000'), numpy.datetime64('2018-10-10T22:12:57.000000000'), numpy.datetime64('2018-10-11T04:15:49.000000000'), numpy.datetime64('2018-10-11T05:46:20.000000000'), numpy.datetime64('2018-10-11T06:22:47.000000000'), numpy.datetime64('2018-10-11T07:39:22.000000000'), numpy.datetime64('2018-10-11T09:46:23.000000000'), numpy.datetime64('2018-10-11T13:01:44.000000000'), numpy.datetime64('2018-10-11T13:10:08.000000000'), numpy.datetime64('2018-10-11T14:10:17.000000000'), numpy.datetime64('2018-10-11T14:50:52.000000000'), numpy.datetime64('2018-10-11T17:57:29.000000000'), numpy.datetime64('2018-10-11T18:28:53.000000000'), numpy.datetime64('2018-10-11T19:11:54.000000000'), numpy.datetime64('2018-10-11T20:05:27.000000000'), numpy.datetime64('2018-10-11T20:34:30.000000000'), numpy.datetime64('2018-10-11T22:45:10.000000000'), numpy.datetime64('2018-10-12T01:39:41.000000000'), numpy.datetime64('2018-10-12T04:56:21.000000000'), numpy.datetime64('2018-10-12T11:15:39.000000000'), numpy.datetime64('2018-10-12T12:38:10.000000000'), numpy.datetime64('2018-10-12T16:30:00.000000000'), numpy.datetime64('2018-10-12T19:00:22.000000000'), numpy.datetime64('2018-10-12T20:17:44.000000000'), numpy.datetime64('2018-10-12T20:33:37.000000000'), numpy.datetime64('2018-10-13T01:38:31.000000000'), numpy.datetime64('2018-10-13T02:47:05.000000000'), numpy.datetime64('2018-10-13T07:49:32.000000000'), numpy.datetime64('2018-10-13T12:18:20.000000000'), numpy.datetime64('2018-10-13T18:44:01.000000000'), numpy.datetime64('2018-10-13T19:00:03.000000000'), numpy.datetime64('2018-10-14T01:54:00.000000000'), numpy.datetime64('2018-10-14T02:36:27.000000000'), numpy.datetime64('2018-10-14T02:42:18.000000000'), numpy.datetime64('2018-10-14T03:24:32.000000000'), numpy.datetime64('2018-10-14T06:51:29.000000000'), numpy.datetime64('2018-10-14T09:03:41.000000000'), numpy.datetime64('2018-10-14T14:26:23.000000000'), numpy.datetime64('2018-10-14T14:53:35.000000000'), numpy.datetime64('2018-10-14T16:23:12.000000000'), numpy.datetime64('2018-10-14T18:06:32.000000000'), numpy.datetime64('2018-10-14T23:57:48.000000000'), numpy.datetime64('2018-10-15T09:01:30.000000000'), numpy.datetime64('2018-10-15T12:02:43.000000000'), numpy.datetime64('2018-10-15T23:47:55.000000000'), numpy.datetime64('2018-10-16T00:24:39.000000000'), numpy.datetime64('2018-10-16T00:33:21.000000000'), numpy.datetime64('2018-10-16T00:50:59.000000000'), numpy.datetime64('2018-10-16T02:29:13.000000000'), numpy.datetime64('2018-10-16T02:52:22.000000000'), numpy.datetime64('2018-10-16T04:05:28.000000000'), numpy.datetime64('2018-10-16T09:03:04.000000000'), numpy.datetime64('2018-10-16T13:31:36.000000000'), numpy.datetime64('2018-10-16T13:32:51.000000000'), numpy.datetime64('2018-10-16T15:04:10.000000000'), numpy.datetime64('2018-10-16T19:57:24.000000000'), numpy.datetime64('2018-10-16T21:38:28.000000000'), numpy.datetime64('2018-10-16T21:55:46.000000000'), numpy.datetime64('2018-10-16T22:49:33.000000000'), numpy.datetime64('2018-10-16T23:38:24.000000000'), numpy.datetime64('2018-10-16T23:49:53.000000000'), numpy.datetime64('2018-10-17T00:13:17.000000000'), numpy.datetime64('2018-10-17T00:27:20.000000000'), numpy.datetime64('2018-10-17T01:32:15.000000000'), numpy.datetime64('2018-10-17T04:54:35.000000000'), numpy.datetime64('2018-10-17T05:44:55.000000000'), numpy.datetime64('2018-10-17T05:45:06.000000000'), numpy.datetime64('2018-10-17T05:50:06.000000000'), numpy.datetime64('2018-10-17T06:31:30.000000000'), numpy.datetime64('2018-10-17T09:43:47.000000000'), numpy.datetime64('2018-10-17T10:15:44.000000000'), numpy.datetime64('2018-10-17T10:23:51.000000000'), numpy.datetime64('2018-10-17T12:27:14.000000000'), numpy.datetime64('2018-10-17T15:53:06.000000000'), numpy.datetime64('2018-10-17T18:28:42.000000000'), numpy.datetime64('2018-10-17T20:10:29.000000000'), numpy.datetime64('2018-10-18T08:14:45.000000000'), numpy.datetime64('2018-10-18T11:07:49.000000000'), numpy.datetime64('2018-10-18T14:26:28.000000000'), numpy.datetime64('2018-10-18T17:10:39.000000000'), numpy.datetime64('2018-10-18T17:45:03.000000000'), numpy.datetime64('2018-10-18T19:00:12.000000000'), numpy.datetime64('2018-10-18T19:15:25.000000000'), numpy.datetime64('2018-10-18T21:42:14.000000000'), numpy.datetime64('2018-10-18T22:08:40.000000000'), numpy.datetime64('2018-10-18T22:33:21.000000000'), numpy.datetime64('2018-10-19T01:32:41.000000000'), numpy.datetime64('2018-10-19T06:40:47.000000000'), numpy.datetime64('2018-10-19T06:47:20.000000000'), numpy.datetime64('2018-10-19T10:38:11.000000000'), numpy.datetime64('2018-10-19T13:33:57.000000000'), numpy.datetime64('2018-10-19T14:56:58.000000000'), numpy.datetime64('2018-10-19T16:12:49.000000000'), numpy.datetime64('2018-10-19T16:14:57.000000000'), numpy.datetime64('2018-10-19T17:38:09.000000000'), numpy.datetime64('2018-10-19T19:40:07.000000000'), numpy.datetime64('2018-10-19T19:49:43.000000000'), numpy.datetime64('2018-10-19T21:02:52.000000000'), numpy.datetime64('2018-10-19T21:18:23.000000000'), numpy.datetime64('2018-10-19T21:41:34.000000000'), numpy.datetime64('2018-10-19T21:44:29.000000000'), numpy.datetime64('2018-10-19T23:21:10.000000000'), numpy.datetime64('2018-10-20T01:01:39.000000000'), numpy.datetime64('2018-10-20T01:06:19.000000000'), numpy.datetime64('2018-10-20T01:23:44.000000000'), numpy.datetime64('2018-10-20T02:06:42.000000000'), numpy.datetime64('2018-10-20T02:17:56.000000000'), numpy.datetime64('2018-10-20T02:36:48.000000000'), numpy.datetime64('2018-10-20T03:14:35.000000000'), numpy.datetime64('2018-10-20T03:31:56.000000000'), numpy.datetime64('2018-10-20T03:55:27.000000000'), numpy.datetime64('2018-10-20T04:04:19.000000000'), numpy.datetime64('2018-10-20T04:10:31.000000000'), numpy.datetime64('2018-10-20T04:16:05.000000000'), numpy.datetime64('2018-10-20T04:44:21.000000000'), numpy.datetime64('2018-10-20T05:55:15.000000000'), numpy.datetime64('2018-10-20T06:51:44.000000000'), numpy.datetime64('2018-10-20T08:47:55.000000000'), numpy.datetime64('2018-10-20T14:38:57.000000000'), numpy.datetime64('2018-10-20T15:26:09.000000000'), numpy.datetime64('2018-10-20T16:01:30.000000000'), numpy.datetime64('2018-10-20T16:19:23.000000000'), numpy.datetime64('2018-10-20T16:30:38.000000000'), numpy.datetime64('2018-10-20T16:37:44.000000000'), numpy.datetime64('2018-10-20T17:04:48.000000000'), numpy.datetime64('2018-10-20T18:04:45.000000000'), numpy.datetime64('2018-10-20T19:00:36.000000000'), numpy.datetime64('2018-10-20T19:07:20.000000000'), numpy.datetime64('2018-10-20T19:55:21.000000000'), numpy.datetime64('2018-10-20T20:44:54.000000000'), numpy.datetime64('2018-10-20T21:03:32.000000000'), numpy.datetime64('2018-10-20T21:09:00.000000000'), numpy.datetime64('2018-10-20T23:06:20.000000000'), numpy.datetime64('2018-10-21T00:26:24.000000000'), numpy.datetime64('2018-10-21T04:35:38.000000000'), numpy.datetime64('2018-10-21T08:06:06.000000000'), numpy.datetime64('2018-10-21T08:49:46.000000000'), numpy.datetime64('2018-10-21T09:36:42.000000000'), numpy.datetime64('2018-10-21T09:46:44.000000000'), numpy.datetime64('2018-10-21T15:15:12.000000000'), numpy.datetime64('2018-10-21T20:10:42.000000000'), numpy.datetime64('2018-10-22T02:23:18.000000000'), numpy.datetime64('2018-10-22T02:45:21.000000000'), numpy.datetime64('2018-10-22T03:04:29.000000000'), numpy.datetime64('2018-10-22T05:16:35.000000000'), numpy.datetime64('2018-10-22T05:41:23.000000000'), numpy.datetime64('2018-10-22T07:59:16.000000000'), numpy.datetime64('2018-10-22T13:41:32.000000000'), numpy.datetime64('2018-10-22T14:40:57.000000000'), numpy.datetime64('2018-10-22T14:48:16.000000000'), numpy.datetime64('2018-10-22T14:59:46.000000000'), numpy.datetime64('2018-10-22T18:10:39.000000000'), numpy.datetime64('2018-10-22T18:34:30.000000000'), numpy.datetime64('2018-10-22T19:26:19.000000000'), numpy.datetime64('2018-10-22T21:42:15.000000000'), numpy.datetime64('2018-10-22T23:47:19.000000000'), numpy.datetime64('2018-10-23T02:13:01.000000000'), numpy.datetime64('2018-10-23T04:43:31.000000000'), numpy.datetime64('2018-10-23T08:04:34.000000000'), numpy.datetime64('2018-10-23T09:58:26.000000000'), numpy.datetime64('2018-10-23T10:04:18.000000000'), numpy.datetime64('2018-10-23T10:17:09.000000000'), numpy.datetime64('2018-10-23T12:39:45.000000000'), numpy.datetime64('2018-10-23T14:50:28.000000000'), numpy.datetime64('2018-10-23T15:42:41.000000000'), numpy.datetime64('2018-10-23T18:30:20.000000000'), numpy.datetime64('2018-10-23T19:45:40.000000000'), numpy.datetime64('2018-10-23T20:17:13.000000000'), numpy.datetime64('2018-10-23T20:53:28.000000000'), numpy.datetime64('2018-10-23T21:24:59.000000000'), numpy.datetime64('2018-10-24T00:23:58.000000000'), numpy.datetime64('2018-10-24T00:48:17.000000000'), numpy.datetime64('2018-10-24T00:49:59.000000000'), numpy.datetime64('2018-10-24T00:55:56.000000000'), numpy.datetime64('2018-10-24T00:57:09.000000000'), numpy.datetime64('2018-10-24T01:11:38.000000000'), numpy.datetime64('2018-10-24T02:22:46.000000000'), numpy.datetime64('2018-10-24T02:27:07.000000000'), numpy.datetime64('2018-10-24T02:56:59.000000000'), numpy.datetime64('2018-10-24T03:36:16.000000000'), numpy.datetime64('2018-10-24T04:32:02.000000000'), numpy.datetime64('2018-10-24T05:11:25.000000000'), numpy.datetime64('2018-10-24T06:34:52.000000000'), numpy.datetime64('2018-10-24T09:02:45.000000000'), numpy.datetime64('2018-10-24T09:18:51.000000000'), numpy.datetime64('2018-10-24T10:13:13.000000000'), numpy.datetime64('2018-10-24T12:04:49.000000000'), numpy.datetime64('2018-10-24T12:20:58.000000000'), numpy.datetime64('2018-10-24T14:26:28.000000000'), numpy.datetime64('2018-10-24T15:07:17.000000000'), numpy.datetime64('2018-10-24T15:40:24.000000000'), numpy.datetime64('2018-10-24T17:39:30.000000000'), numpy.datetime64('2018-10-24T17:45:35.000000000'), numpy.datetime64('2018-10-24T19:49:00.000000000'), numpy.datetime64('2018-10-24T22:17:00.000000000'), numpy.datetime64('2018-10-24T23:57:03.000000000'), numpy.datetime64('2018-10-25T02:46:13.000000000'), numpy.datetime64('2018-10-25T07:43:50.000000000'), numpy.datetime64('2018-10-25T08:01:11.000000000'), numpy.datetime64('2018-10-25T08:19:41.000000000'), numpy.datetime64('2018-10-25T08:21:07.000000000'), numpy.datetime64('2018-10-25T10:01:36.000000000'), numpy.datetime64('2018-10-25T10:36:44.000000000'), numpy.datetime64('2018-10-25T10:57:41.000000000'), numpy.datetime64('2018-10-25T11:04:27.000000000'), numpy.datetime64('2018-10-25T11:54:50.000000000'), numpy.datetime64('2018-10-25T13:02:03.000000000'), numpy.datetime64('2018-10-25T13:58:38.000000000'), numpy.datetime64('2018-10-25T15:07:15.000000000'), numpy.datetime64('2018-10-25T15:08:31.000000000'), numpy.datetime64('2018-10-25T15:10:01.000000000'), numpy.datetime64('2018-10-25T15:58:03.000000000'), numpy.datetime64('2018-10-25T16:21:05.000000000'), numpy.datetime64('2018-10-25T17:22:30.000000000'), numpy.datetime64('2018-10-25T17:49:36.000000000'), numpy.datetime64('2018-10-25T17:51:05.000000000'), numpy.datetime64('2018-10-25T19:07:43.000000000'), numpy.datetime64('2018-10-25T21:20:25.000000000'), numpy.datetime64('2018-10-25T23:18:16.000000000'), numpy.datetime64('2018-10-26T00:03:52.000000000'), numpy.datetime64('2018-10-26T00:21:17.000000000'), numpy.datetime64('2018-10-26T00:32:18.000000000'), numpy.datetime64('2018-10-26T00:45:34.000000000'), numpy.datetime64('2018-10-26T01:00:24.000000000'), numpy.datetime64('2018-10-26T01:54:17.000000000'), numpy.datetime64('2018-10-26T02:22:11.000000000'), numpy.datetime64('2018-10-26T03:41:41.000000000'), numpy.datetime64('2018-10-26T03:52:01.000000000'), numpy.datetime64('2018-10-26T05:07:17.000000000'), numpy.datetime64('2018-10-26T05:16:41.000000000'), numpy.datetime64('2018-10-26T05:28:40.000000000'), numpy.datetime64('2018-10-26T06:02:11.000000000'), numpy.datetime64('2018-10-26T07:20:39.000000000'), numpy.datetime64('2018-10-26T08:22:07.000000000'), numpy.datetime64('2018-10-26T09:10:02.000000000'), numpy.datetime64('2018-10-26T10:01:49.000000000'), numpy.datetime64('2018-10-26T10:45:56.000000000'), numpy.datetime64('2018-10-26T10:53:46.000000000'), numpy.datetime64('2018-10-26T11:50:56.000000000'), numpy.datetime64('2018-10-26T12:22:31.000000000'), numpy.datetime64('2018-10-26T12:38:19.000000000'), numpy.datetime64('2018-10-26T13:45:49.000000000'), numpy.datetime64('2018-10-26T14:38:49.000000000'), numpy.datetime64('2018-10-26T15:14:04.000000000'), numpy.datetime64('2018-10-26T16:51:34.000000000'), numpy.datetime64('2018-10-26T16:52:04.000000000'), numpy.datetime64('2018-10-26T16:58:20.000000000'), numpy.datetime64('2018-10-26T20:58:25.000000000'), numpy.datetime64('2018-10-26T22:21:52.000000000'), numpy.datetime64('2018-10-26T22:27:16.000000000'), numpy.datetime64('2018-10-26T23:04:20.000000000'), numpy.datetime64('2018-10-27T02:27:02.000000000'), numpy.datetime64('2018-10-27T02:40:17.000000000'), numpy.datetime64('2018-10-27T02:46:17.000000000'), numpy.datetime64('2018-10-27T02:47:54.000000000'), numpy.datetime64('2018-10-27T03:13:04.000000000'), numpy.datetime64('2018-10-27T05:28:10.000000000'), numpy.datetime64('2018-10-27T06:22:56.000000000'), numpy.datetime64('2018-10-27T06:34:29.000000000'), numpy.datetime64('2018-10-27T09:06:11.000000000'), numpy.datetime64('2018-10-27T09:45:09.000000000'), numpy.datetime64('2018-10-27T10:01:16.000000000'), numpy.datetime64('2018-10-27T10:39:29.000000000'), numpy.datetime64('2018-10-27T10:48:06.000000000'), numpy.datetime64('2018-10-27T10:53:58.000000000'), numpy.datetime64('2018-10-27T11:10:14.000000000'), numpy.datetime64('2018-10-27T12:31:40.000000000'), numpy.datetime64('2018-10-27T13:21:28.000000000'), numpy.datetime64('2018-10-27T13:25:05.000000000'), numpy.datetime64('2018-10-27T13:29:47.000000000'), numpy.datetime64('2018-10-27T14:31:29.000000000'), numpy.datetime64('2018-10-27T14:46:10.000000000'), numpy.datetime64('2018-10-27T15:35:31.000000000'), numpy.datetime64('2018-10-27T17:27:39.000000000'), numpy.datetime64('2018-10-27T18:39:27.000000000'), numpy.datetime64('2018-10-27T21:30:59.000000000'), numpy.datetime64('2018-10-27T21:31:48.000000000'), numpy.datetime64('2018-10-27T21:51:57.000000000'), numpy.datetime64('2018-10-27T21:55:24.000000000'), numpy.datetime64('2018-10-27T22:38:10.000000000'), numpy.datetime64('2018-10-27T23:19:58.000000000'), numpy.datetime64('2018-10-28T00:44:31.000000000'), numpy.datetime64('2018-10-28T00:54:56.000000000'), numpy.datetime64('2018-10-28T00:55:06.000000000'), numpy.datetime64('2018-10-28T01:10:21.000000000'), numpy.datetime64('2018-10-28T04:05:42.000000000'), numpy.datetime64('2018-10-28T05:28:46.000000000'), numpy.datetime64('2018-10-28T06:20:11.000000000'), numpy.datetime64('2018-10-28T08:17:01.000000000'), numpy.datetime64('2018-10-28T08:34:35.000000000'), numpy.datetime64('2018-10-28T09:00:54.000000000'), numpy.datetime64('2018-10-28T09:09:01.000000000'), numpy.datetime64('2018-10-28T09:09:03.000000000'), numpy.datetime64('2018-10-28T10:01:21.000000000'), numpy.datetime64('2018-10-28T10:11:19.000000000'), numpy.datetime64('2018-10-28T10:35:46.000000000'), numpy.datetime64('2018-10-28T10:38:04.000000000'), numpy.datetime64('2018-10-28T10:45:57.000000000'), numpy.datetime64('2018-10-28T11:34:58.000000000'), numpy.datetime64('2018-10-28T12:29:14.000000000'), numpy.datetime64('2018-10-28T12:50:39.000000000'), numpy.datetime64('2018-10-28T13:08:46.000000000'), numpy.datetime64('2018-10-28T16:18:23.000000000'), numpy.datetime64('2018-10-28T16:37:07.000000000'), numpy.datetime64('2018-10-28T17:10:26.000000000'), numpy.datetime64('2018-10-28T18:47:32.000000000'), numpy.datetime64('2018-10-28T20:03:32.000000000'), numpy.datetime64('2018-10-28T20:39:50.000000000'), numpy.datetime64('2018-10-28T21:48:47.000000000'), numpy.datetime64('2018-10-28T22:22:50.000000000'), numpy.datetime64('2018-10-28T22:43:32.000000000'), numpy.datetime64('2018-10-28T23:13:45.000000000'), numpy.datetime64('2018-10-29T00:30:26.000000000'), numpy.datetime64('2018-10-29T00:55:26.000000000'), numpy.datetime64('2018-10-29T01:19:21.000000000'), numpy.datetime64('2018-10-29T01:43:32.000000000'), numpy.datetime64('2018-10-29T01:48:15.000000000'), numpy.datetime64('2018-10-29T02:00:47.000000000'), numpy.datetime64('2018-10-29T03:06:34.000000000'), numpy.datetime64('2018-10-29T04:17:01.000000000'), numpy.datetime64('2018-10-29T04:25:15.000000000'), numpy.datetime64('2018-10-29T04:32:24.000000000'), numpy.datetime64('2018-10-29T07:10:24.000000000'), numpy.datetime64('2018-10-29T08:49:55.000000000'), numpy.datetime64('2018-10-29T09:50:16.000000000'), numpy.datetime64('2018-10-29T12:31:31.000000000'), numpy.datetime64('2018-10-29T12:47:41.000000000'), numpy.datetime64('2018-10-29T12:50:23.000000000'), numpy.datetime64('2018-10-29T13:03:07.000000000'), numpy.datetime64('2018-10-29T14:21:36.000000000'), numpy.datetime64('2018-10-29T16:31:46.000000000'), numpy.datetime64('2018-10-29T16:40:22.000000000'), numpy.datetime64('2018-10-29T18:41:02.000000000'), numpy.datetime64('2018-10-29T20:07:00.000000000'), numpy.datetime64('2018-10-29T20:15:29.000000000'), numpy.datetime64('2018-10-29T22:13:17.000000000'), numpy.datetime64('2018-10-29T22:31:05.000000000'), numpy.datetime64('2018-10-29T22:33:29.000000000'), numpy.datetime64('2018-10-29T22:51:43.000000000'), numpy.datetime64('2018-10-29T23:07:26.000000000'), numpy.datetime64('2018-10-29T23:35:57.000000000'), numpy.datetime64('2018-10-30T01:58:36.000000000'), numpy.datetime64('2018-10-30T02:07:15.000000000'), numpy.datetime64('2018-10-30T06:28:36.000000000'), numpy.datetime64('2018-10-30T07:10:52.000000000'), numpy.datetime64('2018-10-30T07:47:04.000000000'), numpy.datetime64('2018-10-30T09:14:05.000000000'), numpy.datetime64('2018-10-30T11:47:15.000000000'), numpy.datetime64('2018-10-30T12:12:02.000000000'), numpy.datetime64('2018-10-30T13:11:48.000000000'), numpy.datetime64('2018-10-30T14:16:04.000000000'), numpy.datetime64('2018-10-30T16:40:11.000000000'), numpy.datetime64('2018-10-30T17:41:01.000000000'), numpy.datetime64('2018-10-30T17:42:38.000000000'), numpy.datetime64('2018-10-30T18:45:57.000000000'), numpy.datetime64('2018-10-30T20:04:00.000000000'), numpy.datetime64('2018-10-30T20:08:12.000000000'), numpy.datetime64('2018-10-30T21:47:20.000000000'), numpy.datetime64('2018-10-31T00:07:10.000000000'), numpy.datetime64('2018-10-31T00:14:36.000000000'), numpy.datetime64('2018-10-31T01:04:25.000000000'), numpy.datetime64('2018-10-31T01:54:51.000000000'), numpy.datetime64('2018-10-31T02:43:40.000000000'), numpy.datetime64('2018-10-31T02:46:56.000000000'), numpy.datetime64('2018-10-31T02:49:23.000000000'), numpy.datetime64('2018-10-31T03:46:25.000000000'), numpy.datetime64('2018-10-31T06:01:40.000000000'), numpy.datetime64('2018-10-31T06:01:43.000000000'), numpy.datetime64('2018-10-31T06:48:02.000000000'), numpy.datetime64('2018-10-31T08:17:31.000000000'), numpy.datetime64('2018-10-31T10:59:12.000000000'), numpy.datetime64('2018-10-31T12:16:10.000000000'), numpy.datetime64('2018-10-31T15:12:46.000000000'), numpy.datetime64('2018-10-31T19:37:52.000000000'), numpy.datetime64('2018-10-31T19:45:40.000000000'), numpy.datetime64('2018-10-31T19:46:28.000000000'), numpy.datetime64('2018-10-31T20:37:18.000000000'), numpy.datetime64('2018-10-31T21:17:34.000000000'), numpy.datetime64('2018-11-01T01:42:56.000000000'), numpy.datetime64('2018-11-01T02:00:22.000000000'), numpy.datetime64('2018-11-01T03:06:03.000000000'), numpy.datetime64('2018-11-01T04:09:41.000000000'), numpy.datetime64('2018-11-01T04:14:46.000000000'), numpy.datetime64('2018-11-01T06:40:47.000000000'), numpy.datetime64('2018-11-01T07:55:02.000000000')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[2:3])  # 509 extra, 517 missing = 8 diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- These extras/missing are NOT primarily related to the 10 rows dropped. \n",
    "- However, the fact that the difference is 8 is a clue that that number might be related to the 10 rows dropped. \n",
    " - If so, perhaps most of the balance of the values are valid/errant values in df1/df2 or df2/df1\n",
    "- Investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62278</th>\n",
       "      <td>sautet</td>\n",
       "      <td>gengsun</td>\n",
       "      <td>3915326</td>\n",
       "      <td>2018-10-01 01:24:39</td>\n",
       "      <td>2018-10-01 01:24:41</td>\n",
       "      <td>2018-10-02 01:24:36</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>23:59:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group    owner  job_number     submission_time          start_time  \\\n",
       "62278  sautet  gengsun  3915326    2018-10-01 01:24:39 2018-10-01 01:24:41   \n",
       "\n",
       "                 end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "62278 2018-10-02 01:24:36  100     137          dc_pod     12     0             \n",
       "\n",
       "       maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu   pe  slot  \\\n",
       "62278  0.0      4.0     24.0  0      0          4.0     0    dc*  12     \n",
       "\n",
       "       campus wait_time    wtime  \n",
       "62278  0      00:00:02  23:59:55  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find EXTRA value in df_2:\n",
    "# start_time  extra   numpy.datetime64('2018-10-01T01:24:41.000000000')\n",
    "\n",
    "df_2[df_2.start_time == '2018-10-01T01:24:41.000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62280</th>\n",
       "      <td>g4</td>\n",
       "      <td>u15</td>\n",
       "      <td>3915326</td>\n",
       "      <td>2018-10-01 01:24:39</td>\n",
       "      <td>2018-10-01 01:24:39</td>\n",
       "      <td>2018-10-02 01:24:36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0 days 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62281</th>\n",
       "      <td>g4</td>\n",
       "      <td>u15</td>\n",
       "      <td>3915326</td>\n",
       "      <td>2018-09-30 14:48:36</td>\n",
       "      <td>2018-10-01 01:24:36</td>\n",
       "      <td>2018-10-02 01:24:36</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002394e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10:36:00</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group owner  job_number     submission_time          start_time  \\\n",
       "62280  g4    u15   3915326    2018-10-01 01:24:39 2018-10-01 01:24:39   \n",
       "62281  g4    u15   3915326    2018-09-30 14:48:36 2018-10-01 01:24:36   \n",
       "\n",
       "                 end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "62280 2018-10-02 01:24:36  0       7            dc_pod     12     0             \n",
       "62281 2018-10-02 01:24:36  100     137          dc_pod     12     0             \n",
       "\n",
       "            maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu   pe  slot  \\\n",
       "62280  0.000000e+00  4.0     24.0  0      0          4.0     0    dc*  12     \n",
       "62281  1.002394e+09  4.0     24.0  0      0          4.0     0    dc*  12     \n",
       "\n",
       "       campus wait_time           wtime  \n",
       "62280  0      00:00:00  0 days 23:59:57  \n",
       "62281  0      10:36:00  1 days 00:00:00  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for this row in df_1 by job number to compare its start_time\n",
    "\n",
    "df_1[df_1.job_number == 3915326]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- For submission time 2018-10-01 01:24:39:\n",
    " - There is a 2-second discrepency between the start times in df_1 and df_2\n",
    " - Also, the `failed` values differ (df_1 : 0, df_2 : 100)\n",
    "- Also, there is an earlier submission time in df_1 that is not present in df_2\n",
    " - The two submit times in df_1 have same job/task #s but diff values for \"start,\" \"failed,\" \"exit_status,\" \"maxvmem,\" \"wait_time,\" and \"wtime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_time:\n",
      "   df2_extra ( 1425 ): [numpy.datetime64('2018-10-01T11:03:59.000000000'), numpy.datetime64('2018-10-01T11:28:05.000000000'), numpy.datetime64('2018-10-01T13:37:42.000000000'), numpy.datetime64('2018-10-01T15:23:35.000000000'), numpy.datetime64('2018-10-01T18:27:16.000000000'), numpy.datetime64('2018-10-01T21:08:54.000000000'), numpy.datetime64('2018-10-01T23:53:31.000000000'), numpy.datetime64('2018-10-02T00:07:33.000000000'), numpy.datetime64('2018-10-02T03:18:41.000000000'), numpy.datetime64('2018-10-02T06:23:52.000000000'), numpy.datetime64('2018-10-02T07:33:27.000000000'), numpy.datetime64('2018-10-02T09:34:27.000000000'), numpy.datetime64('2018-10-02T11:09:46.000000000'), numpy.datetime64('2018-10-02T12:01:08.000000000'), numpy.datetime64('2018-10-02T12:05:55.000000000'), numpy.datetime64('2018-10-02T12:20:18.000000000'), numpy.datetime64('2018-10-02T13:56:41.000000000'), numpy.datetime64('2018-10-02T16:58:23.000000000'), numpy.datetime64('2018-10-02T21:29:07.000000000'), numpy.datetime64('2018-10-02T21:45:20.000000000'), numpy.datetime64('2018-10-02T22:32:15.000000000'), numpy.datetime64('2018-10-02T23:45:02.000000000'), numpy.datetime64('2018-10-02T23:53:15.000000000'), numpy.datetime64('2018-10-03T01:14:36.000000000'), numpy.datetime64('2018-10-03T01:20:39.000000000'), numpy.datetime64('2018-10-03T02:18:31.000000000'), numpy.datetime64('2018-10-03T02:28:27.000000000'), numpy.datetime64('2018-10-03T03:23:00.000000000'), numpy.datetime64('2018-10-03T03:38:44.000000000'), numpy.datetime64('2018-10-03T03:50:37.000000000'), numpy.datetime64('2018-10-03T04:59:14.000000000'), numpy.datetime64('2018-10-03T05:16:04.000000000'), numpy.datetime64('2018-10-03T05:23:06.000000000'), numpy.datetime64('2018-10-03T05:23:36.000000000'), numpy.datetime64('2018-10-03T05:44:32.000000000'), numpy.datetime64('2018-10-03T07:12:34.000000000'), numpy.datetime64('2018-10-03T08:46:03.000000000'), numpy.datetime64('2018-10-03T08:53:07.000000000'), numpy.datetime64('2018-10-03T09:26:38.000000000'), numpy.datetime64('2018-10-03T09:26:41.000000000'), numpy.datetime64('2018-10-03T11:29:36.000000000'), numpy.datetime64('2018-10-03T12:02:30.000000000'), numpy.datetime64('2018-10-03T12:09:23.000000000'), numpy.datetime64('2018-10-03T13:41:57.000000000'), numpy.datetime64('2018-10-03T15:30:22.000000000'), numpy.datetime64('2018-10-03T15:41:16.000000000'), numpy.datetime64('2018-10-03T17:30:40.000000000'), numpy.datetime64('2018-10-03T17:36:09.000000000'), numpy.datetime64('2018-10-03T18:54:17.000000000'), numpy.datetime64('2018-10-03T19:22:36.000000000'), numpy.datetime64('2018-10-03T19:40:07.000000000'), numpy.datetime64('2018-10-03T20:25:47.000000000'), numpy.datetime64('2018-10-03T21:03:48.000000000'), numpy.datetime64('2018-10-03T21:07:48.000000000'), numpy.datetime64('2018-10-03T21:29:05.000000000'), numpy.datetime64('2018-10-03T21:39:14.000000000'), numpy.datetime64('2018-10-03T22:14:52.000000000'), numpy.datetime64('2018-10-03T22:23:36.000000000'), numpy.datetime64('2018-10-03T22:34:28.000000000'), numpy.datetime64('2018-10-03T22:42:05.000000000'), numpy.datetime64('2018-10-04T00:11:52.000000000'), numpy.datetime64('2018-10-04T02:24:10.000000000'), numpy.datetime64('2018-10-04T02:32:26.000000000'), numpy.datetime64('2018-10-04T02:33:38.000000000'), numpy.datetime64('2018-10-04T02:33:47.000000000'), numpy.datetime64('2018-10-04T03:52:34.000000000'), numpy.datetime64('2018-10-04T07:48:24.000000000'), numpy.datetime64('2018-10-04T07:48:49.000000000'), numpy.datetime64('2018-10-04T07:58:19.000000000'), numpy.datetime64('2018-10-04T08:20:43.000000000'), numpy.datetime64('2018-10-04T09:28:49.000000000'), numpy.datetime64('2018-10-04T10:16:11.000000000'), numpy.datetime64('2018-10-04T16:07:56.000000000'), numpy.datetime64('2018-10-04T17:40:17.000000000'), numpy.datetime64('2018-10-04T17:43:47.000000000'), numpy.datetime64('2018-10-04T18:23:42.000000000'), numpy.datetime64('2018-10-04T18:29:32.000000000'), numpy.datetime64('2018-10-04T19:18:16.000000000'), numpy.datetime64('2018-10-04T19:37:40.000000000'), numpy.datetime64('2018-10-04T19:57:53.000000000'), numpy.datetime64('2018-10-04T20:58:41.000000000'), numpy.datetime64('2018-10-04T21:09:15.000000000'), numpy.datetime64('2018-10-04T21:11:00.000000000'), numpy.datetime64('2018-10-04T21:15:31.000000000'), numpy.datetime64('2018-10-04T21:19:18.000000000'), numpy.datetime64('2018-10-04T21:21:36.000000000'), numpy.datetime64('2018-10-04T21:31:56.000000000'), numpy.datetime64('2018-10-04T21:51:44.000000000'), numpy.datetime64('2018-10-04T22:09:18.000000000'), numpy.datetime64('2018-10-04T22:36:09.000000000'), numpy.datetime64('2018-10-05T01:30:37.000000000'), numpy.datetime64('2018-10-05T02:05:21.000000000'), numpy.datetime64('2018-10-05T02:09:07.000000000'), numpy.datetime64('2018-10-05T03:21:15.000000000'), numpy.datetime64('2018-10-05T04:12:31.000000000'), numpy.datetime64('2018-10-05T04:14:05.000000000'), numpy.datetime64('2018-10-05T05:26:16.000000000'), numpy.datetime64('2018-10-05T05:41:44.000000000'), numpy.datetime64('2018-10-05T05:57:25.000000000'), numpy.datetime64('2018-10-05T06:03:39.000000000'), numpy.datetime64('2018-10-05T06:46:19.000000000'), numpy.datetime64('2018-10-05T07:26:56.000000000'), numpy.datetime64('2018-10-05T07:29:23.000000000'), numpy.datetime64('2018-10-05T07:41:43.000000000'), numpy.datetime64('2018-10-05T07:49:44.000000000'), numpy.datetime64('2018-10-05T07:56:35.000000000'), numpy.datetime64('2018-10-05T08:15:39.000000000'), numpy.datetime64('2018-10-05T08:22:29.000000000'), numpy.datetime64('2018-10-05T08:28:38.000000000'), numpy.datetime64('2018-10-05T08:34:12.000000000'), numpy.datetime64('2018-10-05T09:13:37.000000000'), numpy.datetime64('2018-10-05T09:30:47.000000000'), numpy.datetime64('2018-10-05T09:37:09.000000000'), numpy.datetime64('2018-10-05T09:45:00.000000000'), numpy.datetime64('2018-10-05T10:00:02.000000000'), numpy.datetime64('2018-10-05T10:15:12.000000000'), numpy.datetime64('2018-10-05T10:21:47.000000000'), numpy.datetime64('2018-10-05T10:31:10.000000000'), numpy.datetime64('2018-10-05T10:37:28.000000000'), numpy.datetime64('2018-10-05T10:51:53.000000000'), numpy.datetime64('2018-10-05T11:00:36.000000000'), numpy.datetime64('2018-10-05T11:15:44.000000000'), numpy.datetime64('2018-10-05T11:30:07.000000000'), numpy.datetime64('2018-10-05T11:49:42.000000000'), numpy.datetime64('2018-10-05T12:06:36.000000000'), numpy.datetime64('2018-10-05T12:10:14.000000000'), numpy.datetime64('2018-10-05T12:17:55.000000000'), numpy.datetime64('2018-10-05T12:19:28.000000000'), numpy.datetime64('2018-10-05T12:32:51.000000000'), numpy.datetime64('2018-10-05T12:35:00.000000000'), numpy.datetime64('2018-10-05T12:36:22.000000000'), numpy.datetime64('2018-10-05T13:31:51.000000000'), numpy.datetime64('2018-10-05T13:52:01.000000000'), numpy.datetime64('2018-10-05T14:00:18.000000000'), numpy.datetime64('2018-10-05T14:00:21.000000000'), numpy.datetime64('2018-10-05T14:41:15.000000000'), numpy.datetime64('2018-10-05T16:29:04.000000000'), numpy.datetime64('2018-10-05T17:21:52.000000000'), numpy.datetime64('2018-10-05T17:42:12.000000000'), numpy.datetime64('2018-10-05T17:57:26.000000000'), numpy.datetime64('2018-10-05T17:59:01.000000000'), numpy.datetime64('2018-10-05T18:03:42.000000000'), numpy.datetime64('2018-10-05T18:28:36.000000000'), numpy.datetime64('2018-10-05T19:02:10.000000000'), numpy.datetime64('2018-10-05T19:02:30.000000000'), numpy.datetime64('2018-10-05T19:05:09.000000000'), numpy.datetime64('2018-10-05T19:39:09.000000000'), numpy.datetime64('2018-10-05T19:57:15.000000000'), numpy.datetime64('2018-10-05T20:08:27.000000000'), numpy.datetime64('2018-10-05T20:12:32.000000000'), numpy.datetime64('2018-10-05T20:29:24.000000000'), numpy.datetime64('2018-10-05T20:33:05.000000000'), numpy.datetime64('2018-10-05T20:34:47.000000000'), numpy.datetime64('2018-10-05T20:35:12.000000000'), numpy.datetime64('2018-10-05T21:04:07.000000000'), numpy.datetime64('2018-10-05T21:16:43.000000000'), numpy.datetime64('2018-10-05T21:37:45.000000000'), numpy.datetime64('2018-10-05T21:42:22.000000000'), numpy.datetime64('2018-10-05T21:48:45.000000000'), numpy.datetime64('2018-10-05T21:54:36.000000000'), numpy.datetime64('2018-10-05T21:56:49.000000000'), numpy.datetime64('2018-10-05T22:12:12.000000000'), numpy.datetime64('2018-10-05T22:51:07.000000000'), numpy.datetime64('2018-10-05T22:59:21.000000000'), numpy.datetime64('2018-10-05T23:07:51.000000000'), numpy.datetime64('2018-10-05T23:26:15.000000000'), numpy.datetime64('2018-10-05T23:48:04.000000000'), numpy.datetime64('2018-10-06T00:33:45.000000000'), numpy.datetime64('2018-10-06T00:34:12.000000000'), numpy.datetime64('2018-10-06T00:49:07.000000000'), numpy.datetime64('2018-10-06T01:12:55.000000000'), numpy.datetime64('2018-10-06T01:47:08.000000000'), numpy.datetime64('2018-10-06T01:47:17.000000000'), numpy.datetime64('2018-10-06T02:33:33.000000000'), numpy.datetime64('2018-10-06T03:16:46.000000000'), numpy.datetime64('2018-10-06T03:33:37.000000000'), numpy.datetime64('2018-10-06T04:50:21.000000000'), numpy.datetime64('2018-10-06T05:21:49.000000000'), numpy.datetime64('2018-10-06T05:22:15.000000000'), numpy.datetime64('2018-10-06T05:22:34.000000000'), numpy.datetime64('2018-10-06T05:22:40.000000000'), numpy.datetime64('2018-10-06T05:22:45.000000000'), numpy.datetime64('2018-10-06T05:23:04.000000000'), numpy.datetime64('2018-10-06T05:23:19.000000000'), numpy.datetime64('2018-10-06T05:23:35.000000000'), numpy.datetime64('2018-10-06T05:24:03.000000000'), numpy.datetime64('2018-10-06T05:24:25.000000000'), numpy.datetime64('2018-10-06T05:24:48.000000000'), numpy.datetime64('2018-10-06T05:25:03.000000000'), numpy.datetime64('2018-10-06T05:25:33.000000000'), numpy.datetime64('2018-10-06T05:26:29.000000000'), numpy.datetime64('2018-10-06T05:26:46.000000000'), numpy.datetime64('2018-10-06T05:26:57.000000000'), numpy.datetime64('2018-10-06T05:27:15.000000000'), numpy.datetime64('2018-10-06T05:27:33.000000000'), numpy.datetime64('2018-10-06T05:28:01.000000000'), numpy.datetime64('2018-10-06T05:28:16.000000000'), numpy.datetime64('2018-10-06T05:28:42.000000000'), numpy.datetime64('2018-10-06T05:29:13.000000000'), numpy.datetime64('2018-10-06T05:29:32.000000000'), numpy.datetime64('2018-10-06T05:29:38.000000000'), numpy.datetime64('2018-10-06T05:29:41.000000000'), numpy.datetime64('2018-10-06T05:31:16.000000000'), numpy.datetime64('2018-10-06T05:31:30.000000000'), numpy.datetime64('2018-10-06T05:32:01.000000000'), numpy.datetime64('2018-10-06T05:33:21.000000000'), numpy.datetime64('2018-10-06T05:34:28.000000000'), numpy.datetime64('2018-10-06T05:35:11.000000000'), numpy.datetime64('2018-10-06T05:36:20.000000000'), numpy.datetime64('2018-10-06T05:36:38.000000000'), numpy.datetime64('2018-10-06T05:37:07.000000000'), numpy.datetime64('2018-10-06T05:37:35.000000000'), numpy.datetime64('2018-10-06T05:38:16.000000000'), numpy.datetime64('2018-10-06T05:38:40.000000000'), numpy.datetime64('2018-10-06T05:39:07.000000000'), numpy.datetime64('2018-10-06T05:39:23.000000000'), numpy.datetime64('2018-10-06T06:00:02.000000000'), numpy.datetime64('2018-10-06T06:19:34.000000000'), numpy.datetime64('2018-10-06T07:02:37.000000000'), numpy.datetime64('2018-10-06T08:05:35.000000000'), numpy.datetime64('2018-10-06T08:50:49.000000000'), numpy.datetime64('2018-10-06T09:20:18.000000000'), numpy.datetime64('2018-10-06T09:33:40.000000000'), numpy.datetime64('2018-10-06T10:13:31.000000000'), numpy.datetime64('2018-10-06T10:29:07.000000000'), numpy.datetime64('2018-10-06T11:09:58.000000000'), numpy.datetime64('2018-10-06T11:41:14.000000000'), numpy.datetime64('2018-10-06T11:45:54.000000000'), numpy.datetime64('2018-10-06T12:10:26.000000000'), numpy.datetime64('2018-10-06T12:15:03.000000000'), numpy.datetime64('2018-10-06T12:41:13.000000000'), numpy.datetime64('2018-10-06T12:47:51.000000000'), numpy.datetime64('2018-10-06T13:10:52.000000000'), numpy.datetime64('2018-10-06T13:51:27.000000000'), numpy.datetime64('2018-10-06T13:54:06.000000000'), numpy.datetime64('2018-10-06T14:08:59.000000000'), numpy.datetime64('2018-10-06T14:11:55.000000000'), numpy.datetime64('2018-10-06T14:53:48.000000000'), numpy.datetime64('2018-10-06T15:25:42.000000000'), numpy.datetime64('2018-10-06T15:28:44.000000000'), numpy.datetime64('2018-10-06T16:20:36.000000000'), numpy.datetime64('2018-10-06T17:34:08.000000000'), numpy.datetime64('2018-10-06T19:10:34.000000000'), numpy.datetime64('2018-10-06T20:05:48.000000000'), numpy.datetime64('2018-10-06T20:07:13.000000000'), numpy.datetime64('2018-10-06T20:13:55.000000000'), numpy.datetime64('2018-10-06T20:36:57.000000000'), numpy.datetime64('2018-10-06T20:45:06.000000000'), numpy.datetime64('2018-10-06T20:51:54.000000000'), numpy.datetime64('2018-10-06T20:58:45.000000000'), numpy.datetime64('2018-10-06T23:28:38.000000000'), numpy.datetime64('2018-10-07T00:41:35.000000000'), numpy.datetime64('2018-10-07T01:26:24.000000000'), numpy.datetime64('2018-10-07T01:45:32.000000000'), numpy.datetime64('2018-10-07T02:05:17.000000000'), numpy.datetime64('2018-10-07T02:10:00.000000000'), numpy.datetime64('2018-10-07T02:47:07.000000000'), numpy.datetime64('2018-10-07T03:40:43.000000000'), numpy.datetime64('2018-10-07T09:05:43.000000000'), numpy.datetime64('2018-10-07T09:42:55.000000000'), numpy.datetime64('2018-10-07T10:33:26.000000000'), numpy.datetime64('2018-10-07T10:51:35.000000000'), numpy.datetime64('2018-10-07T11:01:46.000000000'), numpy.datetime64('2018-10-07T11:21:24.000000000'), numpy.datetime64('2018-10-07T12:01:26.000000000'), numpy.datetime64('2018-10-07T12:41:30.000000000'), numpy.datetime64('2018-10-07T16:34:39.000000000'), numpy.datetime64('2018-10-07T18:05:29.000000000'), numpy.datetime64('2018-10-07T22:03:31.000000000'), numpy.datetime64('2018-10-07T22:51:12.000000000'), numpy.datetime64('2018-10-07T23:00:52.000000000'), numpy.datetime64('2018-10-07T23:57:36.000000000'), numpy.datetime64('2018-10-08T00:52:39.000000000'), numpy.datetime64('2018-10-08T04:44:45.000000000'), numpy.datetime64('2018-10-08T05:27:47.000000000'), numpy.datetime64('2018-10-08T05:29:53.000000000'), numpy.datetime64('2018-10-08T05:30:11.000000000'), numpy.datetime64('2018-10-08T05:30:15.000000000'), numpy.datetime64('2018-10-08T05:32:08.000000000'), numpy.datetime64('2018-10-08T05:32:15.000000000'), numpy.datetime64('2018-10-08T05:32:44.000000000'), numpy.datetime64('2018-10-08T05:32:55.000000000'), numpy.datetime64('2018-10-08T05:33:02.000000000'), numpy.datetime64('2018-10-08T05:33:15.000000000'), numpy.datetime64('2018-10-08T05:33:26.000000000'), numpy.datetime64('2018-10-08T05:33:43.000000000'), numpy.datetime64('2018-10-08T05:33:46.000000000'), numpy.datetime64('2018-10-08T05:34:08.000000000'), numpy.datetime64('2018-10-08T05:35:19.000000000'), numpy.datetime64('2018-10-08T05:36:05.000000000'), numpy.datetime64('2018-10-08T05:36:18.000000000'), numpy.datetime64('2018-10-08T05:36:50.000000000'), numpy.datetime64('2018-10-08T05:37:09.000000000'), numpy.datetime64('2018-10-08T05:37:23.000000000'), numpy.datetime64('2018-10-08T05:38:09.000000000'), numpy.datetime64('2018-10-08T05:38:52.000000000'), numpy.datetime64('2018-10-08T05:39:26.000000000'), numpy.datetime64('2018-10-08T05:55:05.000000000'), numpy.datetime64('2018-10-08T05:56:02.000000000'), numpy.datetime64('2018-10-08T05:56:19.000000000'), numpy.datetime64('2018-10-08T05:57:20.000000000'), numpy.datetime64('2018-10-08T05:57:36.000000000'), numpy.datetime64('2018-10-08T05:57:51.000000000'), numpy.datetime64('2018-10-08T05:57:57.000000000'), numpy.datetime64('2018-10-08T05:58:46.000000000'), numpy.datetime64('2018-10-08T05:58:51.000000000'), numpy.datetime64('2018-10-08T05:59:19.000000000'), numpy.datetime64('2018-10-08T06:00:34.000000000'), numpy.datetime64('2018-10-08T06:01:19.000000000'), numpy.datetime64('2018-10-08T06:07:44.000000000'), numpy.datetime64('2018-10-08T06:08:17.000000000'), numpy.datetime64('2018-10-08T06:09:31.000000000'), numpy.datetime64('2018-10-08T06:09:46.000000000'), numpy.datetime64('2018-10-08T06:10:05.000000000'), numpy.datetime64('2018-10-08T06:10:33.000000000'), numpy.datetime64('2018-10-08T06:10:52.000000000'), numpy.datetime64('2018-10-08T06:11:38.000000000'), numpy.datetime64('2018-10-08T06:13:52.000000000'), numpy.datetime64('2018-10-08T06:14:08.000000000'), numpy.datetime64('2018-10-08T06:15:49.000000000'), numpy.datetime64('2018-10-08T06:16:10.000000000'), numpy.datetime64('2018-10-08T06:16:21.000000000'), numpy.datetime64('2018-10-08T06:16:27.000000000'), numpy.datetime64('2018-10-08T06:17:38.000000000'), numpy.datetime64('2018-10-08T06:18:25.000000000'), numpy.datetime64('2018-10-08T06:20:36.000000000'), numpy.datetime64('2018-10-08T06:21:24.000000000'), numpy.datetime64('2018-10-08T06:22:20.000000000'), numpy.datetime64('2018-10-08T06:22:54.000000000'), numpy.datetime64('2018-10-08T06:23:58.000000000'), numpy.datetime64('2018-10-08T06:25:12.000000000'), numpy.datetime64('2018-10-08T06:45:03.000000000'), numpy.datetime64('2018-10-08T06:46:01.000000000'), numpy.datetime64('2018-10-08T06:46:36.000000000'), numpy.datetime64('2018-10-08T06:47:23.000000000'), numpy.datetime64('2018-10-08T06:47:38.000000000'), numpy.datetime64('2018-10-08T06:47:53.000000000'), numpy.datetime64('2018-10-08T06:48:42.000000000'), numpy.datetime64('2018-10-08T06:49:57.000000000'), numpy.datetime64('2018-10-08T06:50:04.000000000'), numpy.datetime64('2018-10-08T06:50:33.000000000'), numpy.datetime64('2018-10-08T06:51:37.000000000'), numpy.datetime64('2018-10-08T06:51:44.000000000'), numpy.datetime64('2018-10-08T06:51:50.000000000'), numpy.datetime64('2018-10-08T06:52:08.000000000'), numpy.datetime64('2018-10-08T06:52:40.000000000'), numpy.datetime64('2018-10-08T06:53:17.000000000'), numpy.datetime64('2018-10-08T06:53:35.000000000'), numpy.datetime64('2018-10-08T06:53:54.000000000'), numpy.datetime64('2018-10-08T08:02:08.000000000'), numpy.datetime64('2018-10-08T08:04:19.000000000'), numpy.datetime64('2018-10-08T08:05:22.000000000'), numpy.datetime64('2018-10-08T08:32:41.000000000'), numpy.datetime64('2018-10-08T08:33:30.000000000'), numpy.datetime64('2018-10-08T08:34:59.000000000'), numpy.datetime64('2018-10-08T08:35:57.000000000'), numpy.datetime64('2018-10-08T08:36:59.000000000'), numpy.datetime64('2018-10-08T08:37:34.000000000'), numpy.datetime64('2018-10-08T08:38:50.000000000'), numpy.datetime64('2018-10-08T08:39:16.000000000'), numpy.datetime64('2018-10-08T08:39:45.000000000'), numpy.datetime64('2018-10-08T09:18:01.000000000'), numpy.datetime64('2018-10-08T10:00:21.000000000'), numpy.datetime64('2018-10-08T10:01:11.000000000'), numpy.datetime64('2018-10-08T10:02:09.000000000'), numpy.datetime64('2018-10-08T10:02:26.000000000'), numpy.datetime64('2018-10-08T10:48:04.000000000'), numpy.datetime64('2018-10-08T11:33:18.000000000'), numpy.datetime64('2018-10-08T12:12:39.000000000'), numpy.datetime64('2018-10-08T12:15:57.000000000'), numpy.datetime64('2018-10-08T13:08:35.000000000'), numpy.datetime64('2018-10-08T13:23:51.000000000'), numpy.datetime64('2018-10-08T15:07:41.000000000'), numpy.datetime64('2018-10-08T15:17:14.000000000'), numpy.datetime64('2018-10-08T15:21:42.000000000'), numpy.datetime64('2018-10-08T16:52:55.000000000'), numpy.datetime64('2018-10-08T16:53:57.000000000'), numpy.datetime64('2018-10-08T17:08:03.000000000'), numpy.datetime64('2018-10-08T17:23:24.000000000'), numpy.datetime64('2018-10-08T17:46:16.000000000'), numpy.datetime64('2018-10-08T18:32:26.000000000'), numpy.datetime64('2018-10-08T20:03:00.000000000'), numpy.datetime64('2018-10-08T22:12:41.000000000'), numpy.datetime64('2018-10-08T22:40:43.000000000'), numpy.datetime64('2018-10-08T22:52:16.000000000'), numpy.datetime64('2018-10-09T02:06:39.000000000'), numpy.datetime64('2018-10-09T03:34:00.000000000'), numpy.datetime64('2018-10-09T05:54:13.000000000'), numpy.datetime64('2018-10-09T06:13:06.000000000'), numpy.datetime64('2018-10-09T08:10:57.000000000'), numpy.datetime64('2018-10-09T08:17:58.000000000'), numpy.datetime64('2018-10-09T09:24:10.000000000'), numpy.datetime64('2018-10-09T09:33:47.000000000'), numpy.datetime64('2018-10-09T12:52:19.000000000'), numpy.datetime64('2018-10-09T14:22:56.000000000'), numpy.datetime64('2018-10-09T15:14:58.000000000'), numpy.datetime64('2018-10-09T17:02:06.000000000'), numpy.datetime64('2018-10-09T17:17:51.000000000'), numpy.datetime64('2018-10-09T17:22:22.000000000'), numpy.datetime64('2018-10-09T17:41:43.000000000'), numpy.datetime64('2018-10-09T17:44:45.000000000'), numpy.datetime64('2018-10-09T18:00:49.000000000'), numpy.datetime64('2018-10-09T18:46:58.000000000'), numpy.datetime64('2018-10-09T19:15:41.000000000'), numpy.datetime64('2018-10-09T21:18:09.000000000'), numpy.datetime64('2018-10-09T21:24:01.000000000'), numpy.datetime64('2018-10-09T21:33:42.000000000'), numpy.datetime64('2018-10-09T21:38:49.000000000'), numpy.datetime64('2018-10-09T21:43:43.000000000'), numpy.datetime64('2018-10-09T22:47:02.000000000'), numpy.datetime64('2018-10-09T22:59:00.000000000'), numpy.datetime64('2018-10-09T23:00:18.000000000'), numpy.datetime64('2018-10-09T23:05:49.000000000'), numpy.datetime64('2018-10-09T23:17:47.000000000'), numpy.datetime64('2018-10-09T23:20:45.000000000'), numpy.datetime64('2018-10-10T01:24:52.000000000'), numpy.datetime64('2018-10-10T01:33:51.000000000'), numpy.datetime64('2018-10-10T01:50:30.000000000'), numpy.datetime64('2018-10-10T01:53:32.000000000'), numpy.datetime64('2018-10-10T02:05:51.000000000'), numpy.datetime64('2018-10-10T02:07:06.000000000'), numpy.datetime64('2018-10-10T02:13:26.000000000'), numpy.datetime64('2018-10-10T02:23:39.000000000'), numpy.datetime64('2018-10-10T02:30:41.000000000'), numpy.datetime64('2018-10-10T02:38:07.000000000'), numpy.datetime64('2018-10-10T02:52:38.000000000'), numpy.datetime64('2018-10-10T03:10:11.000000000'), numpy.datetime64('2018-10-10T03:15:16.000000000'), numpy.datetime64('2018-10-10T03:37:48.000000000'), numpy.datetime64('2018-10-10T07:22:25.000000000'), numpy.datetime64('2018-10-10T15:13:58.000000000'), numpy.datetime64('2018-10-10T15:18:07.000000000'), numpy.datetime64('2018-10-10T16:19:16.000000000'), numpy.datetime64('2018-10-10T16:35:00.000000000'), numpy.datetime64('2018-10-10T17:50:03.000000000'), numpy.datetime64('2018-10-10T18:18:18.000000000'), numpy.datetime64('2018-10-10T18:45:41.000000000'), numpy.datetime64('2018-10-10T19:16:19.000000000'), numpy.datetime64('2018-10-10T21:25:26.000000000'), numpy.datetime64('2018-10-10T22:21:29.000000000'), numpy.datetime64('2018-10-10T23:10:53.000000000'), numpy.datetime64('2018-10-11T01:24:39.000000000'), numpy.datetime64('2018-10-11T01:35:33.000000000'), numpy.datetime64('2018-10-11T01:42:37.000000000'), numpy.datetime64('2018-10-11T02:02:11.000000000'), numpy.datetime64('2018-10-11T02:19:59.000000000'), numpy.datetime64('2018-10-11T02:29:25.000000000'), numpy.datetime64('2018-10-11T02:55:11.000000000'), numpy.datetime64('2018-10-11T04:14:53.000000000'), numpy.datetime64('2018-10-11T05:27:48.000000000'), numpy.datetime64('2018-10-11T13:45:08.000000000'), numpy.datetime64('2018-10-11T15:17:17.000000000'), numpy.datetime64('2018-10-11T15:55:40.000000000'), numpy.datetime64('2018-10-11T16:29:30.000000000'), numpy.datetime64('2018-10-11T16:41:12.000000000'), numpy.datetime64('2018-10-11T17:44:42.000000000'), numpy.datetime64('2018-10-11T18:38:43.000000000'), numpy.datetime64('2018-10-11T19:13:06.000000000'), numpy.datetime64('2018-10-11T19:41:11.000000000'), numpy.datetime64('2018-10-12T00:19:37.000000000'), numpy.datetime64('2018-10-12T01:48:50.000000000'), numpy.datetime64('2018-10-12T03:09:07.000000000'), numpy.datetime64('2018-10-12T03:29:10.000000000'), numpy.datetime64('2018-10-12T03:36:54.000000000'), numpy.datetime64('2018-10-12T03:37:31.000000000'), numpy.datetime64('2018-10-12T06:38:24.000000000'), numpy.datetime64('2018-10-12T06:42:54.000000000'), numpy.datetime64('2018-10-12T07:43:16.000000000'), numpy.datetime64('2018-10-12T07:55:46.000000000'), numpy.datetime64('2018-10-12T15:45:48.000000000'), numpy.datetime64('2018-10-12T16:06:58.000000000'), numpy.datetime64('2018-10-12T16:37:27.000000000'), numpy.datetime64('2018-10-12T16:50:14.000000000'), numpy.datetime64('2018-10-12T16:53:21.000000000'), numpy.datetime64('2018-10-12T17:04:55.000000000'), numpy.datetime64('2018-10-12T19:32:58.000000000'), numpy.datetime64('2018-10-12T20:12:16.000000000'), numpy.datetime64('2018-10-12T20:33:19.000000000'), numpy.datetime64('2018-10-12T20:52:41.000000000'), numpy.datetime64('2018-10-13T01:44:56.000000000'), numpy.datetime64('2018-10-13T01:58:09.000000000'), numpy.datetime64('2018-10-13T04:42:21.000000000'), numpy.datetime64('2018-10-13T04:46:35.000000000'), numpy.datetime64('2018-10-13T04:50:38.000000000'), numpy.datetime64('2018-10-13T07:54:32.000000000'), numpy.datetime64('2018-10-13T08:43:16.000000000'), numpy.datetime64('2018-10-13T09:08:03.000000000'), numpy.datetime64('2018-10-13T09:43:38.000000000'), numpy.datetime64('2018-10-13T10:22:36.000000000'), numpy.datetime64('2018-10-13T10:23:53.000000000'), numpy.datetime64('2018-10-13T10:28:56.000000000'), numpy.datetime64('2018-10-13T10:34:51.000000000'), numpy.datetime64('2018-10-13T11:05:38.000000000'), numpy.datetime64('2018-10-13T11:07:01.000000000'), numpy.datetime64('2018-10-13T11:38:12.000000000'), numpy.datetime64('2018-10-13T16:24:18.000000000'), numpy.datetime64('2018-10-13T16:28:47.000000000'), numpy.datetime64('2018-10-13T19:07:24.000000000'), numpy.datetime64('2018-10-13T20:04:20.000000000'), numpy.datetime64('2018-10-13T21:16:49.000000000'), numpy.datetime64('2018-10-13T23:43:05.000000000'), numpy.datetime64('2018-10-14T00:16:14.000000000'), numpy.datetime64('2018-10-14T01:21:07.000000000'), numpy.datetime64('2018-10-14T01:41:29.000000000'), numpy.datetime64('2018-10-14T01:45:43.000000000'), numpy.datetime64('2018-10-14T02:46:58.000000000'), numpy.datetime64('2018-10-14T02:55:49.000000000'), numpy.datetime64('2018-10-14T04:36:16.000000000'), numpy.datetime64('2018-10-14T04:45:34.000000000'), numpy.datetime64('2018-10-14T05:08:48.000000000'), numpy.datetime64('2018-10-14T06:14:51.000000000'), numpy.datetime64('2018-10-14T07:01:27.000000000'), numpy.datetime64('2018-10-14T07:08:43.000000000'), numpy.datetime64('2018-10-14T07:09:05.000000000'), numpy.datetime64('2018-10-14T07:14:11.000000000'), numpy.datetime64('2018-10-14T07:35:54.000000000'), numpy.datetime64('2018-10-14T07:40:24.000000000'), numpy.datetime64('2018-10-14T07:57:42.000000000'), numpy.datetime64('2018-10-14T08:38:47.000000000'), numpy.datetime64('2018-10-14T08:48:11.000000000'), numpy.datetime64('2018-10-14T09:03:24.000000000'), numpy.datetime64('2018-10-14T09:53:03.000000000'), numpy.datetime64('2018-10-14T10:39:50.000000000'), numpy.datetime64('2018-10-14T10:47:40.000000000'), numpy.datetime64('2018-10-14T11:05:53.000000000'), numpy.datetime64('2018-10-14T11:27:59.000000000'), numpy.datetime64('2018-10-14T11:35:16.000000000'), numpy.datetime64('2018-10-14T11:48:10.000000000'), numpy.datetime64('2018-10-14T12:03:23.000000000'), numpy.datetime64('2018-10-14T14:56:33.000000000'), numpy.datetime64('2018-10-14T15:19:11.000000000'), numpy.datetime64('2018-10-14T16:32:30.000000000'), numpy.datetime64('2018-10-14T18:03:12.000000000'), numpy.datetime64('2018-10-14T18:45:38.000000000'), numpy.datetime64('2018-10-14T18:48:18.000000000'), numpy.datetime64('2018-10-14T18:49:08.000000000'), numpy.datetime64('2018-10-14T18:51:35.000000000'), numpy.datetime64('2018-10-14T18:55:32.000000000'), numpy.datetime64('2018-10-14T19:47:11.000000000'), numpy.datetime64('2018-10-14T20:06:53.000000000'), numpy.datetime64('2018-10-14T20:14:34.000000000'), numpy.datetime64('2018-10-14T20:19:42.000000000'), numpy.datetime64('2018-10-14T20:35:47.000000000'), numpy.datetime64('2018-10-14T20:40:08.000000000'), numpy.datetime64('2018-10-14T22:17:14.000000000'), numpy.datetime64('2018-10-14T22:27:02.000000000'), numpy.datetime64('2018-10-15T00:21:42.000000000'), numpy.datetime64('2018-10-15T00:38:55.000000000'), numpy.datetime64('2018-10-15T01:26:54.000000000'), numpy.datetime64('2018-10-15T01:53:44.000000000'), numpy.datetime64('2018-10-15T01:57:21.000000000'), numpy.datetime64('2018-10-15T02:38:38.000000000'), numpy.datetime64('2018-10-15T03:55:05.000000000'), numpy.datetime64('2018-10-15T04:50:37.000000000'), numpy.datetime64('2018-10-15T06:55:53.000000000'), numpy.datetime64('2018-10-15T07:16:18.000000000'), numpy.datetime64('2018-10-15T07:27:32.000000000'), numpy.datetime64('2018-10-15T07:40:46.000000000'), numpy.datetime64('2018-10-15T07:46:07.000000000'), numpy.datetime64('2018-10-15T07:57:51.000000000'), numpy.datetime64('2018-10-15T08:20:14.000000000'), numpy.datetime64('2018-10-15T10:14:36.000000000'), numpy.datetime64('2018-10-15T11:05:11.000000000'), numpy.datetime64('2018-10-15T13:07:28.000000000'), numpy.datetime64('2018-10-15T15:52:23.000000000'), numpy.datetime64('2018-10-15T19:06:39.000000000'), numpy.datetime64('2018-10-15T19:12:32.000000000'), numpy.datetime64('2018-10-15T20:36:22.000000000'), numpy.datetime64('2018-10-15T21:11:15.000000000'), numpy.datetime64('2018-10-15T21:58:18.000000000'), numpy.datetime64('2018-10-15T22:38:39.000000000'), numpy.datetime64('2018-10-15T22:48:19.000000000'), numpy.datetime64('2018-10-15T23:13:36.000000000'), numpy.datetime64('2018-10-16T00:21:20.000000000'), numpy.datetime64('2018-10-16T00:51:00.000000000'), numpy.datetime64('2018-10-16T00:55:27.000000000'), numpy.datetime64('2018-10-16T01:04:07.000000000'), numpy.datetime64('2018-10-16T01:19:45.000000000'), numpy.datetime64('2018-10-16T02:29:12.000000000'), numpy.datetime64('2018-10-16T02:54:54.000000000'), numpy.datetime64('2018-10-16T02:55:40.000000000'), numpy.datetime64('2018-10-16T02:58:51.000000000'), numpy.datetime64('2018-10-16T03:22:56.000000000'), numpy.datetime64('2018-10-16T04:46:39.000000000'), numpy.datetime64('2018-10-16T05:06:28.000000000'), numpy.datetime64('2018-10-16T05:12:50.000000000'), numpy.datetime64('2018-10-16T05:26:25.000000000'), numpy.datetime64('2018-10-16T06:13:36.000000000'), numpy.datetime64('2018-10-16T06:46:07.000000000'), numpy.datetime64('2018-10-16T07:38:06.000000000'), numpy.datetime64('2018-10-16T08:08:36.000000000'), numpy.datetime64('2018-10-16T09:04:40.000000000'), numpy.datetime64('2018-10-16T09:34:02.000000000'), numpy.datetime64('2018-10-16T12:09:09.000000000'), numpy.datetime64('2018-10-16T12:19:08.000000000'), numpy.datetime64('2018-10-16T12:25:19.000000000'), numpy.datetime64('2018-10-16T12:28:19.000000000'), numpy.datetime64('2018-10-16T13:38:48.000000000'), numpy.datetime64('2018-10-16T13:45:28.000000000'), numpy.datetime64('2018-10-16T15:46:07.000000000'), numpy.datetime64('2018-10-16T16:38:48.000000000'), numpy.datetime64('2018-10-16T17:08:26.000000000'), numpy.datetime64('2018-10-16T19:41:31.000000000'), numpy.datetime64('2018-10-16T19:42:03.000000000'), numpy.datetime64('2018-10-16T19:42:34.000000000'), numpy.datetime64('2018-10-16T20:06:32.000000000'), numpy.datetime64('2018-10-16T20:47:33.000000000'), numpy.datetime64('2018-10-16T21:38:27.000000000'), numpy.datetime64('2018-10-16T22:34:01.000000000'), numpy.datetime64('2018-10-16T23:19:43.000000000'), numpy.datetime64('2018-10-16T23:45:10.000000000'), numpy.datetime64('2018-10-17T00:24:45.000000000'), numpy.datetime64('2018-10-17T00:47:02.000000000'), numpy.datetime64('2018-10-17T00:47:55.000000000'), numpy.datetime64('2018-10-17T01:45:51.000000000'), numpy.datetime64('2018-10-17T02:24:03.000000000'), numpy.datetime64('2018-10-17T02:33:59.000000000'), numpy.datetime64('2018-10-17T04:26:44.000000000'), numpy.datetime64('2018-10-17T04:42:59.000000000'), numpy.datetime64('2018-10-17T07:02:58.000000000'), numpy.datetime64('2018-10-17T07:51:54.000000000'), numpy.datetime64('2018-10-17T09:36:01.000000000'), numpy.datetime64('2018-10-17T09:55:20.000000000'), numpy.datetime64('2018-10-17T10:41:25.000000000'), numpy.datetime64('2018-10-17T11:01:22.000000000'), numpy.datetime64('2018-10-17T11:44:01.000000000'), numpy.datetime64('2018-10-17T11:54:45.000000000'), numpy.datetime64('2018-10-17T12:06:57.000000000'), numpy.datetime64('2018-10-17T12:11:54.000000000'), numpy.datetime64('2018-10-17T12:18:41.000000000'), numpy.datetime64('2018-10-17T12:30:27.000000000'), numpy.datetime64('2018-10-17T12:42:35.000000000'), numpy.datetime64('2018-10-17T12:54:56.000000000'), numpy.datetime64('2018-10-17T13:30:57.000000000'), numpy.datetime64('2018-10-17T13:37:47.000000000'), numpy.datetime64('2018-10-17T14:36:02.000000000'), numpy.datetime64('2018-10-17T14:51:12.000000000'), numpy.datetime64('2018-10-17T14:56:10.000000000'), numpy.datetime64('2018-10-17T15:51:48.000000000'), numpy.datetime64('2018-10-17T15:53:35.000000000'), numpy.datetime64('2018-10-17T16:11:53.000000000'), numpy.datetime64('2018-10-17T16:20:04.000000000'), numpy.datetime64('2018-10-17T17:10:02.000000000'), numpy.datetime64('2018-10-17T18:07:07.000000000'), numpy.datetime64('2018-10-17T18:10:25.000000000'), numpy.datetime64('2018-10-17T18:14:17.000000000'), numpy.datetime64('2018-10-17T18:32:24.000000000'), numpy.datetime64('2018-10-17T19:24:51.000000000'), numpy.datetime64('2018-10-17T19:37:18.000000000'), numpy.datetime64('2018-10-17T19:44:24.000000000'), numpy.datetime64('2018-10-17T19:49:11.000000000'), numpy.datetime64('2018-10-17T20:44:12.000000000'), numpy.datetime64('2018-10-17T20:46:41.000000000'), numpy.datetime64('2018-10-17T21:00:24.000000000'), numpy.datetime64('2018-10-17T21:03:14.000000000'), numpy.datetime64('2018-10-17T21:35:10.000000000'), numpy.datetime64('2018-10-17T21:38:57.000000000'), numpy.datetime64('2018-10-17T22:46:25.000000000'), numpy.datetime64('2018-10-17T23:05:52.000000000'), numpy.datetime64('2018-10-18T01:00:20.000000000'), numpy.datetime64('2018-10-18T02:11:09.000000000'), numpy.datetime64('2018-10-18T03:04:50.000000000'), numpy.datetime64('2018-10-18T03:40:42.000000000'), numpy.datetime64('2018-10-18T04:41:03.000000000'), numpy.datetime64('2018-10-18T05:25:02.000000000'), numpy.datetime64('2018-10-18T05:43:44.000000000'), numpy.datetime64('2018-10-18T06:29:26.000000000'), numpy.datetime64('2018-10-18T06:32:08.000000000'), numpy.datetime64('2018-10-18T06:42:55.000000000'), numpy.datetime64('2018-10-18T07:10:23.000000000'), numpy.datetime64('2018-10-18T07:40:59.000000000'), numpy.datetime64('2018-10-18T07:47:57.000000000'), numpy.datetime64('2018-10-18T07:55:28.000000000'), numpy.datetime64('2018-10-18T07:59:49.000000000'), numpy.datetime64('2018-10-18T08:08:16.000000000'), numpy.datetime64('2018-10-18T08:37:44.000000000'), numpy.datetime64('2018-10-18T09:51:24.000000000'), numpy.datetime64('2018-10-18T10:29:42.000000000'), numpy.datetime64('2018-10-18T11:48:22.000000000'), numpy.datetime64('2018-10-18T12:31:37.000000000'), numpy.datetime64('2018-10-18T12:49:19.000000000'), numpy.datetime64('2018-10-18T12:52:33.000000000'), numpy.datetime64('2018-10-18T12:53:10.000000000'), numpy.datetime64('2018-10-18T13:17:46.000000000'), numpy.datetime64('2018-10-18T13:38:46.000000000'), numpy.datetime64('2018-10-18T13:41:07.000000000'), numpy.datetime64('2018-10-18T14:13:00.000000000'), numpy.datetime64('2018-10-18T14:19:26.000000000'), numpy.datetime64('2018-10-18T14:24:55.000000000'), numpy.datetime64('2018-10-18T14:43:57.000000000'), numpy.datetime64('2018-10-18T14:45:01.000000000'), numpy.datetime64('2018-10-18T14:54:06.000000000'), numpy.datetime64('2018-10-18T15:00:42.000000000'), numpy.datetime64('2018-10-18T15:15:02.000000000'), numpy.datetime64('2018-10-18T15:15:09.000000000'), numpy.datetime64('2018-10-18T15:17:25.000000000'), numpy.datetime64('2018-10-18T15:44:03.000000000'), numpy.datetime64('2018-10-18T15:48:33.000000000'), numpy.datetime64('2018-10-18T15:48:35.000000000'), numpy.datetime64('2018-10-18T15:48:38.000000000'), numpy.datetime64('2018-10-18T16:12:20.000000000'), numpy.datetime64('2018-10-18T16:30:44.000000000'), numpy.datetime64('2018-10-18T16:37:49.000000000'), numpy.datetime64('2018-10-18T16:42:31.000000000'), numpy.datetime64('2018-10-18T16:47:13.000000000'), numpy.datetime64('2018-10-18T17:06:21.000000000'), numpy.datetime64('2018-10-18T17:22:22.000000000'), numpy.datetime64('2018-10-18T17:28:11.000000000'), numpy.datetime64('2018-10-18T18:02:08.000000000'), numpy.datetime64('2018-10-18T18:18:57.000000000'), numpy.datetime64('2018-10-18T20:30:04.000000000'), numpy.datetime64('2018-10-18T20:37:04.000000000'), numpy.datetime64('2018-10-18T20:58:28.000000000'), numpy.datetime64('2018-10-18T20:59:06.000000000'), numpy.datetime64('2018-10-18T20:59:34.000000000'), numpy.datetime64('2018-10-18T21:31:46.000000000'), numpy.datetime64('2018-10-18T22:06:14.000000000'), numpy.datetime64('2018-10-18T22:20:42.000000000'), numpy.datetime64('2018-10-18T22:29:56.000000000'), numpy.datetime64('2018-10-18T22:47:19.000000000'), numpy.datetime64('2018-10-18T22:51:50.000000000'), numpy.datetime64('2018-10-18T23:01:46.000000000'), numpy.datetime64('2018-10-18T23:18:02.000000000'), numpy.datetime64('2018-10-18T23:20:35.000000000'), numpy.datetime64('2018-10-18T23:21:03.000000000'), numpy.datetime64('2018-10-19T00:52:38.000000000'), numpy.datetime64('2018-10-19T01:08:03.000000000'), numpy.datetime64('2018-10-19T02:07:38.000000000'), numpy.datetime64('2018-10-19T04:54:02.000000000'), numpy.datetime64('2018-10-19T09:19:21.000000000'), numpy.datetime64('2018-10-19T09:21:09.000000000'), numpy.datetime64('2018-10-19T11:05:16.000000000'), numpy.datetime64('2018-10-19T11:34:21.000000000'), numpy.datetime64('2018-10-19T12:49:45.000000000'), numpy.datetime64('2018-10-19T14:04:44.000000000'), numpy.datetime64('2018-10-19T14:26:06.000000000'), numpy.datetime64('2018-10-19T15:58:12.000000000'), numpy.datetime64('2018-10-19T17:10:58.000000000'), numpy.datetime64('2018-10-19T17:13:12.000000000'), numpy.datetime64('2018-10-19T17:15:14.000000000'), numpy.datetime64('2018-10-19T18:39:58.000000000'), numpy.datetime64('2018-10-19T19:52:28.000000000'), numpy.datetime64('2018-10-19T19:59:10.000000000'), numpy.datetime64('2018-10-19T20:42:26.000000000'), numpy.datetime64('2018-10-19T21:38:45.000000000'), numpy.datetime64('2018-10-19T22:06:56.000000000'), numpy.datetime64('2018-10-19T23:01:04.000000000'), numpy.datetime64('2018-10-19T23:16:32.000000000'), numpy.datetime64('2018-10-19T23:32:41.000000000'), numpy.datetime64('2018-10-19T23:54:48.000000000'), numpy.datetime64('2018-10-20T00:08:51.000000000'), numpy.datetime64('2018-10-20T00:21:09.000000000'), numpy.datetime64('2018-10-20T00:45:44.000000000'), numpy.datetime64('2018-10-20T00:51:56.000000000'), numpy.datetime64('2018-10-20T00:57:08.000000000'), numpy.datetime64('2018-10-20T03:28:54.000000000'), numpy.datetime64('2018-10-20T04:06:22.000000000'), numpy.datetime64('2018-10-20T04:16:42.000000000'), numpy.datetime64('2018-10-20T04:37:59.000000000'), numpy.datetime64('2018-10-20T06:21:48.000000000'), numpy.datetime64('2018-10-20T06:31:13.000000000'), numpy.datetime64('2018-10-20T08:10:18.000000000'), numpy.datetime64('2018-10-20T08:54:07.000000000'), numpy.datetime64('2018-10-20T09:07:12.000000000'), numpy.datetime64('2018-10-20T10:19:18.000000000'), numpy.datetime64('2018-10-20T14:27:05.000000000'), numpy.datetime64('2018-10-20T16:17:42.000000000'), numpy.datetime64('2018-10-20T16:30:58.000000000'), numpy.datetime64('2018-10-20T16:46:38.000000000'), numpy.datetime64('2018-10-20T17:32:46.000000000'), numpy.datetime64('2018-10-20T17:57:56.000000000'), numpy.datetime64('2018-10-20T18:11:43.000000000'), numpy.datetime64('2018-10-20T18:41:03.000000000'), numpy.datetime64('2018-10-20T19:05:18.000000000'), numpy.datetime64('2018-10-20T19:21:35.000000000'), numpy.datetime64('2018-10-20T19:34:21.000000000'), numpy.datetime64('2018-10-20T20:48:11.000000000'), numpy.datetime64('2018-10-20T20:57:24.000000000'), numpy.datetime64('2018-10-20T21:00:32.000000000'), numpy.datetime64('2018-10-20T21:44:17.000000000'), numpy.datetime64('2018-10-20T22:27:36.000000000'), numpy.datetime64('2018-10-20T23:35:08.000000000'), numpy.datetime64('2018-10-20T23:38:58.000000000'), numpy.datetime64('2018-10-21T00:10:33.000000000'), numpy.datetime64('2018-10-21T00:43:00.000000000'), numpy.datetime64('2018-10-21T00:54:13.000000000'), numpy.datetime64('2018-10-21T01:04:41.000000000'), numpy.datetime64('2018-10-21T01:23:56.000000000'), numpy.datetime64('2018-10-21T01:58:12.000000000'), numpy.datetime64('2018-10-21T02:29:38.000000000'), numpy.datetime64('2018-10-21T03:34:10.000000000'), numpy.datetime64('2018-10-21T06:13:53.000000000'), numpy.datetime64('2018-10-21T06:27:03.000000000'), numpy.datetime64('2018-10-21T07:03:11.000000000'), numpy.datetime64('2018-10-21T07:45:56.000000000'), numpy.datetime64('2018-10-21T08:17:55.000000000'), numpy.datetime64('2018-10-21T08:28:17.000000000'), numpy.datetime64('2018-10-21T10:06:32.000000000'), numpy.datetime64('2018-10-21T10:25:36.000000000'), numpy.datetime64('2018-10-21T10:26:08.000000000'), numpy.datetime64('2018-10-21T11:36:29.000000000'), numpy.datetime64('2018-10-21T11:39:36.000000000'), numpy.datetime64('2018-10-21T11:58:37.000000000'), numpy.datetime64('2018-10-21T12:00:33.000000000'), numpy.datetime64('2018-10-21T12:09:00.000000000'), numpy.datetime64('2018-10-21T12:09:43.000000000'), numpy.datetime64('2018-10-21T12:20:34.000000000'), numpy.datetime64('2018-10-21T13:16:40.000000000'), numpy.datetime64('2018-10-21T13:47:21.000000000'), numpy.datetime64('2018-10-21T13:51:23.000000000'), numpy.datetime64('2018-10-21T14:12:11.000000000'), numpy.datetime64('2018-10-21T14:26:38.000000000'), numpy.datetime64('2018-10-21T15:41:44.000000000'), numpy.datetime64('2018-10-21T19:33:32.000000000'), numpy.datetime64('2018-10-21T21:18:04.000000000'), numpy.datetime64('2018-10-21T21:40:44.000000000'), numpy.datetime64('2018-10-21T22:35:46.000000000'), numpy.datetime64('2018-10-21T23:26:00.000000000'), numpy.datetime64('2018-10-21T23:42:50.000000000'), numpy.datetime64('2018-10-21T23:43:54.000000000'), numpy.datetime64('2018-10-22T00:44:37.000000000'), numpy.datetime64('2018-10-22T02:33:04.000000000'), numpy.datetime64('2018-10-22T04:49:48.000000000'), numpy.datetime64('2018-10-22T05:14:19.000000000'), numpy.datetime64('2018-10-22T05:17:52.000000000'), numpy.datetime64('2018-10-22T05:32:06.000000000'), numpy.datetime64('2018-10-22T05:33:33.000000000'), numpy.datetime64('2018-10-22T06:20:06.000000000'), numpy.datetime64('2018-10-22T06:23:52.000000000'), numpy.datetime64('2018-10-22T07:09:01.000000000'), numpy.datetime64('2018-10-22T07:24:03.000000000'), numpy.datetime64('2018-10-22T09:47:05.000000000'), numpy.datetime64('2018-10-22T09:48:13.000000000'), numpy.datetime64('2018-10-22T11:01:20.000000000'), numpy.datetime64('2018-10-22T11:31:54.000000000'), numpy.datetime64('2018-10-22T11:41:06.000000000'), numpy.datetime64('2018-10-22T14:51:10.000000000'), numpy.datetime64('2018-10-22T15:08:27.000000000'), numpy.datetime64('2018-10-22T15:18:16.000000000'), numpy.datetime64('2018-10-22T15:49:45.000000000'), numpy.datetime64('2018-10-22T15:59:10.000000000'), numpy.datetime64('2018-10-22T16:03:21.000000000'), numpy.datetime64('2018-10-22T16:36:24.000000000'), numpy.datetime64('2018-10-22T16:39:06.000000000'), numpy.datetime64('2018-10-22T17:46:48.000000000'), numpy.datetime64('2018-10-22T17:57:32.000000000'), numpy.datetime64('2018-10-22T17:59:24.000000000'), numpy.datetime64('2018-10-22T18:17:36.000000000'), numpy.datetime64('2018-10-22T18:39:49.000000000'), numpy.datetime64('2018-10-22T18:42:15.000000000'), numpy.datetime64('2018-10-22T18:54:42.000000000'), numpy.datetime64('2018-10-22T18:55:42.000000000'), numpy.datetime64('2018-10-22T19:25:34.000000000'), numpy.datetime64('2018-10-22T19:36:02.000000000'), numpy.datetime64('2018-10-22T19:53:49.000000000'), numpy.datetime64('2018-10-22T20:16:20.000000000'), numpy.datetime64('2018-10-22T20:55:48.000000000'), numpy.datetime64('2018-10-22T21:44:04.000000000'), numpy.datetime64('2018-10-22T21:51:31.000000000'), numpy.datetime64('2018-10-22T21:52:28.000000000'), numpy.datetime64('2018-10-22T22:06:52.000000000'), numpy.datetime64('2018-10-22T22:13:04.000000000'), numpy.datetime64('2018-10-22T22:14:57.000000000'), numpy.datetime64('2018-10-22T22:25:14.000000000'), numpy.datetime64('2018-10-22T23:22:19.000000000'), numpy.datetime64('2018-10-22T23:35:36.000000000'), numpy.datetime64('2018-10-22T23:35:40.000000000'), numpy.datetime64('2018-10-22T23:41:11.000000000'), numpy.datetime64('2018-10-22T23:47:17.000000000'), numpy.datetime64('2018-10-23T01:30:23.000000000'), numpy.datetime64('2018-10-23T02:04:04.000000000'), numpy.datetime64('2018-10-23T03:01:53.000000000'), numpy.datetime64('2018-10-23T03:11:22.000000000'), numpy.datetime64('2018-10-23T03:23:23.000000000'), numpy.datetime64('2018-10-23T03:28:23.000000000'), numpy.datetime64('2018-10-23T03:42:59.000000000'), numpy.datetime64('2018-10-23T03:49:52.000000000'), numpy.datetime64('2018-10-23T05:03:56.000000000'), numpy.datetime64('2018-10-23T05:52:59.000000000'), numpy.datetime64('2018-10-23T05:54:40.000000000'), numpy.datetime64('2018-10-23T08:19:15.000000000'), numpy.datetime64('2018-10-23T10:03:14.000000000'), numpy.datetime64('2018-10-23T12:10:57.000000000'), numpy.datetime64('2018-10-23T12:34:20.000000000'), numpy.datetime64('2018-10-23T12:39:45.000000000'), numpy.datetime64('2018-10-23T14:09:37.000000000'), numpy.datetime64('2018-10-23T14:30:56.000000000'), numpy.datetime64('2018-10-23T16:16:42.000000000'), numpy.datetime64('2018-10-23T16:33:28.000000000'), numpy.datetime64('2018-10-23T16:43:51.000000000'), numpy.datetime64('2018-10-23T17:24:20.000000000'), numpy.datetime64('2018-10-23T17:46:28.000000000'), numpy.datetime64('2018-10-23T18:31:25.000000000'), numpy.datetime64('2018-10-23T18:46:54.000000000'), numpy.datetime64('2018-10-23T19:24:20.000000000'), numpy.datetime64('2018-10-23T20:01:57.000000000'), numpy.datetime64('2018-10-23T20:29:11.000000000'), numpy.datetime64('2018-10-23T20:39:02.000000000'), numpy.datetime64('2018-10-23T21:32:37.000000000'), numpy.datetime64('2018-10-23T21:52:10.000000000'), numpy.datetime64('2018-10-23T22:08:44.000000000'), numpy.datetime64('2018-10-23T23:04:24.000000000'), numpy.datetime64('2018-10-23T23:24:30.000000000'), numpy.datetime64('2018-10-23T23:26:47.000000000'), numpy.datetime64('2018-10-23T23:36:35.000000000'), numpy.datetime64('2018-10-23T23:37:12.000000000'), numpy.datetime64('2018-10-23T23:39:11.000000000'), numpy.datetime64('2018-10-23T23:55:57.000000000'), numpy.datetime64('2018-10-24T00:21:22.000000000'), numpy.datetime64('2018-10-24T00:24:40.000000000'), numpy.datetime64('2018-10-24T00:28:50.000000000'), numpy.datetime64('2018-10-24T00:41:52.000000000'), numpy.datetime64('2018-10-24T00:43:20.000000000'), numpy.datetime64('2018-10-24T00:49:37.000000000'), numpy.datetime64('2018-10-24T00:55:05.000000000'), numpy.datetime64('2018-10-24T00:57:34.000000000'), numpy.datetime64('2018-10-24T01:24:21.000000000'), numpy.datetime64('2018-10-24T01:25:09.000000000'), numpy.datetime64('2018-10-24T01:34:20.000000000'), numpy.datetime64('2018-10-24T02:10:49.000000000'), numpy.datetime64('2018-10-24T02:27:38.000000000'), numpy.datetime64('2018-10-24T02:28:06.000000000'), numpy.datetime64('2018-10-24T03:09:45.000000000'), numpy.datetime64('2018-10-24T03:35:18.000000000'), numpy.datetime64('2018-10-24T03:49:03.000000000'), numpy.datetime64('2018-10-24T03:50:30.000000000'), numpy.datetime64('2018-10-24T03:50:32.000000000'), numpy.datetime64('2018-10-24T03:57:18.000000000'), numpy.datetime64('2018-10-24T04:15:36.000000000'), numpy.datetime64('2018-10-24T04:28:34.000000000'), numpy.datetime64('2018-10-24T04:39:40.000000000'), numpy.datetime64('2018-10-24T04:51:04.000000000'), numpy.datetime64('2018-10-24T05:37:15.000000000'), numpy.datetime64('2018-10-24T05:40:11.000000000'), numpy.datetime64('2018-10-24T05:50:15.000000000'), numpy.datetime64('2018-10-24T05:58:41.000000000'), numpy.datetime64('2018-10-24T06:17:36.000000000'), numpy.datetime64('2018-10-24T06:20:33.000000000'), numpy.datetime64('2018-10-24T06:24:05.000000000'), numpy.datetime64('2018-10-24T06:30:51.000000000'), numpy.datetime64('2018-10-24T06:57:19.000000000'), numpy.datetime64('2018-10-24T06:59:46.000000000'), numpy.datetime64('2018-10-24T07:00:51.000000000'), numpy.datetime64('2018-10-24T07:15:13.000000000'), numpy.datetime64('2018-10-24T07:32:27.000000000'), numpy.datetime64('2018-10-24T07:35:26.000000000'), numpy.datetime64('2018-10-24T07:35:47.000000000'), numpy.datetime64('2018-10-24T07:36:35.000000000'), numpy.datetime64('2018-10-24T07:40:31.000000000'), numpy.datetime64('2018-10-24T07:46:23.000000000'), numpy.datetime64('2018-10-24T07:52:18.000000000'), numpy.datetime64('2018-10-24T08:27:44.000000000'), numpy.datetime64('2018-10-24T08:35:29.000000000'), numpy.datetime64('2018-10-24T08:37:23.000000000'), numpy.datetime64('2018-10-24T09:37:21.000000000'), numpy.datetime64('2018-10-24T10:20:02.000000000'), numpy.datetime64('2018-10-24T10:21:58.000000000'), numpy.datetime64('2018-10-24T10:32:58.000000000'), numpy.datetime64('2018-10-24T12:48:13.000000000'), numpy.datetime64('2018-10-24T13:30:34.000000000'), numpy.datetime64('2018-10-24T14:57:12.000000000'), numpy.datetime64('2018-10-24T15:55:56.000000000'), numpy.datetime64('2018-10-24T16:39:05.000000000'), numpy.datetime64('2018-10-24T18:17:53.000000000'), numpy.datetime64('2018-10-24T18:37:42.000000000'), numpy.datetime64('2018-10-24T18:39:46.000000000'), numpy.datetime64('2018-10-24T18:42:33.000000000'), numpy.datetime64('2018-10-24T18:50:17.000000000'), numpy.datetime64('2018-10-24T19:26:21.000000000'), numpy.datetime64('2018-10-24T19:33:38.000000000'), numpy.datetime64('2018-10-24T20:35:59.000000000'), numpy.datetime64('2018-10-24T20:36:52.000000000'), numpy.datetime64('2018-10-24T22:24:01.000000000'), numpy.datetime64('2018-10-25T03:57:57.000000000'), numpy.datetime64('2018-10-25T06:44:35.000000000'), numpy.datetime64('2018-10-25T08:30:02.000000000'), numpy.datetime64('2018-10-25T08:44:14.000000000'), numpy.datetime64('2018-10-25T09:10:07.000000000'), numpy.datetime64('2018-10-25T11:18:37.000000000'), numpy.datetime64('2018-10-25T11:41:34.000000000'), numpy.datetime64('2018-10-25T11:51:51.000000000'), numpy.datetime64('2018-10-25T12:00:34.000000000'), numpy.datetime64('2018-10-25T12:21:05.000000000'), numpy.datetime64('2018-10-25T13:43:05.000000000'), numpy.datetime64('2018-10-25T13:55:16.000000000'), numpy.datetime64('2018-10-25T14:06:14.000000000'), numpy.datetime64('2018-10-25T14:55:51.000000000'), numpy.datetime64('2018-10-25T15:01:43.000000000'), numpy.datetime64('2018-10-25T15:23:45.000000000'), numpy.datetime64('2018-10-25T15:46:35.000000000'), numpy.datetime64('2018-10-25T15:59:17.000000000'), numpy.datetime64('2018-10-25T16:44:31.000000000'), numpy.datetime64('2018-10-25T16:50:26.000000000'), numpy.datetime64('2018-10-25T17:47:00.000000000'), numpy.datetime64('2018-10-25T18:20:14.000000000'), numpy.datetime64('2018-10-25T21:14:31.000000000'), numpy.datetime64('2018-10-25T21:34:16.000000000'), numpy.datetime64('2018-10-25T21:44:12.000000000'), numpy.datetime64('2018-10-25T21:53:48.000000000'), numpy.datetime64('2018-10-25T22:16:52.000000000'), numpy.datetime64('2018-10-26T00:44:25.000000000'), numpy.datetime64('2018-10-26T00:50:28.000000000'), numpy.datetime64('2018-10-26T01:16:36.000000000'), numpy.datetime64('2018-10-26T04:23:47.000000000'), numpy.datetime64('2018-10-26T04:42:32.000000000'), numpy.datetime64('2018-10-26T04:43:50.000000000'), numpy.datetime64('2018-10-26T06:19:21.000000000'), numpy.datetime64('2018-10-26T07:42:02.000000000'), numpy.datetime64('2018-10-26T07:57:51.000000000'), numpy.datetime64('2018-10-26T08:16:10.000000000'), numpy.datetime64('2018-10-26T08:43:21.000000000'), numpy.datetime64('2018-10-26T09:04:09.000000000'), numpy.datetime64('2018-10-26T09:25:57.000000000'), numpy.datetime64('2018-10-26T10:01:02.000000000'), numpy.datetime64('2018-10-26T10:13:17.000000000'), numpy.datetime64('2018-10-26T10:32:55.000000000'), numpy.datetime64('2018-10-26T11:25:50.000000000'), numpy.datetime64('2018-10-26T12:39:24.000000000'), numpy.datetime64('2018-10-26T12:48:08.000000000'), numpy.datetime64('2018-10-26T12:58:40.000000000'), numpy.datetime64('2018-10-26T13:36:13.000000000'), numpy.datetime64('2018-10-26T13:39:14.000000000'), numpy.datetime64('2018-10-26T13:47:05.000000000'), numpy.datetime64('2018-10-26T13:56:30.000000000'), numpy.datetime64('2018-10-26T13:58:24.000000000'), numpy.datetime64('2018-10-26T13:58:38.000000000'), numpy.datetime64('2018-10-26T14:18:00.000000000'), numpy.datetime64('2018-10-26T15:56:19.000000000'), numpy.datetime64('2018-10-26T17:42:20.000000000'), numpy.datetime64('2018-10-26T18:01:36.000000000'), numpy.datetime64('2018-10-26T18:06:30.000000000'), numpy.datetime64('2018-10-26T18:10:31.000000000'), numpy.datetime64('2018-10-26T18:49:48.000000000'), numpy.datetime64('2018-10-26T18:54:56.000000000'), numpy.datetime64('2018-10-26T18:58:54.000000000'), numpy.datetime64('2018-10-26T19:08:53.000000000'), numpy.datetime64('2018-10-26T19:20:59.000000000'), numpy.datetime64('2018-10-26T19:43:21.000000000'), numpy.datetime64('2018-10-26T20:08:18.000000000'), numpy.datetime64('2018-10-26T20:11:26.000000000'), numpy.datetime64('2018-10-26T20:19:02.000000000'), numpy.datetime64('2018-10-26T20:30:19.000000000'), numpy.datetime64('2018-10-26T20:39:02.000000000'), numpy.datetime64('2018-10-26T20:48:12.000000000'), numpy.datetime64('2018-10-26T21:36:19.000000000'), numpy.datetime64('2018-10-26T21:40:35.000000000'), numpy.datetime64('2018-10-26T21:42:01.000000000'), numpy.datetime64('2018-10-26T22:09:32.000000000'), numpy.datetime64('2018-10-26T22:13:26.000000000'), numpy.datetime64('2018-10-26T22:20:39.000000000'), numpy.datetime64('2018-10-26T22:26:23.000000000'), numpy.datetime64('2018-10-26T22:30:25.000000000'), numpy.datetime64('2018-10-26T22:33:22.000000000'), numpy.datetime64('2018-10-26T22:38:07.000000000'), numpy.datetime64('2018-10-26T22:38:40.000000000'), numpy.datetime64('2018-10-26T22:42:33.000000000'), numpy.datetime64('2018-10-26T22:54:04.000000000'), numpy.datetime64('2018-10-26T23:00:08.000000000'), numpy.datetime64('2018-10-26T23:24:01.000000000'), numpy.datetime64('2018-10-26T23:29:04.000000000'), numpy.datetime64('2018-10-26T23:32:31.000000000'), numpy.datetime64('2018-10-26T23:42:50.000000000'), numpy.datetime64('2018-10-26T23:57:05.000000000'), numpy.datetime64('2018-10-27T00:22:53.000000000'), numpy.datetime64('2018-10-27T00:27:54.000000000'), numpy.datetime64('2018-10-27T00:32:17.000000000'), numpy.datetime64('2018-10-27T00:57:21.000000000'), numpy.datetime64('2018-10-27T01:21:26.000000000'), numpy.datetime64('2018-10-27T01:48:50.000000000'), numpy.datetime64('2018-10-27T01:52:55.000000000'), numpy.datetime64('2018-10-27T02:19:35.000000000'), numpy.datetime64('2018-10-27T02:53:51.000000000'), numpy.datetime64('2018-10-27T03:29:11.000000000'), numpy.datetime64('2018-10-27T04:00:06.000000000'), numpy.datetime64('2018-10-27T04:12:11.000000000'), numpy.datetime64('2018-10-27T04:13:51.000000000'), numpy.datetime64('2018-10-27T04:14:26.000000000'), numpy.datetime64('2018-10-27T05:00:41.000000000'), numpy.datetime64('2018-10-27T05:49:48.000000000'), numpy.datetime64('2018-10-27T06:04:23.000000000'), numpy.datetime64('2018-10-27T06:06:56.000000000'), numpy.datetime64('2018-10-27T06:29:10.000000000'), numpy.datetime64('2018-10-27T06:29:50.000000000'), numpy.datetime64('2018-10-27T06:42:53.000000000'), numpy.datetime64('2018-10-27T07:23:35.000000000'), numpy.datetime64('2018-10-27T07:33:47.000000000'), numpy.datetime64('2018-10-27T07:39:38.000000000'), numpy.datetime64('2018-10-27T08:16:42.000000000'), numpy.datetime64('2018-10-27T08:44:36.000000000'), numpy.datetime64('2018-10-27T08:48:04.000000000'), numpy.datetime64('2018-10-27T08:55:53.000000000'), numpy.datetime64('2018-10-27T09:02:32.000000000'), numpy.datetime64('2018-10-27T09:23:14.000000000'), numpy.datetime64('2018-10-27T09:24:03.000000000'), numpy.datetime64('2018-10-27T09:36:47.000000000'), numpy.datetime64('2018-10-27T09:46:40.000000000'), numpy.datetime64('2018-10-27T09:48:20.000000000'), numpy.datetime64('2018-10-27T10:08:08.000000000'), numpy.datetime64('2018-10-27T10:10:39.000000000'), numpy.datetime64('2018-10-27T10:14:40.000000000'), numpy.datetime64('2018-10-27T10:25:14.000000000'), numpy.datetime64('2018-10-27T10:33:51.000000000'), numpy.datetime64('2018-10-27T10:56:50.000000000'), numpy.datetime64('2018-10-27T11:01:10.000000000'), numpy.datetime64('2018-10-27T11:02:43.000000000'), numpy.datetime64('2018-10-27T11:05:23.000000000'), numpy.datetime64('2018-10-27T11:21:57.000000000'), numpy.datetime64('2018-10-27T11:45:22.000000000'), numpy.datetime64('2018-10-27T11:53:00.000000000'), numpy.datetime64('2018-10-27T12:08:13.000000000'), numpy.datetime64('2018-10-27T12:08:55.000000000'), numpy.datetime64('2018-10-27T12:10:36.000000000'), numpy.datetime64('2018-10-27T12:13:39.000000000'), numpy.datetime64('2018-10-27T12:19:42.000000000'), numpy.datetime64('2018-10-27T12:27:38.000000000'), numpy.datetime64('2018-10-27T12:42:25.000000000'), numpy.datetime64('2018-10-27T12:46:10.000000000'), numpy.datetime64('2018-10-27T12:47:58.000000000'), numpy.datetime64('2018-10-27T12:53:32.000000000'), numpy.datetime64('2018-10-27T12:53:38.000000000'), numpy.datetime64('2018-10-27T13:02:11.000000000'), numpy.datetime64('2018-10-27T13:28:06.000000000'), numpy.datetime64('2018-10-27T13:38:00.000000000'), numpy.datetime64('2018-10-27T14:38:41.000000000'), numpy.datetime64('2018-10-27T14:51:12.000000000'), numpy.datetime64('2018-10-27T15:55:57.000000000'), numpy.datetime64('2018-10-27T16:14:09.000000000'), numpy.datetime64('2018-10-27T16:59:20.000000000'), numpy.datetime64('2018-10-27T17:26:34.000000000'), numpy.datetime64('2018-10-27T18:56:16.000000000'), numpy.datetime64('2018-10-27T19:01:04.000000000'), numpy.datetime64('2018-10-27T19:09:13.000000000'), numpy.datetime64('2018-10-27T19:28:19.000000000'), numpy.datetime64('2018-10-27T19:48:26.000000000'), numpy.datetime64('2018-10-27T19:57:09.000000000'), numpy.datetime64('2018-10-27T20:03:47.000000000'), numpy.datetime64('2018-10-27T20:04:08.000000000'), numpy.datetime64('2018-10-27T20:18:11.000000000'), numpy.datetime64('2018-10-27T20:31:09.000000000'), numpy.datetime64('2018-10-27T21:16:49.000000000'), numpy.datetime64('2018-10-27T21:37:32.000000000'), numpy.datetime64('2018-10-27T21:39:01.000000000'), numpy.datetime64('2018-10-27T21:54:52.000000000'), numpy.datetime64('2018-10-27T22:32:09.000000000'), numpy.datetime64('2018-10-27T22:47:47.000000000'), numpy.datetime64('2018-10-27T22:52:53.000000000'), numpy.datetime64('2018-10-27T23:30:12.000000000'), numpy.datetime64('2018-10-27T23:31:47.000000000'), numpy.datetime64('2018-10-28T00:09:47.000000000'), numpy.datetime64('2018-10-28T00:21:41.000000000'), numpy.datetime64('2018-10-28T00:23:06.000000000'), numpy.datetime64('2018-10-28T00:45:43.000000000'), numpy.datetime64('2018-10-28T00:47:24.000000000'), numpy.datetime64('2018-10-28T00:49:01.000000000'), numpy.datetime64('2018-10-28T01:01:58.000000000'), numpy.datetime64('2018-10-28T01:40:25.000000000'), numpy.datetime64('2018-10-28T01:54:02.000000000'), numpy.datetime64('2018-10-28T01:56:33.000000000'), numpy.datetime64('2018-10-28T01:58:52.000000000'), numpy.datetime64('2018-10-28T02:03:10.000000000'), numpy.datetime64('2018-10-28T02:09:40.000000000'), numpy.datetime64('2018-10-28T02:14:53.000000000'), numpy.datetime64('2018-10-28T02:20:54.000000000'), numpy.datetime64('2018-10-28T02:29:33.000000000'), numpy.datetime64('2018-10-28T02:32:43.000000000'), numpy.datetime64('2018-10-28T02:36:06.000000000'), numpy.datetime64('2018-10-28T02:36:18.000000000'), numpy.datetime64('2018-10-28T02:37:12.000000000'), numpy.datetime64('2018-10-28T02:40:11.000000000'), numpy.datetime64('2018-10-28T02:50:46.000000000'), numpy.datetime64('2018-10-28T02:58:00.000000000'), numpy.datetime64('2018-10-28T02:59:21.000000000'), numpy.datetime64('2018-10-28T03:03:31.000000000'), numpy.datetime64('2018-10-28T03:05:58.000000000'), numpy.datetime64('2018-10-28T03:10:29.000000000'), numpy.datetime64('2018-10-28T03:22:31.000000000'), numpy.datetime64('2018-10-28T03:24:45.000000000'), numpy.datetime64('2018-10-28T04:02:45.000000000'), numpy.datetime64('2018-10-28T04:18:30.000000000'), numpy.datetime64('2018-10-28T04:27:24.000000000'), numpy.datetime64('2018-10-28T04:28:41.000000000'), numpy.datetime64('2018-10-28T04:37:17.000000000'), numpy.datetime64('2018-10-28T04:38:51.000000000'), numpy.datetime64('2018-10-28T04:40:40.000000000'), numpy.datetime64('2018-10-28T05:28:53.000000000'), numpy.datetime64('2018-10-28T05:30:26.000000000'), numpy.datetime64('2018-10-28T05:38:33.000000000'), numpy.datetime64('2018-10-28T05:44:23.000000000'), numpy.datetime64('2018-10-28T05:44:49.000000000'), numpy.datetime64('2018-10-28T06:13:47.000000000'), numpy.datetime64('2018-10-28T06:40:20.000000000'), numpy.datetime64('2018-10-28T07:06:21.000000000'), numpy.datetime64('2018-10-28T07:10:30.000000000'), numpy.datetime64('2018-10-28T07:13:24.000000000'), numpy.datetime64('2018-10-28T07:13:32.000000000'), numpy.datetime64('2018-10-28T07:51:36.000000000'), numpy.datetime64('2018-10-28T07:56:17.000000000'), numpy.datetime64('2018-10-28T08:10:56.000000000'), numpy.datetime64('2018-10-28T08:14:07.000000000'), numpy.datetime64('2018-10-28T08:22:07.000000000'), numpy.datetime64('2018-10-28T08:34:35.000000000'), numpy.datetime64('2018-10-28T08:46:58.000000000'), numpy.datetime64('2018-10-28T08:51:33.000000000'), numpy.datetime64('2018-10-28T09:15:12.000000000'), numpy.datetime64('2018-10-28T09:19:46.000000000'), numpy.datetime64('2018-10-28T09:36:14.000000000'), numpy.datetime64('2018-10-28T09:36:58.000000000'), numpy.datetime64('2018-10-28T09:37:14.000000000'), numpy.datetime64('2018-10-28T09:44:16.000000000'), numpy.datetime64('2018-10-28T09:48:56.000000000'), numpy.datetime64('2018-10-28T09:55:48.000000000'), numpy.datetime64('2018-10-28T10:39:57.000000000'), numpy.datetime64('2018-10-28T11:11:26.000000000'), numpy.datetime64('2018-10-28T11:12:34.000000000'), numpy.datetime64('2018-10-28T11:13:48.000000000'), numpy.datetime64('2018-10-28T11:15:48.000000000'), numpy.datetime64('2018-10-28T11:18:42.000000000'), numpy.datetime64('2018-10-28T11:41:13.000000000'), numpy.datetime64('2018-10-28T12:12:01.000000000'), numpy.datetime64('2018-10-28T13:34:27.000000000'), numpy.datetime64('2018-10-28T13:48:35.000000000'), numpy.datetime64('2018-10-28T14:01:01.000000000'), numpy.datetime64('2018-10-28T14:28:14.000000000'), numpy.datetime64('2018-10-28T14:32:12.000000000'), numpy.datetime64('2018-10-28T14:33:36.000000000'), numpy.datetime64('2018-10-28T14:38:00.000000000'), numpy.datetime64('2018-10-28T15:00:38.000000000'), numpy.datetime64('2018-10-28T15:07:05.000000000'), numpy.datetime64('2018-10-28T15:09:02.000000000'), numpy.datetime64('2018-10-28T15:11:12.000000000'), numpy.datetime64('2018-10-28T17:13:19.000000000'), numpy.datetime64('2018-10-28T17:19:23.000000000'), numpy.datetime64('2018-10-28T17:25:02.000000000'), numpy.datetime64('2018-10-28T17:38:28.000000000'), numpy.datetime64('2018-10-28T18:10:53.000000000'), numpy.datetime64('2018-10-28T18:55:36.000000000'), numpy.datetime64('2018-10-28T18:56:35.000000000'), numpy.datetime64('2018-10-28T19:06:30.000000000'), numpy.datetime64('2018-10-28T19:09:37.000000000'), numpy.datetime64('2018-10-28T19:13:01.000000000'), numpy.datetime64('2018-10-28T19:22:05.000000000'), numpy.datetime64('2018-10-28T19:32:32.000000000'), numpy.datetime64('2018-10-28T19:34:52.000000000'), numpy.datetime64('2018-10-28T19:49:30.000000000'), numpy.datetime64('2018-10-28T19:53:49.000000000'), numpy.datetime64('2018-10-28T20:21:16.000000000'), numpy.datetime64('2018-10-28T21:12:39.000000000'), numpy.datetime64('2018-10-28T21:39:57.000000000'), numpy.datetime64('2018-10-28T21:55:26.000000000'), numpy.datetime64('2018-10-29T00:06:48.000000000'), numpy.datetime64('2018-10-29T00:42:54.000000000'), numpy.datetime64('2018-10-29T01:16:53.000000000'), numpy.datetime64('2018-10-29T01:39:06.000000000'), numpy.datetime64('2018-10-29T01:55:28.000000000'), numpy.datetime64('2018-10-29T01:58:32.000000000'), numpy.datetime64('2018-10-29T02:06:54.000000000'), numpy.datetime64('2018-10-29T03:02:15.000000000'), numpy.datetime64('2018-10-29T03:32:49.000000000'), numpy.datetime64('2018-10-29T03:38:46.000000000'), numpy.datetime64('2018-10-29T04:10:27.000000000'), numpy.datetime64('2018-10-29T04:16:04.000000000'), numpy.datetime64('2018-10-29T04:17:36.000000000'), numpy.datetime64('2018-10-29T04:34:04.000000000'), numpy.datetime64('2018-10-29T04:48:50.000000000'), numpy.datetime64('2018-10-29T05:42:08.000000000'), numpy.datetime64('2018-10-29T05:54:23.000000000'), numpy.datetime64('2018-10-29T05:55:11.000000000'), numpy.datetime64('2018-10-29T06:04:04.000000000'), numpy.datetime64('2018-10-29T06:30:04.000000000'), numpy.datetime64('2018-10-29T07:00:45.000000000'), numpy.datetime64('2018-10-29T07:07:55.000000000'), numpy.datetime64('2018-10-29T07:09:11.000000000'), numpy.datetime64('2018-10-29T07:09:38.000000000'), numpy.datetime64('2018-10-29T07:40:23.000000000'), numpy.datetime64('2018-10-29T07:41:27.000000000'), numpy.datetime64('2018-10-29T07:59:06.000000000'), numpy.datetime64('2018-10-29T09:12:27.000000000'), numpy.datetime64('2018-10-29T09:19:09.000000000'), numpy.datetime64('2018-10-29T09:21:52.000000000'), numpy.datetime64('2018-10-29T09:55:24.000000000'), numpy.datetime64('2018-10-29T10:46:51.000000000'), numpy.datetime64('2018-10-29T11:19:41.000000000'), numpy.datetime64('2018-10-29T11:22:39.000000000'), numpy.datetime64('2018-10-29T11:37:15.000000000'), numpy.datetime64('2018-10-29T12:08:33.000000000'), numpy.datetime64('2018-10-29T12:46:00.000000000'), numpy.datetime64('2018-10-29T13:01:30.000000000'), numpy.datetime64('2018-10-29T13:12:08.000000000'), numpy.datetime64('2018-10-29T13:29:21.000000000'), numpy.datetime64('2018-10-29T14:02:00.000000000'), numpy.datetime64('2018-10-29T14:05:29.000000000'), numpy.datetime64('2018-10-29T14:09:49.000000000'), numpy.datetime64('2018-10-29T14:19:57.000000000'), numpy.datetime64('2018-10-29T14:37:24.000000000'), numpy.datetime64('2018-10-29T14:40:33.000000000'), numpy.datetime64('2018-10-29T16:20:07.000000000'), numpy.datetime64('2018-10-29T16:22:55.000000000'), numpy.datetime64('2018-10-29T17:37:29.000000000'), numpy.datetime64('2018-10-29T17:55:30.000000000'), numpy.datetime64('2018-10-29T17:57:43.000000000'), numpy.datetime64('2018-10-29T18:16:40.000000000'), numpy.datetime64('2018-10-29T18:29:27.000000000'), numpy.datetime64('2018-10-29T19:31:45.000000000'), numpy.datetime64('2018-10-29T19:45:46.000000000'), numpy.datetime64('2018-10-29T20:21:17.000000000'), numpy.datetime64('2018-10-29T20:31:21.000000000'), numpy.datetime64('2018-10-29T21:37:33.000000000'), numpy.datetime64('2018-10-29T22:07:33.000000000'), numpy.datetime64('2018-10-29T22:14:22.000000000'), numpy.datetime64('2018-10-29T22:15:28.000000000'), numpy.datetime64('2018-10-29T22:23:11.000000000'), numpy.datetime64('2018-10-29T22:27:33.000000000'), numpy.datetime64('2018-10-29T22:36:54.000000000'), numpy.datetime64('2018-10-29T22:51:07.000000000'), numpy.datetime64('2018-10-29T23:03:59.000000000'), numpy.datetime64('2018-10-29T23:07:23.000000000'), numpy.datetime64('2018-10-29T23:16:12.000000000'), numpy.datetime64('2018-10-29T23:33:24.000000000'), numpy.datetime64('2018-10-29T23:44:29.000000000'), numpy.datetime64('2018-10-29T23:59:02.000000000'), numpy.datetime64('2018-10-30T00:56:48.000000000'), numpy.datetime64('2018-10-30T01:14:42.000000000'), numpy.datetime64('2018-10-30T04:28:40.000000000'), numpy.datetime64('2018-10-30T04:31:50.000000000'), numpy.datetime64('2018-10-30T04:51:24.000000000'), numpy.datetime64('2018-10-30T04:52:22.000000000'), numpy.datetime64('2018-10-30T06:28:35.000000000'), numpy.datetime64('2018-10-30T07:12:40.000000000'), numpy.datetime64('2018-10-30T10:52:58.000000000'), numpy.datetime64('2018-10-30T11:03:18.000000000'), numpy.datetime64('2018-10-30T12:58:23.000000000'), numpy.datetime64('2018-10-30T13:04:47.000000000'), numpy.datetime64('2018-10-30T13:38:56.000000000'), numpy.datetime64('2018-10-30T13:49:04.000000000'), numpy.datetime64('2018-10-30T13:49:45.000000000'), numpy.datetime64('2018-10-30T14:32:08.000000000'), numpy.datetime64('2018-10-30T15:24:39.000000000'), numpy.datetime64('2018-10-30T15:58:46.000000000'), numpy.datetime64('2018-10-30T16:15:44.000000000'), numpy.datetime64('2018-10-30T17:15:37.000000000'), numpy.datetime64('2018-10-30T17:24:01.000000000'), numpy.datetime64('2018-10-30T18:37:33.000000000'), numpy.datetime64('2018-10-30T18:45:12.000000000'), numpy.datetime64('2018-10-30T18:48:06.000000000'), numpy.datetime64('2018-10-30T18:57:22.000000000'), numpy.datetime64('2018-10-30T19:20:48.000000000'), numpy.datetime64('2018-10-30T19:33:01.000000000'), numpy.datetime64('2018-10-30T19:36:45.000000000'), numpy.datetime64('2018-10-30T19:43:38.000000000'), numpy.datetime64('2018-10-30T20:17:57.000000000'), numpy.datetime64('2018-10-30T21:00:25.000000000'), numpy.datetime64('2018-10-30T21:24:14.000000000'), numpy.datetime64('2018-10-30T21:29:43.000000000'), numpy.datetime64('2018-10-30T21:30:45.000000000'), numpy.datetime64('2018-10-30T21:57:03.000000000'), numpy.datetime64('2018-10-30T23:30:46.000000000'), numpy.datetime64('2018-10-30T23:48:01.000000000'), numpy.datetime64('2018-10-30T23:50:16.000000000'), numpy.datetime64('2018-10-31T00:17:23.000000000'), numpy.datetime64('2018-10-31T00:24:55.000000000'), numpy.datetime64('2018-10-31T00:29:59.000000000'), numpy.datetime64('2018-10-31T00:30:59.000000000'), numpy.datetime64('2018-10-31T01:08:31.000000000'), numpy.datetime64('2018-10-31T01:44:25.000000000'), numpy.datetime64('2018-10-31T02:47:53.000000000'), numpy.datetime64('2018-10-31T02:57:51.000000000'), numpy.datetime64('2018-10-31T06:24:16.000000000'), numpy.datetime64('2018-10-31T06:33:50.000000000'), numpy.datetime64('2018-10-31T06:37:17.000000000'), numpy.datetime64('2018-10-31T10:12:33.000000000'), numpy.datetime64('2018-10-31T10:47:03.000000000'), numpy.datetime64('2018-10-31T11:14:40.000000000'), numpy.datetime64('2018-10-31T11:20:23.000000000'), numpy.datetime64('2018-10-31T12:12:55.000000000'), numpy.datetime64('2018-10-31T12:17:24.000000000'), numpy.datetime64('2018-10-31T12:22:37.000000000'), numpy.datetime64('2018-10-31T12:25:07.000000000'), numpy.datetime64('2018-10-31T12:37:58.000000000'), numpy.datetime64('2018-10-31T13:04:48.000000000'), numpy.datetime64('2018-10-31T13:28:20.000000000'), numpy.datetime64('2018-10-31T14:19:58.000000000'), numpy.datetime64('2018-10-31T14:43:27.000000000'), numpy.datetime64('2018-10-31T14:54:54.000000000'), numpy.datetime64('2018-10-31T15:04:24.000000000'), numpy.datetime64('2018-10-31T15:10:41.000000000'), numpy.datetime64('2018-10-31T15:13:19.000000000'), numpy.datetime64('2018-10-31T15:20:30.000000000'), numpy.datetime64('2018-10-31T15:55:25.000000000'), numpy.datetime64('2018-10-31T16:12:38.000000000'), numpy.datetime64('2018-10-31T16:43:56.000000000'), numpy.datetime64('2018-10-31T16:44:29.000000000'), numpy.datetime64('2018-10-31T18:51:05.000000000'), numpy.datetime64('2018-10-31T19:12:04.000000000'), numpy.datetime64('2018-10-31T19:43:00.000000000'), numpy.datetime64('2018-10-31T20:27:36.000000000'), numpy.datetime64('2018-10-31T21:47:02.000000000'), numpy.datetime64('2018-10-31T21:52:14.000000000'), numpy.datetime64('2018-10-31T21:54:42.000000000'), numpy.datetime64('2018-10-31T22:01:12.000000000'), numpy.datetime64('2018-10-31T22:27:25.000000000'), numpy.datetime64('2018-10-31T22:33:55.000000000'), numpy.datetime64('2018-10-31T22:42:09.000000000'), numpy.datetime64('2018-10-31T22:48:00.000000000'), numpy.datetime64('2018-10-31T22:50:39.000000000'), numpy.datetime64('2018-10-31T23:00:20.000000000'), numpy.datetime64('2018-10-31T23:11:01.000000000'), numpy.datetime64('2018-10-31T23:43:14.000000000'), numpy.datetime64('2018-11-01T00:03:28.000000000'), numpy.datetime64('2018-11-01T00:04:43.000000000'), numpy.datetime64('2018-11-01T00:06:51.000000000'), numpy.datetime64('2018-11-01T00:19:07.000000000'), numpy.datetime64('2018-11-01T00:42:44.000000000'), numpy.datetime64('2018-11-01T01:06:20.000000000'), numpy.datetime64('2018-11-01T01:41:16.000000000'), numpy.datetime64('2018-11-01T01:54:04.000000000'), numpy.datetime64('2018-11-01T01:55:15.000000000'), numpy.datetime64('2018-11-01T02:49:07.000000000'), numpy.datetime64('2018-11-01T03:25:49.000000000'), numpy.datetime64('2018-11-01T03:35:53.000000000'), numpy.datetime64('2018-11-01T03:53:28.000000000'), numpy.datetime64('2018-11-01T04:05:13.000000000'), numpy.datetime64('2018-11-01T04:45:30.000000000'), numpy.datetime64('2018-11-01T05:16:53.000000000'), numpy.datetime64('2018-11-01T07:41:58.000000000'), numpy.datetime64('2018-11-01T07:50:43.000000000')]\n",
      "\n",
      "\n",
      "   df2_missing ( 1089 ): [numpy.datetime64('2018-10-01T10:09:53.000000000'), numpy.datetime64('2018-10-01T22:04:38.000000000'), numpy.datetime64('2018-10-01T22:34:46.000000000'), numpy.datetime64('2018-10-02T08:04:00.000000000'), numpy.datetime64('2018-10-02T12:05:57.000000000'), numpy.datetime64('2018-10-02T13:31:36.000000000'), numpy.datetime64('2018-10-02T13:56:42.000000000'), numpy.datetime64('2018-10-02T14:03:19.000000000'), numpy.datetime64('2018-10-02T15:23:04.000000000'), numpy.datetime64('2018-10-02T17:02:25.000000000'), numpy.datetime64('2018-10-02T19:41:14.000000000'), numpy.datetime64('2018-10-02T23:45:01.000000000'), numpy.datetime64('2018-10-02T23:53:16.000000000'), numpy.datetime64('2018-10-03T02:18:30.000000000'), numpy.datetime64('2018-10-03T02:28:26.000000000'), numpy.datetime64('2018-10-03T03:23:01.000000000'), numpy.datetime64('2018-10-03T03:38:45.000000000'), numpy.datetime64('2018-10-03T03:50:38.000000000'), numpy.datetime64('2018-10-03T04:59:19.000000000'), numpy.datetime64('2018-10-03T05:16:05.000000000'), numpy.datetime64('2018-10-03T05:23:35.000000000'), numpy.datetime64('2018-10-03T09:26:45.000000000'), numpy.datetime64('2018-10-03T12:02:31.000000000'), numpy.datetime64('2018-10-03T12:09:24.000000000'), numpy.datetime64('2018-10-03T14:56:05.000000000'), numpy.datetime64('2018-10-03T15:41:24.000000000'), numpy.datetime64('2018-10-03T21:00:11.000000000'), numpy.datetime64('2018-10-03T22:23:37.000000000'), numpy.datetime64('2018-10-03T22:42:04.000000000'), numpy.datetime64('2018-10-04T03:24:54.000000000'), numpy.datetime64('2018-10-04T03:48:50.000000000'), numpy.datetime64('2018-10-04T07:48:28.000000000'), numpy.datetime64('2018-10-04T07:48:51.000000000'), numpy.datetime64('2018-10-04T08:03:10.000000000'), numpy.datetime64('2018-10-04T08:20:46.000000000'), numpy.datetime64('2018-10-04T16:35:08.000000000'), numpy.datetime64('2018-10-04T17:43:46.000000000'), numpy.datetime64('2018-10-04T18:23:41.000000000'), numpy.datetime64('2018-10-04T18:31:07.000000000'), numpy.datetime64('2018-10-04T19:18:17.000000000'), numpy.datetime64('2018-10-04T19:37:39.000000000'), numpy.datetime64('2018-10-04T20:58:42.000000000'), numpy.datetime64('2018-10-04T21:31:57.000000000'), numpy.datetime64('2018-10-04T22:09:17.000000000'), numpy.datetime64('2018-10-04T22:36:10.000000000'), numpy.datetime64('2018-10-04T22:58:17.000000000'), numpy.datetime64('2018-10-05T02:21:32.000000000'), numpy.datetime64('2018-10-05T04:08:31.000000000'), numpy.datetime64('2018-10-05T05:16:40.000000000'), numpy.datetime64('2018-10-05T05:26:18.000000000'), numpy.datetime64('2018-10-05T05:41:47.000000000'), numpy.datetime64('2018-10-05T05:53:39.000000000'), numpy.datetime64('2018-10-05T05:57:26.000000000'), numpy.datetime64('2018-10-05T07:26:57.000000000'), numpy.datetime64('2018-10-05T07:29:24.000000000'), numpy.datetime64('2018-10-05T07:32:20.000000000'), numpy.datetime64('2018-10-05T07:41:44.000000000'), numpy.datetime64('2018-10-05T07:47:45.000000000'), numpy.datetime64('2018-10-05T07:49:46.000000000'), numpy.datetime64('2018-10-05T07:56:36.000000000'), numpy.datetime64('2018-10-05T08:34:13.000000000'), numpy.datetime64('2018-10-05T09:22:22.000000000'), numpy.datetime64('2018-10-05T09:37:10.000000000'), numpy.datetime64('2018-10-05T09:45:01.000000000'), numpy.datetime64('2018-10-05T10:06:33.000000000'), numpy.datetime64('2018-10-05T10:15:13.000000000'), numpy.datetime64('2018-10-05T10:21:48.000000000'), numpy.datetime64('2018-10-05T10:31:11.000000000'), numpy.datetime64('2018-10-05T10:45:38.000000000'), numpy.datetime64('2018-10-05T10:51:54.000000000'), numpy.datetime64('2018-10-05T11:00:37.000000000'), numpy.datetime64('2018-10-05T11:23:43.000000000'), numpy.datetime64('2018-10-05T11:38:40.000000000'), numpy.datetime64('2018-10-05T12:19:29.000000000'), numpy.datetime64('2018-10-05T12:32:52.000000000'), numpy.datetime64('2018-10-05T14:00:20.000000000'), numpy.datetime64('2018-10-05T14:27:41.000000000'), numpy.datetime64('2018-10-05T14:38:06.000000000'), numpy.datetime64('2018-10-05T15:19:00.000000000'), numpy.datetime64('2018-10-05T16:42:04.000000000'), numpy.datetime64('2018-10-05T17:39:35.000000000'), numpy.datetime64('2018-10-05T17:48:29.000000000'), numpy.datetime64('2018-10-05T17:57:27.000000000'), numpy.datetime64('2018-10-05T19:02:11.000000000'), numpy.datetime64('2018-10-05T19:02:31.000000000'), numpy.datetime64('2018-10-05T19:47:05.000000000'), numpy.datetime64('2018-10-05T19:57:16.000000000'), numpy.datetime64('2018-10-05T20:29:25.000000000'), numpy.datetime64('2018-10-05T21:04:06.000000000'), numpy.datetime64('2018-10-05T21:16:16.000000000'), numpy.datetime64('2018-10-05T21:37:46.000000000'), numpy.datetime64('2018-10-05T22:39:49.000000000'), numpy.datetime64('2018-10-05T22:51:08.000000000'), numpy.datetime64('2018-10-05T22:59:22.000000000'), numpy.datetime64('2018-10-05T23:07:50.000000000'), numpy.datetime64('2018-10-05T23:32:25.000000000'), numpy.datetime64('2018-10-05T23:33:47.000000000'), numpy.datetime64('2018-10-06T00:33:46.000000000'), numpy.datetime64('2018-10-06T00:52:23.000000000'), numpy.datetime64('2018-10-06T01:47:16.000000000'), numpy.datetime64('2018-10-06T02:03:53.000000000'), numpy.datetime64('2018-10-06T02:53:59.000000000'), numpy.datetime64('2018-10-06T03:33:39.000000000'), numpy.datetime64('2018-10-06T05:21:50.000000000'), numpy.datetime64('2018-10-06T05:22:14.000000000'), numpy.datetime64('2018-10-06T05:22:33.000000000'), numpy.datetime64('2018-10-06T05:22:41.000000000'), numpy.datetime64('2018-10-06T05:22:44.000000000'), numpy.datetime64('2018-10-06T05:23:03.000000000'), numpy.datetime64('2018-10-06T05:23:18.000000000'), numpy.datetime64('2018-10-06T05:23:34.000000000'), numpy.datetime64('2018-10-06T05:23:45.000000000'), numpy.datetime64('2018-10-06T05:24:02.000000000'), numpy.datetime64('2018-10-06T05:24:26.000000000'), numpy.datetime64('2018-10-06T05:24:47.000000000'), numpy.datetime64('2018-10-06T05:25:25.000000000'), numpy.datetime64('2018-10-06T05:25:32.000000000'), numpy.datetime64('2018-10-06T05:26:28.000000000'), numpy.datetime64('2018-10-06T05:28:00.000000000'), numpy.datetime64('2018-10-06T05:28:15.000000000'), numpy.datetime64('2018-10-06T05:28:41.000000000'), numpy.datetime64('2018-10-06T05:29:14.000000000'), numpy.datetime64('2018-10-06T05:29:39.000000000'), numpy.datetime64('2018-10-06T05:29:42.000000000'), numpy.datetime64('2018-10-06T05:29:59.000000000'), numpy.datetime64('2018-10-06T05:30:14.000000000'), numpy.datetime64('2018-10-06T05:30:46.000000000'), numpy.datetime64('2018-10-06T05:31:15.000000000'), numpy.datetime64('2018-10-06T05:31:31.000000000'), numpy.datetime64('2018-10-06T05:32:00.000000000'), numpy.datetime64('2018-10-06T05:32:18.000000000'), numpy.datetime64('2018-10-06T05:32:37.000000000'), numpy.datetime64('2018-10-06T05:33:15.000000000'), numpy.datetime64('2018-10-06T05:33:22.000000000'), numpy.datetime64('2018-10-06T05:34:27.000000000'), numpy.datetime64('2018-10-06T05:35:10.000000000'), numpy.datetime64('2018-10-06T05:35:47.000000000'), numpy.datetime64('2018-10-06T05:36:19.000000000'), numpy.datetime64('2018-10-06T05:36:37.000000000'), numpy.datetime64('2018-10-06T05:37:06.000000000'), numpy.datetime64('2018-10-06T05:37:34.000000000'), numpy.datetime64('2018-10-06T05:38:14.000000000'), numpy.datetime64('2018-10-06T05:38:39.000000000'), numpy.datetime64('2018-10-06T05:39:06.000000000'), numpy.datetime64('2018-10-06T06:00:01.000000000'), numpy.datetime64('2018-10-06T06:04:37.000000000'), numpy.datetime64('2018-10-06T08:50:48.000000000'), numpy.datetime64('2018-10-06T09:20:17.000000000'), numpy.datetime64('2018-10-06T09:33:39.000000000'), numpy.datetime64('2018-10-06T10:13:30.000000000'), numpy.datetime64('2018-10-06T11:09:59.000000000'), numpy.datetime64('2018-10-06T14:08:58.000000000'), numpy.datetime64('2018-10-06T23:26:55.000000000'), numpy.datetime64('2018-10-07T01:26:23.000000000'), numpy.datetime64('2018-10-07T01:45:33.000000000'), numpy.datetime64('2018-10-07T01:53:54.000000000'), numpy.datetime64('2018-10-07T04:48:50.000000000'), numpy.datetime64('2018-10-07T06:54:14.000000000'), numpy.datetime64('2018-10-07T07:42:11.000000000'), numpy.datetime64('2018-10-07T10:51:36.000000000'), numpy.datetime64('2018-10-07T10:59:03.000000000'), numpy.datetime64('2018-10-07T15:26:05.000000000'), numpy.datetime64('2018-10-07T17:17:26.000000000'), numpy.datetime64('2018-10-07T19:29:09.000000000'), numpy.datetime64('2018-10-07T19:47:24.000000000'), numpy.datetime64('2018-10-08T05:28:08.000000000'), numpy.datetime64('2018-10-08T05:29:05.000000000'), numpy.datetime64('2018-10-08T05:29:59.000000000'), numpy.datetime64('2018-10-08T05:31:57.000000000'), numpy.datetime64('2018-10-08T05:32:54.000000000'), numpy.datetime64('2018-10-08T05:33:45.000000000'), numpy.datetime64('2018-10-08T05:34:39.000000000'), numpy.datetime64('2018-10-08T05:35:41.000000000'), numpy.datetime64('2018-10-08T05:36:39.000000000'), numpy.datetime64('2018-10-08T05:36:52.000000000'), numpy.datetime64('2018-10-08T05:37:08.000000000'), numpy.datetime64('2018-10-08T05:38:08.000000000'), numpy.datetime64('2018-10-08T05:38:51.000000000'), numpy.datetime64('2018-10-08T05:55:50.000000000'), numpy.datetime64('2018-10-08T05:56:01.000000000'), numpy.datetime64('2018-10-08T05:56:18.000000000'), numpy.datetime64('2018-10-08T05:57:35.000000000'), numpy.datetime64('2018-10-08T05:57:58.000000000'), numpy.datetime64('2018-10-08T05:58:01.000000000'), numpy.datetime64('2018-10-08T05:58:17.000000000'), numpy.datetime64('2018-10-08T05:58:50.000000000'), numpy.datetime64('2018-10-08T06:01:32.000000000'), numpy.datetime64('2018-10-08T06:07:12.000000000'), numpy.datetime64('2018-10-08T06:08:32.000000000'), numpy.datetime64('2018-10-08T06:08:41.000000000'), numpy.datetime64('2018-10-08T06:09:45.000000000'), numpy.datetime64('2018-10-08T06:10:04.000000000'), numpy.datetime64('2018-10-08T06:10:32.000000000'), numpy.datetime64('2018-10-08T06:11:37.000000000'), numpy.datetime64('2018-10-08T06:13:51.000000000'), numpy.datetime64('2018-10-08T06:17:39.000000000'), numpy.datetime64('2018-10-08T06:19:09.000000000'), numpy.datetime64('2018-10-08T06:19:29.000000000'), numpy.datetime64('2018-10-08T06:20:35.000000000'), numpy.datetime64('2018-10-08T06:20:53.000000000'), numpy.datetime64('2018-10-08T06:22:19.000000000'), numpy.datetime64('2018-10-08T06:24:27.000000000'), numpy.datetime64('2018-10-08T06:25:11.000000000'), numpy.datetime64('2018-10-08T06:25:44.000000000'), numpy.datetime64('2018-10-08T06:44:48.000000000'), numpy.datetime64('2018-10-08T06:45:02.000000000'), numpy.datetime64('2018-10-08T06:45:34.000000000'), numpy.datetime64('2018-10-08T06:46:19.000000000'), numpy.datetime64('2018-10-08T06:46:35.000000000'), numpy.datetime64('2018-10-08T06:46:47.000000000'), numpy.datetime64('2018-10-08T06:47:37.000000000'), numpy.datetime64('2018-10-08T06:48:45.000000000'), numpy.datetime64('2018-10-08T06:49:15.000000000'), numpy.datetime64('2018-10-08T06:49:31.000000000'), numpy.datetime64('2018-10-08T06:50:03.000000000'), numpy.datetime64('2018-10-08T06:50:32.000000000'), numpy.datetime64('2018-10-08T06:51:45.000000000'), numpy.datetime64('2018-10-08T06:51:49.000000000'), numpy.datetime64('2018-10-08T06:52:07.000000000'), numpy.datetime64('2018-10-08T06:52:39.000000000'), numpy.datetime64('2018-10-08T06:53:18.000000000'), numpy.datetime64('2018-10-08T06:53:53.000000000'), numpy.datetime64('2018-10-08T08:36:15.000000000'), numpy.datetime64('2018-10-08T08:38:16.000000000'), numpy.datetime64('2018-10-08T08:38:49.000000000'), numpy.datetime64('2018-10-08T08:39:15.000000000'), numpy.datetime64('2018-10-08T08:39:44.000000000'), numpy.datetime64('2018-10-08T10:02:10.000000000'), numpy.datetime64('2018-10-08T12:15:58.000000000'), numpy.datetime64('2018-10-08T16:53:58.000000000'), numpy.datetime64('2018-10-08T20:34:42.000000000'), numpy.datetime64('2018-10-08T22:53:07.000000000'), numpy.datetime64('2018-10-08T23:20:18.000000000'), numpy.datetime64('2018-10-09T06:13:07.000000000'), numpy.datetime64('2018-10-09T10:36:44.000000000'), numpy.datetime64('2018-10-09T12:42:17.000000000'), numpy.datetime64('2018-10-09T14:22:57.000000000'), numpy.datetime64('2018-10-09T17:02:05.000000000'), numpy.datetime64('2018-10-09T20:36:46.000000000'), numpy.datetime64('2018-10-09T20:53:48.000000000'), numpy.datetime64('2018-10-09T21:12:14.000000000'), numpy.datetime64('2018-10-09T21:18:08.000000000'), numpy.datetime64('2018-10-09T21:18:34.000000000'), numpy.datetime64('2018-10-09T21:24:03.000000000'), numpy.datetime64('2018-10-09T21:33:43.000000000'), numpy.datetime64('2018-10-09T21:38:51.000000000'), numpy.datetime64('2018-10-09T21:43:45.000000000'), numpy.datetime64('2018-10-10T00:05:08.000000000'), numpy.datetime64('2018-10-10T02:13:25.000000000'), numpy.datetime64('2018-10-10T02:23:40.000000000'), numpy.datetime64('2018-10-10T02:38:09.000000000'), numpy.datetime64('2018-10-10T02:40:03.000000000'), numpy.datetime64('2018-10-10T02:59:31.000000000'), numpy.datetime64('2018-10-10T03:06:27.000000000'), numpy.datetime64('2018-10-10T03:10:14.000000000'), numpy.datetime64('2018-10-10T03:25:26.000000000'), numpy.datetime64('2018-10-10T03:57:40.000000000'), numpy.datetime64('2018-10-10T08:25:44.000000000'), numpy.datetime64('2018-10-10T09:49:32.000000000'), numpy.datetime64('2018-10-10T17:10:12.000000000'), numpy.datetime64('2018-10-11T00:20:40.000000000'), numpy.datetime64('2018-10-11T02:13:11.000000000'), numpy.datetime64('2018-10-11T04:14:54.000000000'), numpy.datetime64('2018-10-11T05:53:23.000000000'), numpy.datetime64('2018-10-11T06:09:33.000000000'), numpy.datetime64('2018-10-11T06:27:23.000000000'), numpy.datetime64('2018-10-11T13:36:26.000000000'), numpy.datetime64('2018-10-11T14:10:11.000000000'), numpy.datetime64('2018-10-11T14:31:46.000000000'), numpy.datetime64('2018-10-11T15:17:16.000000000'), numpy.datetime64('2018-10-11T15:22:01.000000000'), numpy.datetime64('2018-10-11T15:37:13.000000000'), numpy.datetime64('2018-10-11T18:11:07.000000000'), numpy.datetime64('2018-10-11T18:38:44.000000000'), numpy.datetime64('2018-10-11T22:01:00.000000000'), numpy.datetime64('2018-10-11T22:34:21.000000000'), numpy.datetime64('2018-10-12T00:19:38.000000000'), numpy.datetime64('2018-10-12T01:48:51.000000000'), numpy.datetime64('2018-10-12T03:46:17.000000000'), numpy.datetime64('2018-10-12T05:54:09.000000000'), numpy.datetime64('2018-10-12T07:43:17.000000000'), numpy.datetime64('2018-10-12T19:51:08.000000000'), numpy.datetime64('2018-10-12T20:12:15.000000000'), numpy.datetime64('2018-10-12T20:30:53.000000000'), numpy.datetime64('2018-10-13T01:58:08.000000000'), numpy.datetime64('2018-10-13T03:00:46.000000000'), numpy.datetime64('2018-10-13T05:31:36.000000000'), numpy.datetime64('2018-10-13T07:09:25.000000000'), numpy.datetime64('2018-10-13T12:13:03.000000000'), numpy.datetime64('2018-10-13T12:23:15.000000000'), numpy.datetime64('2018-10-13T14:39:13.000000000'), numpy.datetime64('2018-10-13T16:28:46.000000000'), numpy.datetime64('2018-10-14T00:15:28.000000000'), numpy.datetime64('2018-10-14T00:58:17.000000000'), numpy.datetime64('2018-10-14T01:41:28.000000000'), numpy.datetime64('2018-10-14T04:36:15.000000000'), numpy.datetime64('2018-10-14T04:45:33.000000000'), numpy.datetime64('2018-10-14T05:08:47.000000000'), numpy.datetime64('2018-10-14T07:01:28.000000000'), numpy.datetime64('2018-10-14T07:08:44.000000000'), numpy.datetime64('2018-10-14T07:09:04.000000000'), numpy.datetime64('2018-10-14T07:35:53.000000000'), numpy.datetime64('2018-10-14T07:40:23.000000000'), numpy.datetime64('2018-10-14T07:57:41.000000000'), numpy.datetime64('2018-10-14T08:38:48.000000000'), numpy.datetime64('2018-10-14T08:48:10.000000000'), numpy.datetime64('2018-10-14T08:54:57.000000000'), numpy.datetime64('2018-10-14T09:03:25.000000000'), numpy.datetime64('2018-10-14T09:18:19.000000000'), numpy.datetime64('2018-10-14T10:39:51.000000000'), numpy.datetime64('2018-10-14T10:47:41.000000000'), numpy.datetime64('2018-10-14T11:00:46.000000000'), numpy.datetime64('2018-10-14T11:05:52.000000000'), numpy.datetime64('2018-10-14T11:12:40.000000000'), numpy.datetime64('2018-10-14T11:27:58.000000000'), numpy.datetime64('2018-10-14T11:35:17.000000000'), numpy.datetime64('2018-10-14T11:48:09.000000000'), numpy.datetime64('2018-10-14T12:03:22.000000000'), numpy.datetime64('2018-10-14T12:18:02.000000000'), numpy.datetime64('2018-10-14T14:37:25.000000000'), numpy.datetime64('2018-10-14T14:56:32.000000000'), numpy.datetime64('2018-10-14T15:19:10.000000000'), numpy.datetime64('2018-10-14T16:32:31.000000000'), numpy.datetime64('2018-10-14T18:03:11.000000000'), numpy.datetime64('2018-10-14T20:35:48.000000000'), numpy.datetime64('2018-10-14T20:53:51.000000000'), numpy.datetime64('2018-10-14T21:35:57.000000000'), numpy.datetime64('2018-10-14T22:17:15.000000000'), numpy.datetime64('2018-10-14T22:27:01.000000000'), numpy.datetime64('2018-10-15T00:21:43.000000000'), numpy.datetime64('2018-10-15T01:26:55.000000000'), numpy.datetime64('2018-10-15T01:57:22.000000000'), numpy.datetime64('2018-10-15T02:38:39.000000000'), numpy.datetime64('2018-10-15T05:54:23.000000000'), numpy.datetime64('2018-10-15T07:16:19.000000000'), numpy.datetime64('2018-10-15T07:27:31.000000000'), numpy.datetime64('2018-10-15T07:40:45.000000000'), numpy.datetime64('2018-10-15T07:57:50.000000000'), numpy.datetime64('2018-10-15T08:20:13.000000000'), numpy.datetime64('2018-10-15T10:14:35.000000000'), numpy.datetime64('2018-10-15T11:05:12.000000000'), numpy.datetime64('2018-10-15T13:07:27.000000000'), numpy.datetime64('2018-10-15T19:06:40.000000000'), numpy.datetime64('2018-10-15T20:36:21.000000000'), numpy.datetime64('2018-10-15T21:11:16.000000000'), numpy.datetime64('2018-10-15T21:58:17.000000000'), numpy.datetime64('2018-10-15T22:00:13.000000000'), numpy.datetime64('2018-10-15T22:13:12.000000000'), numpy.datetime64('2018-10-15T22:32:46.000000000'), numpy.datetime64('2018-10-15T22:48:20.000000000'), numpy.datetime64('2018-10-15T23:01:42.000000000'), numpy.datetime64('2018-10-15T23:38:34.000000000'), numpy.datetime64('2018-10-16T00:00:08.000000000'), numpy.datetime64('2018-10-16T00:28:56.000000000'), numpy.datetime64('2018-10-16T00:50:43.000000000'), numpy.datetime64('2018-10-16T01:04:08.000000000'), numpy.datetime64('2018-10-16T01:40:55.000000000'), numpy.datetime64('2018-10-16T02:39:14.000000000'), numpy.datetime64('2018-10-16T02:53:28.000000000'), numpy.datetime64('2018-10-16T02:54:53.000000000'), numpy.datetime64('2018-10-16T02:58:34.000000000'), numpy.datetime64('2018-10-16T02:58:52.000000000'), numpy.datetime64('2018-10-16T03:50:34.000000000'), numpy.datetime64('2018-10-16T04:25:49.000000000'), numpy.datetime64('2018-10-16T04:46:40.000000000'), numpy.datetime64('2018-10-16T05:06:27.000000000'), numpy.datetime64('2018-10-16T05:12:49.000000000'), numpy.datetime64('2018-10-16T05:26:24.000000000'), numpy.datetime64('2018-10-16T06:13:35.000000000'), numpy.datetime64('2018-10-16T06:46:08.000000000'), numpy.datetime64('2018-10-16T06:47:02.000000000'), numpy.datetime64('2018-10-16T07:38:07.000000000'), numpy.datetime64('2018-10-16T08:08:37.000000000'), numpy.datetime64('2018-10-16T09:04:41.000000000'), numpy.datetime64('2018-10-16T11:06:35.000000000'), numpy.datetime64('2018-10-16T12:09:08.000000000'), numpy.datetime64('2018-10-16T12:19:07.000000000'), numpy.datetime64('2018-10-16T12:25:18.000000000'), numpy.datetime64('2018-10-16T12:28:20.000000000'), numpy.datetime64('2018-10-16T13:30:33.000000000'), numpy.datetime64('2018-10-16T13:41:14.000000000'), numpy.datetime64('2018-10-16T13:45:29.000000000'), numpy.datetime64('2018-10-16T14:59:05.000000000'), numpy.datetime64('2018-10-16T15:46:08.000000000'), numpy.datetime64('2018-10-16T20:06:31.000000000'), numpy.datetime64('2018-10-16T20:47:32.000000000'), numpy.datetime64('2018-10-16T21:03:37.000000000'), numpy.datetime64('2018-10-16T21:38:30.000000000'), numpy.datetime64('2018-10-16T21:53:42.000000000'), numpy.datetime64('2018-10-16T21:55:09.000000000'), numpy.datetime64('2018-10-16T22:34:03.000000000'), numpy.datetime64('2018-10-16T23:19:44.000000000'), numpy.datetime64('2018-10-16T23:45:09.000000000'), numpy.datetime64('2018-10-16T23:49:43.000000000'), numpy.datetime64('2018-10-17T00:24:44.000000000'), numpy.datetime64('2018-10-17T00:40:31.000000000'), numpy.datetime64('2018-10-17T00:47:52.000000000'), numpy.datetime64('2018-10-17T00:49:54.000000000'), numpy.datetime64('2018-10-17T01:27:44.000000000'), numpy.datetime64('2018-10-17T02:24:04.000000000'), numpy.datetime64('2018-10-17T02:27:38.000000000'), numpy.datetime64('2018-10-17T02:34:00.000000000'), numpy.datetime64('2018-10-17T05:40:14.000000000'), numpy.datetime64('2018-10-17T06:49:29.000000000'), numpy.datetime64('2018-10-17T07:02:59.000000000'), numpy.datetime64('2018-10-17T07:51:53.000000000'), numpy.datetime64('2018-10-17T08:47:54.000000000'), numpy.datetime64('2018-10-17T09:36:00.000000000'), numpy.datetime64('2018-10-17T09:55:21.000000000'), numpy.datetime64('2018-10-17T10:41:24.000000000'), numpy.datetime64('2018-10-17T11:01:21.000000000'), numpy.datetime64('2018-10-17T11:29:24.000000000'), numpy.datetime64('2018-10-17T12:06:58.000000000'), numpy.datetime64('2018-10-17T12:18:42.000000000'), numpy.datetime64('2018-10-17T12:30:28.000000000'), numpy.datetime64('2018-10-17T12:42:36.000000000'), numpy.datetime64('2018-10-17T13:30:58.000000000'), numpy.datetime64('2018-10-17T14:13:49.000000000'), numpy.datetime64('2018-10-17T14:36:01.000000000'), numpy.datetime64('2018-10-17T14:51:11.000000000'), numpy.datetime64('2018-10-17T14:56:11.000000000'), numpy.datetime64('2018-10-17T15:20:23.000000000'), numpy.datetime64('2018-10-17T15:51:50.000000000'), numpy.datetime64('2018-10-17T15:53:34.000000000'), numpy.datetime64('2018-10-17T16:11:52.000000000'), numpy.datetime64('2018-10-17T16:20:05.000000000'), numpy.datetime64('2018-10-17T17:10:03.000000000'), numpy.datetime64('2018-10-17T18:07:14.000000000'), numpy.datetime64('2018-10-17T19:24:50.000000000'), numpy.datetime64('2018-10-17T19:37:19.000000000'), numpy.datetime64('2018-10-17T19:44:25.000000000'), numpy.datetime64('2018-10-17T19:49:12.000000000'), numpy.datetime64('2018-10-17T20:29:33.000000000'), numpy.datetime64('2018-10-17T20:46:42.000000000'), numpy.datetime64('2018-10-17T21:35:11.000000000'), numpy.datetime64('2018-10-17T21:38:58.000000000'), numpy.datetime64('2018-10-17T21:57:58.000000000'), numpy.datetime64('2018-10-17T22:11:42.000000000'), numpy.datetime64('2018-10-17T23:05:53.000000000'), numpy.datetime64('2018-10-18T03:04:51.000000000'), numpy.datetime64('2018-10-18T05:25:04.000000000'), numpy.datetime64('2018-10-18T05:43:45.000000000'), numpy.datetime64('2018-10-18T06:42:54.000000000'), numpy.datetime64('2018-10-18T07:11:17.000000000'), numpy.datetime64('2018-10-18T07:47:58.000000000'), numpy.datetime64('2018-10-18T07:55:29.000000000'), numpy.datetime64('2018-10-18T07:59:50.000000000'), numpy.datetime64('2018-10-18T08:08:17.000000000'), numpy.datetime64('2018-10-18T09:51:23.000000000'), numpy.datetime64('2018-10-18T11:29:50.000000000'), numpy.datetime64('2018-10-18T11:48:23.000000000'), numpy.datetime64('2018-10-18T12:49:20.000000000'), numpy.datetime64('2018-10-18T12:52:34.000000000'), numpy.datetime64('2018-10-18T12:53:11.000000000'), numpy.datetime64('2018-10-18T13:17:45.000000000'), numpy.datetime64('2018-10-18T13:38:45.000000000'), numpy.datetime64('2018-10-18T13:41:08.000000000'), numpy.datetime64('2018-10-18T14:12:59.000000000'), numpy.datetime64('2018-10-18T15:00:43.000000000'), numpy.datetime64('2018-10-18T15:15:03.000000000'), numpy.datetime64('2018-10-18T15:15:10.000000000'), numpy.datetime64('2018-10-18T15:25:12.000000000'), numpy.datetime64('2018-10-18T15:44:04.000000000'), numpy.datetime64('2018-10-18T15:48:37.000000000'), numpy.datetime64('2018-10-18T16:30:43.000000000'), numpy.datetime64('2018-10-18T16:37:50.000000000'), numpy.datetime64('2018-10-18T16:42:32.000000000'), numpy.datetime64('2018-10-18T17:00:41.000000000'), numpy.datetime64('2018-10-18T17:06:24.000000000'), numpy.datetime64('2018-10-18T18:04:25.000000000'), numpy.datetime64('2018-10-18T18:18:58.000000000'), numpy.datetime64('2018-10-18T19:50:53.000000000'), numpy.datetime64('2018-10-18T20:37:03.000000000'), numpy.datetime64('2018-10-18T20:58:27.000000000'), numpy.datetime64('2018-10-18T22:06:31.000000000'), numpy.datetime64('2018-10-18T22:08:20.000000000'), numpy.datetime64('2018-10-18T22:29:05.000000000'), numpy.datetime64('2018-10-18T22:36:48.000000000'), numpy.datetime64('2018-10-18T22:51:51.000000000'), numpy.datetime64('2018-10-18T23:20:34.000000000'), numpy.datetime64('2018-10-19T00:20:46.000000000'), numpy.datetime64('2018-10-19T00:52:39.000000000'), numpy.datetime64('2018-10-19T01:08:04.000000000'), numpy.datetime64('2018-10-19T08:43:08.000000000'), numpy.datetime64('2018-10-19T09:21:08.000000000'), numpy.datetime64('2018-10-19T09:54:44.000000000'), numpy.datetime64('2018-10-19T11:34:29.000000000'), numpy.datetime64('2018-10-19T12:49:46.000000000'), numpy.datetime64('2018-10-19T14:04:45.000000000'), numpy.datetime64('2018-10-19T14:26:07.000000000'), numpy.datetime64('2018-10-19T15:58:11.000000000'), numpy.datetime64('2018-10-19T17:13:11.000000000'), numpy.datetime64('2018-10-19T18:39:59.000000000'), numpy.datetime64('2018-10-19T20:56:06.000000000'), numpy.datetime64('2018-10-19T21:39:34.000000000'), numpy.datetime64('2018-10-19T21:51:39.000000000'), numpy.datetime64('2018-10-19T21:54:04.000000000'), numpy.datetime64('2018-10-19T22:17:32.000000000'), numpy.datetime64('2018-10-19T22:46:53.000000000'), numpy.datetime64('2018-10-19T22:52:23.000000000'), numpy.datetime64('2018-10-19T23:01:05.000000000'), numpy.datetime64('2018-10-19T23:32:42.000000000'), numpy.datetime64('2018-10-19T23:52:01.000000000'), numpy.datetime64('2018-10-19T23:54:47.000000000'), numpy.datetime64('2018-10-20T00:45:43.000000000'), numpy.datetime64('2018-10-20T00:51:55.000000000'), numpy.datetime64('2018-10-20T00:57:07.000000000'), numpy.datetime64('2018-10-20T04:09:58.000000000'), numpy.datetime64('2018-10-20T05:04:49.000000000'), numpy.datetime64('2018-10-20T05:50:37.000000000'), numpy.datetime64('2018-10-20T07:02:20.000000000'), numpy.datetime64('2018-10-20T08:54:08.000000000'), numpy.datetime64('2018-10-20T10:07:14.000000000'), numpy.datetime64('2018-10-20T10:43:29.000000000'), numpy.datetime64('2018-10-20T12:27:22.000000000'), numpy.datetime64('2018-10-20T14:27:06.000000000'), numpy.datetime64('2018-10-20T15:19:06.000000000'), numpy.datetime64('2018-10-20T16:30:59.000000000'), numpy.datetime64('2018-10-20T16:46:37.000000000'), numpy.datetime64('2018-10-20T16:47:09.000000000'), numpy.datetime64('2018-10-20T17:16:06.000000000'), numpy.datetime64('2018-10-20T17:32:47.000000000'), numpy.datetime64('2018-10-20T17:37:00.000000000'), numpy.datetime64('2018-10-20T17:57:57.000000000'), numpy.datetime64('2018-10-20T18:15:31.000000000'), numpy.datetime64('2018-10-20T18:41:02.000000000'), numpy.datetime64('2018-10-20T19:05:17.000000000'), numpy.datetime64('2018-10-20T19:21:34.000000000'), numpy.datetime64('2018-10-20T20:48:10.000000000'), numpy.datetime64('2018-10-20T21:44:18.000000000'), numpy.datetime64('2018-10-20T23:38:57.000000000'), numpy.datetime64('2018-10-21T00:10:32.000000000'), numpy.datetime64('2018-10-21T00:50:07.000000000'), numpy.datetime64('2018-10-21T01:04:42.000000000'), numpy.datetime64('2018-10-21T01:23:57.000000000'), numpy.datetime64('2018-10-21T01:58:11.000000000'), numpy.datetime64('2018-10-21T02:29:37.000000000'), numpy.datetime64('2018-10-21T03:34:09.000000000'), numpy.datetime64('2018-10-21T06:13:52.000000000'), numpy.datetime64('2018-10-21T06:38:19.000000000'), numpy.datetime64('2018-10-21T07:17:50.000000000'), numpy.datetime64('2018-10-21T07:45:20.000000000'), numpy.datetime64('2018-10-21T08:41:17.000000000'), numpy.datetime64('2018-10-21T08:42:13.000000000'), numpy.datetime64('2018-10-21T10:06:33.000000000'), numpy.datetime64('2018-10-21T10:26:09.000000000'), numpy.datetime64('2018-10-21T10:36:53.000000000'), numpy.datetime64('2018-10-21T10:53:16.000000000'), numpy.datetime64('2018-10-21T11:02:40.000000000'), numpy.datetime64('2018-10-21T11:57:57.000000000'), numpy.datetime64('2018-10-21T12:00:34.000000000'), numpy.datetime64('2018-10-21T12:09:44.000000000'), numpy.datetime64('2018-10-21T12:21:32.000000000'), numpy.datetime64('2018-10-21T12:47:50.000000000'), numpy.datetime64('2018-10-21T12:55:39.000000000'), numpy.datetime64('2018-10-21T13:05:14.000000000'), numpy.datetime64('2018-10-21T13:16:41.000000000'), numpy.datetime64('2018-10-21T13:47:22.000000000'), numpy.datetime64('2018-10-21T14:26:39.000000000'), numpy.datetime64('2018-10-21T16:45:09.000000000'), numpy.datetime64('2018-10-21T19:33:33.000000000'), numpy.datetime64('2018-10-21T20:42:42.000000000'), numpy.datetime64('2018-10-21T21:17:59.000000000'), numpy.datetime64('2018-10-21T21:18:13.000000000'), numpy.datetime64('2018-10-21T21:40:43.000000000'), numpy.datetime64('2018-10-21T22:35:45.000000000'), numpy.datetime64('2018-10-21T23:26:01.000000000'), numpy.datetime64('2018-10-21T23:42:49.000000000'), numpy.datetime64('2018-10-21T23:43:53.000000000'), numpy.datetime64('2018-10-22T00:44:36.000000000'), numpy.datetime64('2018-10-22T02:33:03.000000000'), numpy.datetime64('2018-10-22T02:45:20.000000000'), numpy.datetime64('2018-10-22T03:59:51.000000000'), numpy.datetime64('2018-10-22T04:49:47.000000000'), numpy.datetime64('2018-10-22T05:41:21.000000000'), numpy.datetime64('2018-10-22T06:20:07.000000000'), numpy.datetime64('2018-10-22T06:23:53.000000000'), numpy.datetime64('2018-10-22T07:09:02.000000000'), numpy.datetime64('2018-10-22T07:24:04.000000000'), numpy.datetime64('2018-10-22T09:48:14.000000000'), numpy.datetime64('2018-10-22T11:01:19.000000000'), numpy.datetime64('2018-10-22T11:31:53.000000000'), numpy.datetime64('2018-10-22T11:41:07.000000000'), numpy.datetime64('2018-10-22T11:55:35.000000000'), numpy.datetime64('2018-10-22T15:08:26.000000000'), numpy.datetime64('2018-10-22T15:18:17.000000000'), numpy.datetime64('2018-10-22T15:49:44.000000000'), numpy.datetime64('2018-10-22T15:59:09.000000000'), numpy.datetime64('2018-10-22T16:03:20.000000000'), numpy.datetime64('2018-10-22T16:36:23.000000000'), numpy.datetime64('2018-10-22T16:39:07.000000000'), numpy.datetime64('2018-10-22T17:46:47.000000000'), numpy.datetime64('2018-10-22T17:57:31.000000000'), numpy.datetime64('2018-10-22T18:17:35.000000000'), numpy.datetime64('2018-10-22T18:39:50.000000000'), numpy.datetime64('2018-10-22T18:42:16.000000000'), numpy.datetime64('2018-10-22T18:54:43.000000000'), numpy.datetime64('2018-10-22T18:55:43.000000000'), numpy.datetime64('2018-10-22T19:30:56.000000000'), numpy.datetime64('2018-10-22T19:44:35.000000000'), numpy.datetime64('2018-10-22T19:53:50.000000000'), numpy.datetime64('2018-10-22T20:16:19.000000000'), numpy.datetime64('2018-10-22T21:44:05.000000000'), numpy.datetime64('2018-10-22T22:06:53.000000000'), numpy.datetime64('2018-10-22T22:13:05.000000000'), numpy.datetime64('2018-10-22T22:14:56.000000000'), numpy.datetime64('2018-10-22T22:25:13.000000000'), numpy.datetime64('2018-10-22T23:35:35.000000000'), numpy.datetime64('2018-10-22T23:41:20.000000000'), numpy.datetime64('2018-10-23T01:30:22.000000000'), numpy.datetime64('2018-10-23T02:04:03.000000000'), numpy.datetime64('2018-10-23T02:28:37.000000000'), numpy.datetime64('2018-10-23T02:52:42.000000000'), numpy.datetime64('2018-10-23T04:37:03.000000000'), numpy.datetime64('2018-10-23T05:03:57.000000000'), numpy.datetime64('2018-10-23T05:53:00.000000000'), numpy.datetime64('2018-10-23T05:54:41.000000000'), numpy.datetime64('2018-10-23T06:45:33.000000000'), numpy.datetime64('2018-10-23T10:03:13.000000000'), numpy.datetime64('2018-10-23T10:47:10.000000000'), numpy.datetime64('2018-10-23T11:53:11.000000000'), numpy.datetime64('2018-10-23T12:10:56.000000000'), numpy.datetime64('2018-10-23T12:34:19.000000000'), numpy.datetime64('2018-10-23T14:09:36.000000000'), numpy.datetime64('2018-10-23T14:30:55.000000000'), numpy.datetime64('2018-10-23T17:46:29.000000000'), numpy.datetime64('2018-10-23T18:09:27.000000000'), numpy.datetime64('2018-10-23T18:31:24.000000000'), numpy.datetime64('2018-10-23T18:46:53.000000000'), numpy.datetime64('2018-10-23T20:39:03.000000000'), numpy.datetime64('2018-10-23T21:28:00.000000000'), numpy.datetime64('2018-10-23T21:47:34.000000000'), numpy.datetime64('2018-10-23T21:52:09.000000000'), numpy.datetime64('2018-10-23T22:08:45.000000000'), numpy.datetime64('2018-10-23T22:13:08.000000000'), numpy.datetime64('2018-10-23T23:04:25.000000000'), numpy.datetime64('2018-10-23T23:37:13.000000000'), numpy.datetime64('2018-10-23T23:55:58.000000000'), numpy.datetime64('2018-10-24T00:28:51.000000000'), numpy.datetime64('2018-10-24T00:41:51.000000000'), numpy.datetime64('2018-10-24T00:42:57.000000000'), numpy.datetime64('2018-10-24T00:43:21.000000000'), numpy.datetime64('2018-10-24T00:55:06.000000000'), numpy.datetime64('2018-10-24T01:24:20.000000000'), numpy.datetime64('2018-10-24T01:25:10.000000000'), numpy.datetime64('2018-10-24T01:34:21.000000000'), numpy.datetime64('2018-10-24T02:10:50.000000000'), numpy.datetime64('2018-10-24T02:27:39.000000000'), numpy.datetime64('2018-10-24T02:28:07.000000000'), numpy.datetime64('2018-10-24T03:09:46.000000000'), numpy.datetime64('2018-10-24T03:49:02.000000000'), numpy.datetime64('2018-10-24T03:57:19.000000000'), numpy.datetime64('2018-10-24T04:11:35.000000000'), numpy.datetime64('2018-10-24T04:15:37.000000000'), numpy.datetime64('2018-10-24T04:28:35.000000000'), numpy.datetime64('2018-10-24T04:39:41.000000000'), numpy.datetime64('2018-10-24T04:51:03.000000000'), numpy.datetime64('2018-10-24T05:12:21.000000000'), numpy.datetime64('2018-10-24T05:13:09.000000000'), numpy.datetime64('2018-10-24T05:32:42.000000000'), numpy.datetime64('2018-10-24T05:37:14.000000000'), numpy.datetime64('2018-10-24T05:40:12.000000000'), numpy.datetime64('2018-10-24T05:46:39.000000000'), numpy.datetime64('2018-10-24T06:17:37.000000000'), numpy.datetime64('2018-10-24T06:24:04.000000000'), numpy.datetime64('2018-10-24T06:44:53.000000000'), numpy.datetime64('2018-10-24T06:57:18.000000000'), numpy.datetime64('2018-10-24T07:17:35.000000000'), numpy.datetime64('2018-10-24T07:35:27.000000000'), numpy.datetime64('2018-10-24T07:35:48.000000000'), numpy.datetime64('2018-10-24T07:36:21.000000000'), numpy.datetime64('2018-10-24T07:40:30.000000000'), numpy.datetime64('2018-10-24T07:46:24.000000000'), numpy.datetime64('2018-10-24T08:27:45.000000000'), numpy.datetime64('2018-10-24T08:29:17.000000000'), numpy.datetime64('2018-10-24T08:37:24.000000000'), numpy.datetime64('2018-10-24T09:23:52.000000000'), numpy.datetime64('2018-10-24T09:37:20.000000000'), numpy.datetime64('2018-10-24T10:15:00.000000000'), numpy.datetime64('2018-10-24T10:21:59.000000000'), numpy.datetime64('2018-10-24T10:32:57.000000000'), numpy.datetime64('2018-10-24T10:44:56.000000000'), numpy.datetime64('2018-10-24T11:34:30.000000000'), numpy.datetime64('2018-10-24T12:03:30.000000000'), numpy.datetime64('2018-10-24T12:25:28.000000000'), numpy.datetime64('2018-10-24T12:42:41.000000000'), numpy.datetime64('2018-10-24T14:03:22.000000000'), numpy.datetime64('2018-10-24T15:32:21.000000000'), numpy.datetime64('2018-10-24T17:30:11.000000000'), numpy.datetime64('2018-10-24T18:37:43.000000000'), numpy.datetime64('2018-10-24T18:39:45.000000000'), numpy.datetime64('2018-10-24T18:42:02.000000000'), numpy.datetime64('2018-10-24T18:42:34.000000000'), numpy.datetime64('2018-10-24T18:50:18.000000000'), numpy.datetime64('2018-10-24T18:56:20.000000000'), numpy.datetime64('2018-10-24T19:26:22.000000000'), numpy.datetime64('2018-10-24T19:33:37.000000000'), numpy.datetime64('2018-10-24T20:36:53.000000000'), numpy.datetime64('2018-10-24T20:44:00.000000000'), numpy.datetime64('2018-10-25T05:19:36.000000000'), numpy.datetime64('2018-10-25T07:18:24.000000000'), numpy.datetime64('2018-10-25T11:18:38.000000000'), numpy.datetime64('2018-10-25T11:37:23.000000000'), numpy.datetime64('2018-10-25T11:44:26.000000000'), numpy.datetime64('2018-10-25T12:17:43.000000000'), numpy.datetime64('2018-10-25T12:20:08.000000000'), numpy.datetime64('2018-10-25T12:21:06.000000000'), numpy.datetime64('2018-10-25T13:43:06.000000000'), numpy.datetime64('2018-10-25T14:30:04.000000000'), numpy.datetime64('2018-10-25T14:55:52.000000000'), numpy.datetime64('2018-10-25T15:38:59.000000000'), numpy.datetime64('2018-10-25T15:59:18.000000000'), numpy.datetime64('2018-10-25T16:26:55.000000000'), numpy.datetime64('2018-10-25T17:59:36.000000000'), numpy.datetime64('2018-10-25T21:43:58.000000000'), numpy.datetime64('2018-10-25T22:16:51.000000000'), numpy.datetime64('2018-10-25T22:39:44.000000000'), numpy.datetime64('2018-10-26T01:16:35.000000000'), numpy.datetime64('2018-10-26T04:54:28.000000000'), numpy.datetime64('2018-10-26T06:11:25.000000000'), numpy.datetime64('2018-10-26T07:57:50.000000000'), numpy.datetime64('2018-10-26T08:50:28.000000000'), numpy.datetime64('2018-10-26T09:04:10.000000000'), numpy.datetime64('2018-10-26T09:25:58.000000000'), numpy.datetime64('2018-10-26T10:01:01.000000000'), numpy.datetime64('2018-10-26T10:13:16.000000000'), numpy.datetime64('2018-10-26T10:32:54.000000000'), numpy.datetime64('2018-10-26T11:37:09.000000000'), numpy.datetime64('2018-10-26T12:39:25.000000000'), numpy.datetime64('2018-10-26T12:48:07.000000000'), numpy.datetime64('2018-10-26T12:58:41.000000000'), numpy.datetime64('2018-10-26T13:36:14.000000000'), numpy.datetime64('2018-10-26T13:47:10.000000000'), numpy.datetime64('2018-10-26T13:56:32.000000000'), numpy.datetime64('2018-10-26T16:04:56.000000000'), numpy.datetime64('2018-10-26T18:01:37.000000000'), numpy.datetime64('2018-10-26T18:06:31.000000000'), numpy.datetime64('2018-10-26T18:10:32.000000000'), numpy.datetime64('2018-10-26T18:24:29.000000000'), numpy.datetime64('2018-10-26T18:34:55.000000000'), numpy.datetime64('2018-10-26T19:08:54.000000000'), numpy.datetime64('2018-10-26T19:21:00.000000000'), numpy.datetime64('2018-10-26T19:48:07.000000000'), numpy.datetime64('2018-10-26T20:02:46.000000000'), numpy.datetime64('2018-10-26T20:19:03.000000000'), numpy.datetime64('2018-10-26T20:30:20.000000000'), numpy.datetime64('2018-10-26T21:18:22.000000000'), numpy.datetime64('2018-10-26T21:36:20.000000000'), numpy.datetime64('2018-10-26T21:42:00.000000000'), numpy.datetime64('2018-10-26T22:00:33.000000000'), numpy.datetime64('2018-10-26T22:09:33.000000000'), numpy.datetime64('2018-10-26T22:13:27.000000000'), numpy.datetime64('2018-10-26T22:20:40.000000000'), numpy.datetime64('2018-10-26T22:30:26.000000000'), numpy.datetime64('2018-10-26T22:42:34.000000000'), numpy.datetime64('2018-10-26T22:47:09.000000000'), numpy.datetime64('2018-10-26T22:56:59.000000000'), numpy.datetime64('2018-10-26T23:04:37.000000000'), numpy.datetime64('2018-10-26T23:24:02.000000000'), numpy.datetime64('2018-10-26T23:29:03.000000000'), numpy.datetime64('2018-10-26T23:32:32.000000000'), numpy.datetime64('2018-10-26T23:42:49.000000000'), numpy.datetime64('2018-10-26T23:57:04.000000000'), numpy.datetime64('2018-10-27T00:18:03.000000000'), numpy.datetime64('2018-10-27T00:30:16.000000000'), numpy.datetime64('2018-10-27T00:51:54.000000000'), numpy.datetime64('2018-10-27T00:57:22.000000000'), numpy.datetime64('2018-10-27T01:31:33.000000000'), numpy.datetime64('2018-10-27T01:52:56.000000000'), numpy.datetime64('2018-10-27T01:53:15.000000000'), numpy.datetime64('2018-10-27T02:44:01.000000000'), numpy.datetime64('2018-10-27T02:47:34.000000000'), numpy.datetime64('2018-10-27T03:04:10.000000000'), numpy.datetime64('2018-10-27T03:36:30.000000000'), numpy.datetime64('2018-10-27T04:00:07.000000000'), numpy.datetime64('2018-10-27T04:10:28.000000000'), numpy.datetime64('2018-10-27T04:12:10.000000000'), numpy.datetime64('2018-10-27T04:29:08.000000000'), numpy.datetime64('2018-10-27T04:40:44.000000000'), numpy.datetime64('2018-10-27T05:49:47.000000000'), numpy.datetime64('2018-10-27T06:04:22.000000000'), numpy.datetime64('2018-10-27T06:06:57.000000000'), numpy.datetime64('2018-10-27T06:29:11.000000000'), numpy.datetime64('2018-10-27T06:29:51.000000000'), numpy.datetime64('2018-10-27T06:34:25.000000000'), numpy.datetime64('2018-10-27T06:49:04.000000000'), numpy.datetime64('2018-10-27T06:54:38.000000000'), numpy.datetime64('2018-10-27T06:57:35.000000000'), numpy.datetime64('2018-10-27T07:23:36.000000000'), numpy.datetime64('2018-10-27T07:25:05.000000000'), numpy.datetime64('2018-10-27T08:16:43.000000000'), numpy.datetime64('2018-10-27T08:36:35.000000000'), numpy.datetime64('2018-10-27T08:44:37.000000000'), numpy.datetime64('2018-10-27T08:55:54.000000000'), numpy.datetime64('2018-10-27T09:23:13.000000000'), numpy.datetime64('2018-10-27T09:44:07.000000000'), numpy.datetime64('2018-10-27T09:46:41.000000000'), numpy.datetime64('2018-10-27T09:48:21.000000000'), numpy.datetime64('2018-10-27T10:08:09.000000000'), numpy.datetime64('2018-10-27T10:10:40.000000000'), numpy.datetime64('2018-10-27T10:14:41.000000000'), numpy.datetime64('2018-10-27T10:25:13.000000000'), numpy.datetime64('2018-10-27T10:25:32.000000000'), numpy.datetime64('2018-10-27T10:33:52.000000000'), numpy.datetime64('2018-10-27T10:56:51.000000000'), numpy.datetime64('2018-10-27T10:58:03.000000000'), numpy.datetime64('2018-10-27T11:01:11.000000000'), numpy.datetime64('2018-10-27T11:05:22.000000000'), numpy.datetime64('2018-10-27T11:21:58.000000000'), numpy.datetime64('2018-10-27T11:36:46.000000000'), numpy.datetime64('2018-10-27T11:45:23.000000000'), numpy.datetime64('2018-10-27T11:52:59.000000000'), numpy.datetime64('2018-10-27T12:08:14.000000000'), numpy.datetime64('2018-10-27T12:08:54.000000000'), numpy.datetime64('2018-10-27T12:08:56.000000000'), numpy.datetime64('2018-10-27T12:10:37.000000000'), numpy.datetime64('2018-10-27T12:13:38.000000000'), numpy.datetime64('2018-10-27T12:19:41.000000000'), numpy.datetime64('2018-10-27T12:21:49.000000000'), numpy.datetime64('2018-10-27T12:27:39.000000000'), numpy.datetime64('2018-10-27T12:42:24.000000000'), numpy.datetime64('2018-10-27T12:47:57.000000000'), numpy.datetime64('2018-10-27T12:53:31.000000000'), numpy.datetime64('2018-10-27T12:53:39.000000000'), numpy.datetime64('2018-10-27T13:14:41.000000000'), numpy.datetime64('2018-10-27T13:38:01.000000000'), numpy.datetime64('2018-10-27T18:39:27.000000000'), numpy.datetime64('2018-10-27T19:00:09.000000000'), numpy.datetime64('2018-10-27T19:01:03.000000000'), numpy.datetime64('2018-10-27T19:02:38.000000000'), numpy.datetime64('2018-10-27T19:09:14.000000000'), numpy.datetime64('2018-10-27T19:35:34.000000000'), numpy.datetime64('2018-10-27T19:39:13.000000000'), numpy.datetime64('2018-10-27T19:48:27.000000000'), numpy.datetime64('2018-10-27T20:18:10.000000000'), numpy.datetime64('2018-10-27T21:39:00.000000000'), numpy.datetime64('2018-10-27T22:36:46.000000000'), numpy.datetime64('2018-10-27T22:47:46.000000000'), numpy.datetime64('2018-10-27T22:55:01.000000000'), numpy.datetime64('2018-10-27T23:23:39.000000000'), numpy.datetime64('2018-10-27T23:29:10.000000000'), numpy.datetime64('2018-10-27T23:30:13.000000000'), numpy.datetime64('2018-10-27T23:31:48.000000000'), numpy.datetime64('2018-10-28T00:09:48.000000000'), numpy.datetime64('2018-10-28T00:21:42.000000000'), numpy.datetime64('2018-10-28T00:45:44.000000000'), numpy.datetime64('2018-10-28T00:47:25.000000000'), numpy.datetime64('2018-10-28T00:49:02.000000000'), numpy.datetime64('2018-10-28T00:56:57.000000000'), numpy.datetime64('2018-10-28T01:40:26.000000000'), numpy.datetime64('2018-10-28T01:54:01.000000000'), numpy.datetime64('2018-10-28T01:56:32.000000000'), numpy.datetime64('2018-10-28T01:59:02.000000000'), numpy.datetime64('2018-10-28T02:03:11.000000000'), numpy.datetime64('2018-10-28T02:09:39.000000000'), numpy.datetime64('2018-10-28T02:20:53.000000000'), numpy.datetime64('2018-10-28T02:31:44.000000000'), numpy.datetime64('2018-10-28T02:32:42.000000000'), numpy.datetime64('2018-10-28T02:37:11.000000000'), numpy.datetime64('2018-10-28T02:42:41.000000000'), numpy.datetime64('2018-10-28T02:50:47.000000000'), numpy.datetime64('2018-10-28T02:57:59.000000000'), numpy.datetime64('2018-10-28T02:59:22.000000000'), numpy.datetime64('2018-10-28T03:05:59.000000000'), numpy.datetime64('2018-10-28T03:10:30.000000000'), numpy.datetime64('2018-10-28T03:24:46.000000000'), numpy.datetime64('2018-10-28T04:14:36.000000000'), numpy.datetime64('2018-10-28T04:27:25.000000000'), numpy.datetime64('2018-10-28T04:38:50.000000000'), numpy.datetime64('2018-10-28T04:40:39.000000000'), numpy.datetime64('2018-10-28T05:23:16.000000000'), numpy.datetime64('2018-10-28T05:30:27.000000000'), numpy.datetime64('2018-10-28T05:38:34.000000000'), numpy.datetime64('2018-10-28T05:44:22.000000000'), numpy.datetime64('2018-10-28T06:13:46.000000000'), numpy.datetime64('2018-10-28T06:40:19.000000000'), numpy.datetime64('2018-10-28T07:13:25.000000000'), numpy.datetime64('2018-10-28T07:13:31.000000000'), numpy.datetime64('2018-10-28T07:25:47.000000000'), numpy.datetime64('2018-10-28T07:56:18.000000000'), numpy.datetime64('2018-10-28T08:10:57.000000000'), numpy.datetime64('2018-10-28T08:14:08.000000000'), numpy.datetime64('2018-10-28T08:22:06.000000000'), numpy.datetime64('2018-10-28T08:34:34.000000000'), numpy.datetime64('2018-10-28T08:47:02.000000000'), numpy.datetime64('2018-10-28T08:50:15.000000000'), numpy.datetime64('2018-10-28T08:51:04.000000000'), numpy.datetime64('2018-10-28T08:51:32.000000000'), numpy.datetime64('2018-10-28T09:15:11.000000000'), numpy.datetime64('2018-10-28T09:19:47.000000000'), numpy.datetime64('2018-10-28T09:29:03.000000000'), numpy.datetime64('2018-10-28T09:36:59.000000000'), numpy.datetime64('2018-10-28T09:37:13.000000000'), numpy.datetime64('2018-10-28T09:55:49.000000000'), numpy.datetime64('2018-10-28T10:39:56.000000000'), numpy.datetime64('2018-10-28T11:11:27.000000000'), numpy.datetime64('2018-10-28T11:12:35.000000000'), numpy.datetime64('2018-10-28T11:13:47.000000000'), numpy.datetime64('2018-10-28T11:15:47.000000000'), numpy.datetime64('2018-10-28T11:18:43.000000000'), numpy.datetime64('2018-10-28T11:41:12.000000000'), numpy.datetime64('2018-10-28T12:28:20.000000000'), numpy.datetime64('2018-10-28T12:57:45.000000000'), numpy.datetime64('2018-10-28T13:34:28.000000000'), numpy.datetime64('2018-10-28T14:01:02.000000000'), numpy.datetime64('2018-10-28T14:03:46.000000000'), numpy.datetime64('2018-10-28T14:28:13.000000000'), numpy.datetime64('2018-10-28T14:32:13.000000000'), numpy.datetime64('2018-10-28T14:33:35.000000000'), numpy.datetime64('2018-10-28T14:57:00.000000000'), numpy.datetime64('2018-10-28T15:01:01.000000000'), numpy.datetime64('2018-10-28T15:07:06.000000000'), numpy.datetime64('2018-10-28T15:11:11.000000000'), numpy.datetime64('2018-10-28T15:12:51.000000000'), numpy.datetime64('2018-10-28T15:13:00.000000000'), numpy.datetime64('2018-10-28T15:14:39.000000000'), numpy.datetime64('2018-10-28T16:34:45.000000000'), numpy.datetime64('2018-10-28T17:13:20.000000000'), numpy.datetime64('2018-10-28T17:19:24.000000000'), numpy.datetime64('2018-10-28T17:38:27.000000000'), numpy.datetime64('2018-10-28T17:44:38.000000000'), numpy.datetime64('2018-10-28T18:10:54.000000000'), numpy.datetime64('2018-10-28T18:55:37.000000000'), numpy.datetime64('2018-10-28T19:03:06.000000000'), numpy.datetime64('2018-10-28T19:06:31.000000000'), numpy.datetime64('2018-10-28T19:09:38.000000000'), numpy.datetime64('2018-10-28T19:13:00.000000000'), numpy.datetime64('2018-10-28T19:32:31.000000000'), numpy.datetime64('2018-10-28T19:34:53.000000000'), numpy.datetime64('2018-10-28T19:47:17.000000000'), numpy.datetime64('2018-10-28T19:49:31.000000000'), numpy.datetime64('2018-10-28T19:53:48.000000000'), numpy.datetime64('2018-10-28T20:56:40.000000000'), numpy.datetime64('2018-10-28T21:39:56.000000000'), numpy.datetime64('2018-10-28T21:55:25.000000000'), numpy.datetime64('2018-10-29T00:06:47.000000000'), numpy.datetime64('2018-10-29T01:16:43.000000000'), numpy.datetime64('2018-10-29T01:16:52.000000000'), numpy.datetime64('2018-10-29T01:31:08.000000000'), numpy.datetime64('2018-10-29T02:14:25.000000000'), numpy.datetime64('2018-10-29T03:02:14.000000000'), numpy.datetime64('2018-10-29T03:32:51.000000000'), numpy.datetime64('2018-10-29T03:38:47.000000000'), numpy.datetime64('2018-10-29T04:10:26.000000000'), numpy.datetime64('2018-10-29T04:17:35.000000000'), numpy.datetime64('2018-10-29T04:34:05.000000000'), numpy.datetime64('2018-10-29T04:40:40.000000000'), numpy.datetime64('2018-10-29T04:48:51.000000000'), numpy.datetime64('2018-10-29T05:54:24.000000000'), numpy.datetime64('2018-10-29T05:55:12.000000000'), numpy.datetime64('2018-10-29T06:04:03.000000000'), numpy.datetime64('2018-10-29T06:30:05.000000000'), numpy.datetime64('2018-10-29T06:37:33.000000000'), numpy.datetime64('2018-10-29T06:49:56.000000000'), numpy.datetime64('2018-10-29T07:00:46.000000000'), numpy.datetime64('2018-10-29T07:07:56.000000000'), numpy.datetime64('2018-10-29T07:09:12.000000000'), numpy.datetime64('2018-10-29T07:40:22.000000000'), numpy.datetime64('2018-10-29T07:41:26.000000000'), numpy.datetime64('2018-10-29T09:12:28.000000000'), numpy.datetime64('2018-10-29T09:47:47.000000000'), numpy.datetime64('2018-10-29T09:55:25.000000000'), numpy.datetime64('2018-10-29T10:23:19.000000000'), numpy.datetime64('2018-10-29T10:46:50.000000000'), numpy.datetime64('2018-10-29T10:52:56.000000000'), numpy.datetime64('2018-10-29T11:22:38.000000000'), numpy.datetime64('2018-10-29T11:37:16.000000000'), numpy.datetime64('2018-10-29T12:08:32.000000000'), numpy.datetime64('2018-10-29T13:12:09.000000000'), numpy.datetime64('2018-10-29T14:01:59.000000000'), numpy.datetime64('2018-10-29T14:05:28.000000000'), numpy.datetime64('2018-10-29T14:09:48.000000000'), numpy.datetime64('2018-10-29T14:19:56.000000000'), numpy.datetime64('2018-10-29T14:37:25.000000000'), numpy.datetime64('2018-10-29T14:40:32.000000000'), numpy.datetime64('2018-10-29T14:49:30.000000000'), numpy.datetime64('2018-10-29T15:30:59.000000000'), numpy.datetime64('2018-10-29T15:40:10.000000000'), numpy.datetime64('2018-10-29T15:40:25.000000000'), numpy.datetime64('2018-10-29T16:43:24.000000000'), numpy.datetime64('2018-10-29T17:31:48.000000000'), numpy.datetime64('2018-10-29T17:55:31.000000000'), numpy.datetime64('2018-10-29T18:16:41.000000000'), numpy.datetime64('2018-10-29T18:24:26.000000000'), numpy.datetime64('2018-10-29T18:30:51.000000000'), numpy.datetime64('2018-10-29T19:31:44.000000000'), numpy.datetime64('2018-10-29T19:45:45.000000000'), numpy.datetime64('2018-10-29T20:21:18.000000000'), numpy.datetime64('2018-10-29T20:31:20.000000000'), numpy.datetime64('2018-10-29T22:14:21.000000000'), numpy.datetime64('2018-10-29T22:15:31.000000000'), numpy.datetime64('2018-10-29T22:17:43.000000000'), numpy.datetime64('2018-10-29T22:18:45.000000000'), numpy.datetime64('2018-10-29T22:21:19.000000000'), numpy.datetime64('2018-10-29T22:23:14.000000000'), numpy.datetime64('2018-10-29T22:31:25.000000000'), numpy.datetime64('2018-10-29T22:34:11.000000000'), numpy.datetime64('2018-10-29T22:44:07.000000000'), numpy.datetime64('2018-10-29T22:45:16.000000000'), numpy.datetime64('2018-10-29T22:51:06.000000000'), numpy.datetime64('2018-10-29T23:06:58.000000000'), numpy.datetime64('2018-10-29T23:07:22.000000000'), numpy.datetime64('2018-10-29T23:21:07.000000000'), numpy.datetime64('2018-10-29T23:44:28.000000000'), numpy.datetime64('2018-10-30T00:56:49.000000000'), numpy.datetime64('2018-10-30T01:14:41.000000000'), numpy.datetime64('2018-10-30T02:20:37.000000000'), numpy.datetime64('2018-10-30T03:31:41.000000000'), numpy.datetime64('2018-10-30T03:43:07.000000000'), numpy.datetime64('2018-10-30T04:51:25.000000000'), numpy.datetime64('2018-10-30T07:57:13.000000000'), numpy.datetime64('2018-10-30T08:04:12.000000000'), numpy.datetime64('2018-10-30T08:53:43.000000000'), numpy.datetime64('2018-10-30T10:52:57.000000000'), numpy.datetime64('2018-10-30T11:41:32.000000000'), numpy.datetime64('2018-10-30T12:00:30.000000000'), numpy.datetime64('2018-10-30T12:04:13.000000000'), numpy.datetime64('2018-10-30T13:04:52.000000000'), numpy.datetime64('2018-10-30T13:15:38.000000000'), numpy.datetime64('2018-10-30T13:31:37.000000000'), numpy.datetime64('2018-10-30T13:46:39.000000000'), numpy.datetime64('2018-10-30T13:49:05.000000000'), numpy.datetime64('2018-10-30T14:23:09.000000000'), numpy.datetime64('2018-10-30T14:56:42.000000000'), numpy.datetime64('2018-10-30T15:30:20.000000000'), numpy.datetime64('2018-10-30T16:20:17.000000000'), numpy.datetime64('2018-10-30T16:28:06.000000000'), numpy.datetime64('2018-10-30T16:28:11.000000000'), numpy.datetime64('2018-10-30T16:34:37.000000000'), numpy.datetime64('2018-10-30T16:40:03.000000000'), numpy.datetime64('2018-10-30T18:32:43.000000000'), numpy.datetime64('2018-10-30T18:45:13.000000000'), numpy.datetime64('2018-10-30T18:48:05.000000000'), numpy.datetime64('2018-10-30T19:26:19.000000000'), numpy.datetime64('2018-10-30T19:37:59.000000000'), numpy.datetime64('2018-10-30T20:18:00.000000000'), numpy.datetime64('2018-10-30T21:24:15.000000000'), numpy.datetime64('2018-10-30T21:29:44.000000000'), numpy.datetime64('2018-10-30T21:30:46.000000000'), numpy.datetime64('2018-10-30T21:38:22.000000000'), numpy.datetime64('2018-10-30T22:15:51.000000000'), numpy.datetime64('2018-10-30T23:05:22.000000000'), numpy.datetime64('2018-10-30T23:35:21.000000000'), numpy.datetime64('2018-10-31T00:22:54.000000000'), numpy.datetime64('2018-10-31T00:24:54.000000000'), numpy.datetime64('2018-10-31T02:38:41.000000000'), numpy.datetime64('2018-10-31T05:17:28.000000000'), numpy.datetime64('2018-10-31T06:10:46.000000000'), numpy.datetime64('2018-10-31T06:22:21.000000000'), numpy.datetime64('2018-10-31T10:12:32.000000000'), numpy.datetime64('2018-10-31T11:14:41.000000000'), numpy.datetime64('2018-10-31T12:12:56.000000000'), numpy.datetime64('2018-10-31T12:14:05.000000000'), numpy.datetime64('2018-10-31T12:17:23.000000000'), numpy.datetime64('2018-10-31T13:04:47.000000000'), numpy.datetime64('2018-10-31T13:33:48.000000000'), numpy.datetime64('2018-10-31T13:54:50.000000000'), numpy.datetime64('2018-10-31T14:19:59.000000000'), numpy.datetime64('2018-10-31T14:39:19.000000000'), numpy.datetime64('2018-10-31T14:54:55.000000000'), numpy.datetime64('2018-10-31T15:13:21.000000000'), numpy.datetime64('2018-10-31T15:25:31.000000000'), numpy.datetime64('2018-10-31T15:28:19.000000000'), numpy.datetime64('2018-10-31T15:39:54.000000000'), numpy.datetime64('2018-10-31T16:29:47.000000000'), numpy.datetime64('2018-10-31T16:36:08.000000000'), numpy.datetime64('2018-10-31T18:00:46.000000000'), numpy.datetime64('2018-10-31T20:24:01.000000000'), numpy.datetime64('2018-10-31T20:27:37.000000000'), numpy.datetime64('2018-10-31T21:52:13.000000000'), numpy.datetime64('2018-10-31T21:54:41.000000000'), numpy.datetime64('2018-10-31T22:33:56.000000000'), numpy.datetime64('2018-10-31T22:42:10.000000000'), numpy.datetime64('2018-10-31T22:50:38.000000000'), numpy.datetime64('2018-10-31T23:15:42.000000000'), numpy.datetime64('2018-10-31T23:31:03.000000000'), numpy.datetime64('2018-11-01T00:00:44.000000000'), numpy.datetime64('2018-11-01T00:03:27.000000000'), numpy.datetime64('2018-11-01T00:04:44.000000000'), numpy.datetime64('2018-11-01T01:51:13.000000000'), numpy.datetime64('2018-11-01T02:05:32.000000000'), numpy.datetime64('2018-11-01T02:21:15.000000000'), numpy.datetime64('2018-11-01T02:25:32.000000000'), numpy.datetime64('2018-11-01T03:25:48.000000000'), numpy.datetime64('2018-11-01T03:35:52.000000000'), numpy.datetime64('2018-11-01T04:08:18.000000000'), numpy.datetime64('2018-11-01T04:23:32.000000000'), numpy.datetime64('2018-11-01T05:22:49.000000000'), numpy.datetime64('2018-11-01T07:38:23.000000000')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[3:4])  # 1425 extra, 1089 missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Is the large number of differences due to diffs in datetime formatting???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. exit_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit_status:\n",
      "   df2_extra ( 0 ): []\n",
      "\n",
      "\n",
      "   df2_missing ( 1 ): [130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[4:5])  # 0 extra, 1 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893131</th>\n",
       "      <td>g36</td>\n",
       "      <td>u65</td>\n",
       "      <td>4008055</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:28:06</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>00:05:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893259</th>\n",
       "      <td>g36</td>\n",
       "      <td>u65</td>\n",
       "      <td>4008132</td>\n",
       "      <td>2018-10-15 22:34:34</td>\n",
       "      <td>2018-10-15 22:34:34</td>\n",
       "      <td>2018-10-15 22:38:40</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>00:04:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group owner  job_number     submission_time          start_time  \\\n",
       "1893131  g36   u65   4008055    2018-10-15 22:22:31 2018-10-15 22:22:31   \n",
       "1893259  g36   u65   4008132    2018-10-15 22:34:34 2018-10-15 22:34:34   \n",
       "\n",
       "                   end_time  failed  exit_status granted_pe  slots  \\\n",
       "1893131 2018-10-15 22:28:06  100     130          dc_pod     48      \n",
       "1893259 2018-10-15 22:38:40  100     130          dc_pod     48      \n",
       "\n",
       "         task_number  maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu  \\\n",
       "1893131  0            0.0      5.0     1.0   1      0          5.0     0     \n",
       "1893259  0            0.0      5.0     1.0   1      0          5.0     0     \n",
       "\n",
       "          pe  slot  campus wait_time    wtime  \n",
       "1893131  dc*  48    0      0 days    00:05:35  \n",
       "1893259  dc*  48    0      0 days    00:04:06  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chec df_1 for the missing value\n",
    "\n",
    "df_1[df_1.exit_status == 130]  # indexes 1893131, 1893259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893130</th>\n",
       "      <td>saide</td>\n",
       "      <td>xye</td>\n",
       "      <td>4008055</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:28:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:05:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893132</th>\n",
       "      <td>saide</td>\n",
       "      <td>xye</td>\n",
       "      <td>4008055</td>\n",
       "      <td>2018-10-15 22:21:06</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:28:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>391663616.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:25</td>\n",
       "      <td>00:05:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group owner  job_number     submission_time          start_time  \\\n",
       "1893130  saide  xye   4008055    2018-10-15 22:22:31 2018-10-15 22:22:31   \n",
       "1893132  saide  xye   4008055    2018-10-15 22:21:06 2018-10-15 22:22:31   \n",
       "\n",
       "                   end_time  failed  exit_status granted_pe  slots  \\\n",
       "1893130 2018-10-15 22:28:06  0       0            dc_pod     48      \n",
       "1893132 2018-10-15 22:28:06  0       0            dc_pod     48      \n",
       "\n",
       "         task_number      maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \\\n",
       "1893130  0            0.0          5.0     1.0   1      0          5.0      \n",
       "1893132  0            391663616.0  5.0     1.0   1      0          5.0      \n",
       "\n",
       "         gpu   pe  slot  campus wait_time    wtime  \n",
       "1893130  0    dc*  48    0      00:00:00  00:05:35  \n",
       "1893132  0    dc*  48    0      00:01:25  00:05:35  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check df_2 for job_number 4008055\n",
    "df_2[df_2.job_number == 4008055]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893131</th>\n",
       "      <td>g36</td>\n",
       "      <td>u65</td>\n",
       "      <td>4008055</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:28:06</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:05:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893132</th>\n",
       "      <td>g36</td>\n",
       "      <td>u65</td>\n",
       "      <td>4008055</td>\n",
       "      <td>2018-10-15 22:21:06</td>\n",
       "      <td>2018-10-15 22:22:31</td>\n",
       "      <td>2018-10-15 22:28:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>391663616.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:25</td>\n",
       "      <td>00:05:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group owner  job_number     submission_time          start_time  \\\n",
       "1893131  g36   u65   4008055    2018-10-15 22:22:31 2018-10-15 22:22:31   \n",
       "1893132  g36   u65   4008055    2018-10-15 22:21:06 2018-10-15 22:22:31   \n",
       "\n",
       "                   end_time  failed  exit_status granted_pe  slots  \\\n",
       "1893131 2018-10-15 22:28:06  100     130          dc_pod     48      \n",
       "1893132 2018-10-15 22:28:06  0       0            dc_pod     48      \n",
       "\n",
       "         task_number      maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \\\n",
       "1893131  0            0.0          5.0     1.0   1      0          5.0      \n",
       "1893132  0            391663616.0  5.0     1.0   1      0          5.0      \n",
       "\n",
       "         gpu   pe  slot  campus wait_time    wtime  \n",
       "1893131  0    dc*  48    0      00:00:00  00:05:35  \n",
       "1893132  0    dc*  48    0      00:01:25  00:05:35  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same job and task number had 2 diff submit times in df_2\n",
    "\n",
    "# Check df_1 for same job number\n",
    "df_1[df_1.job_number == 4008055]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Hmm. This is NOT a \"duplicate\" row b/c submit time differs\n",
    "- So why do I have 0 as exit status for both when df_1 has 0 and 130?\n",
    " - Maybe the df_2 I was given has 0 exit status (i.e., is different from df_1) and I didn't change anything\n",
    " - Or **maybe** there were \"duplicate\" entries of this row in df_2 but the first one had 0. Then even if the other(s) had 130 my `drop_duplicates(...keepfirst)` would keep the 0 row\n",
    " \n",
    "Look at this row(job number) BEFORE drop_dupes\n",
    "\n",
    "- Yep, that's exactly it:\n",
    "```\n",
    "         group owner  job_number  submission_time  start_time    end_time  \\\n",
    "1893130  saide  xye   4008055     1539642151       1539642151  1539642486   \n",
    "1893131  saide  xye   4008055     1539642151       1539642151  1539642486   \n",
    "1893132  saide  xye   4008055     1539642066       1539642151  1539642486   \n",
    "\n",
    "         failed  exit_status granted_pe  slots  task_number  \\\n",
    "1893130  0       0            dc_pod     48     0             \n",
    "1893131  100     130          dc_pod     48     0             \n",
    "1893132  0       0            dc_pod     48     0             \n",
    "\n",
    "                                                                       category  \\\n",
    "1893130  -U saide -u xye -l h_data=5G,h_rt=3600,h_vmem=5G,highp=TRUE -pe dc* 48   \n",
    "1893131  -U saide -u xye -l h_data=5G,h_rt=3600,h_vmem=5G,highp=TRUE -pe dc* 48   \n",
    "1893132  -U saide -u xye -l h_data=5G,h_rt=3600,h_vmem=5G,highp=TRUE -pe dc* 48   \n",
    "\n",
    "             maxvmem  \n",
    "1893130  0.0          \n",
    "1893131  0.0          \n",
    "1893132  391663616.0  \n",
    "```\n",
    "\n",
    "This suggests that defining \"duplicate\" only by job, task and submit might not be sufficient to distinguish rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. h_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_data:\n",
      "   df2_extra ( 38 ): [0.097656, 0.195312, 0.292969, 0.488281, 0.976562, 1.06543, 1.072266, 1.145508, 1.464844, 1.660156, 2.130859, 2.148438, 2.291016, 2.441406, 2.929688, 2.988281, 3.320312, 3.417969, 4.001953, 4.488281, 4.882812, 7.835938, 7.990234, 8.003906, 8.789062, 9.789062, 14.648438, 15.945312, 15.998047, 16.00293, 16.601562, 19.554688, 21.972656, 24.414062, 29.320312, 63.476562, 63.999023, 64.026367]\n",
      "\n",
      "\n",
      "   df2_missing ( 46 ): [-1.0, 3.814697265625e-06, 4.76837158203125e-06, 7.62939453125e-06, 9.5367431640625e-06, 1.1444091796875e-05, 1.52587890625e-05, 2.288818359375e-05, 0.09765625, 0.1953125, 0.29296875, 0.48828125, 0.9765625, 1.0654296875, 1.072265625, 1.1455078125, 1.46484375, 1.66015625, 2.130859375, 2.1484375, 2.291015625, 2.44140625, 2.9296875, 2.98828125, 3.3203125, 3.41796875, 4.001953125, 4.48828125, 4.8828125, 7.8359375, 7.990234375, 8.00390625, 8.7890625, 9.7890625, 14.6484375, 15.9453125, 15.998046875, 16.0029296875, 16.6015625, 19.5546875, 21.97265625, 24.4140625, 29.3203125, 63.4765625, 63.9990234375, 64.0263671875]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(fields[5:6])  # extra 38, missing 46 = diff 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one of the extra/missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>937191</th>\n",
       "      <td>g22</td>\n",
       "      <td>u30</td>\n",
       "      <td>3971239</td>\n",
       "      <td>2018-10-08 23:18:35</td>\n",
       "      <td>2018-10-08 23:20:17</td>\n",
       "      <td>2018-10-08 23:20:18</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:42</td>\n",
       "      <td>00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937192</th>\n",
       "      <td>g22</td>\n",
       "      <td>u30</td>\n",
       "      <td>3971238</td>\n",
       "      <td>2018-10-08 23:18:08</td>\n",
       "      <td>2018-10-08 23:20:17</td>\n",
       "      <td>2018-10-08 23:20:18</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:02:09</td>\n",
       "      <td>00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576109</th>\n",
       "      <td>g69</td>\n",
       "      <td>u486</td>\n",
       "      <td>4058455</td>\n",
       "      <td>2018-10-22 04:16:48</td>\n",
       "      <td>2018-10-22 04:17:32</td>\n",
       "      <td>2018-10-22 06:20:03</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:44</td>\n",
       "      <td>02:02:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group owner  job_number     submission_time          start_time  \\\n",
       "937191   g22   u30   3971239    2018-10-08 23:18:35 2018-10-08 23:20:17   \n",
       "937192   g22   u30   3971238    2018-10-08 23:18:08 2018-10-08 23:20:17   \n",
       "3576109  g69   u486  4058455    2018-10-22 04:16:48 2018-10-22 04:17:32   \n",
       "\n",
       "                   end_time  failed  exit_status granted_pe  slots  \\\n",
       "937191  2018-10-08 23:20:18  15      127          NONE       1       \n",
       "937192  2018-10-08 23:20:18  15      127          NONE       1       \n",
       "3576109 2018-10-22 06:20:03  37      0            single     1       \n",
       "\n",
       "         task_number  maxvmem    h_data  h_rt  highp  exclusive  h_vmem  gpu  \\\n",
       "937191   0            0.0      0.000004  24.0  1      0          4.0     0     \n",
       "937192   0            0.0      0.000004  24.0  1      0          4.0     0     \n",
       "3576109  0            0.0      0.000004  2.0   0      0          0.0     0     \n",
       "\n",
       "             pe  slot  campus wait_time    wtime  \n",
       "937191           1     0      00:01:42  00:00:01  \n",
       "937192           1     0      00:02:09  00:00:01  \n",
       "3576109  single  1     0      00:00:44  02:02:31  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[df_1.h_data == 3.814697265625e-06]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- I rounded these floats to 1 place but df_1 rounded most to 6 places\n",
    "- Change df_2 to 6 places\n",
    "- This did not fix all b/c df_1 is inconsistent. Round df_1 to 6 places also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_data:\n",
      "   df2_extra ( 0 ): []\n",
      "\n",
      "\n",
      "   df2_missing ( 8 ): [-1.0, 4e-06, 5e-06, 8e-06, 1e-05, 1.1e-05, 1.5e-05, 2.3e-05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1['h_data'] = df_1['h_data'].astype(float).round(6)\n",
    "\n",
    "print_extra_missing_values_in_df2(fields[5:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Took care of a lot of them! In fact all but 8, which may be the values I dropped b/c of bad h_data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25150</th>\n",
       "      <td>g43</td>\n",
       "      <td>u79</td>\n",
       "      <td>3896566</td>\n",
       "      <td>2018-09-26 21:23:02</td>\n",
       "      <td>2018-09-26 21:23:51</td>\n",
       "      <td>2018-10-01 15:10:02</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_msa</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:49</td>\n",
       "      <td>4 days 17:46:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216100</th>\n",
       "      <td>g104</td>\n",
       "      <td>u265</td>\n",
       "      <td>3931237</td>\n",
       "      <td>2018-10-02 21:38:06</td>\n",
       "      <td>2018-10-02 21:39:13</td>\n",
       "      <td>2018-10-03 00:20:02</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:07</td>\n",
       "      <td>0 days 02:40:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363365</th>\n",
       "      <td>g104</td>\n",
       "      <td>u265</td>\n",
       "      <td>3934075</td>\n",
       "      <td>2018-10-03 14:51:34</td>\n",
       "      <td>2018-10-03 14:53:16</td>\n",
       "      <td>2018-10-03 23:20:01</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_ib56</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dc*</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:42</td>\n",
       "      <td>0 days 08:26:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       group owner  job_number     submission_time          start_time  \\\n",
       "25150   g43   u79   3896566    2018-09-26 21:23:02 2018-09-26 21:23:51   \n",
       "216100  g104  u265  3931237    2018-10-02 21:38:06 2018-10-02 21:39:13   \n",
       "363365  g104  u265  3934075    2018-10-03 14:51:34 2018-10-03 14:53:16   \n",
       "\n",
       "                  end_time  failed  exit_status   granted_pe  slots  \\\n",
       "25150  2018-10-01 15:10:02  37      0            dc_msa       64      \n",
       "216100 2018-10-03 00:20:02  37      0            NONE         1       \n",
       "363365 2018-10-03 23:20:01  37      0            dc_pod_ib56  32      \n",
       "\n",
       "        task_number  maxvmem  h_data   h_rt  highp  exclusive  h_vmem  gpu  \\\n",
       "25150   0            0.0      0.0     300.0  1      1          0.0     0     \n",
       "216100  0            0.0      0.0     2.0    0      1          0.0     0     \n",
       "363365  0            0.0      0.0     8.0    0      1          0.0     0     \n",
       "\n",
       "         pe  slot  campus wait_time           wtime  \n",
       "25150   dc*  64    0      00:00:49  4 days 17:46:11  \n",
       "216100       1     0      00:01:07  0 days 02:40:49  \n",
       "363365  dc*  32    0      00:01:42  0 days 08:26:45  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_1[df_1.h_data == 0.0]))  # 20\n",
    "df_1[df_1.h_data == 0.0].head(3)      # job_nums 3896566, 3931237, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       group owner  job_number     submission_time          start_time  \\\n",
      "216100  g104  u265  3931237    2018-10-02 21:38:06 2018-10-02 21:39:13   \n",
      "\n",
      "                  end_time  failed  exit_status granted_pe  slots  \\\n",
      "216100 2018-10-03 00:20:02  37      0            NONE       1       \n",
      "\n",
      "        task_number  maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu pe  \\\n",
      "216100  0            0.0      0.0     2.0   0      1          0.0     0        \n",
      "\n",
      "        slot  campus wait_time    wtime  \n",
      "216100  1     0      00:01:07  02:40:49  \n"
     ]
    }
   ],
   "source": [
    "print(df_1[df_1.job_number == 3931237])  # h_data 0.0, h_vmem 0.0, h_rt 2.0, pe ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "       group owner  job_number     submission_time          start_time  \\\n",
    "216100  g104  u265  3931237    2018-10-02 21:38:06 2018-10-02 21:39:13   \n",
    "\n",
    "                  end_time  failed  exit_status granted_pe  slots  \\\n",
    "216100 2018-10-03 00:20:02  37      0            NONE       1       \n",
    "\n",
    "        task_number  maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu pe  \\\n",
    "216100  0            0.0      0.0     2.0   0      1          0.0     0        \n",
    "\n",
    "        slot  campus wait_time    wtime  \n",
    "216100  1     0      00:01:07  02:40:49 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         group owner  job_number     submission_time          start_time  \\\n",
      "216100  staff1  ppk   3931237    2018-10-02 21:38:06 2018-10-02 21:39:13   \n",
      "\n",
      "                  end_time  failed  exit_status granted_pe  slots  \\\n",
      "216100 2018-10-03 00:20:02  37      0            NONE       1       \n",
      "\n",
      "        task_number  maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu  \\\n",
      "216100  0            0.0      0.0     0.0   0      1          0.0     0     \n",
      "\n",
      "          pe  slot  campus wait_time    wtime  \n",
      "216100  none  1     0      00:01:07  02:40:49  \n"
     ]
    }
   ],
   "source": [
    "print(df_2[df_2.job_number == 3931237])  # h_data, h_rt, h_vmem all -1.0, pe none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "         group owner  job_number     submission_time          start_time  \\\n",
    "216100  staff1  ppk   3931237    2018-10-02 21:38:06 2018-10-02 21:39:13   \n",
    "\n",
    "                  end_time  failed  exit_status granted_pe  slots  \\\n",
    "216100 2018-10-03 00:20:02  37      0            NONE       1       \n",
    "\n",
    "        task_number  maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu  \\\n",
    "216100  0            0.0     -1.0    -1.0   0      1         -1.0     0     \n",
    "\n",
    "          pe  slot  campus wait_time    wtime  \n",
    "216100  none  1     0      00:01:07  02:40:49  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at pre- de-duped category values**\n",
    "\n",
    "`-U gpu,idre_testing,jdavis,staff -u ppk -l exclusive=TRUE,h_rt=7200 -I y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         df1_orig  df1_recorded   df2_orig   df2_recorded\n",
    "`h_rt`   2.0       2.0            7200      -1.0  FIX\n",
    "`h_data` 0.0       0.0            -         -1.0\n",
    "`h_vmem` 0.0       0.0            -         -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. h_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_rt:\n",
      "   df2_extra ( 72 ): [0.0, 0.000278, 0.003333, 0.008333, 0.016667, 0.033333, 0.066667, 0.083333, 0.116667, 0.133333, 0.166667, 0.216667, 0.283333, 0.333333, 0.366667, 0.383333, 0.416667, 0.466667, 0.533333, 0.583333, 0.666667, 0.833333, 0.916667, 0.966667, 1.008333, 1.033333, 1.166667, 1.333333, 1.583333, 1.666667, 2.083333, 2.333333, 2.847222, 3.931944, 4.111111, 4.999722, 5.999444, 6.008333, 6.083333, 6.931944, 7.333333, 8.033333, 8.333333, 10.033333, 10.333333, 10.983333, 11.999722, 12.333333, 12.999722, 15.999722, 18.033333, 19.999722, 20.931944, 22.333333, 23.833333, 23.847222, 23.916667, 23.931944, 23.983333, 23.999444, 23.999722, 24.999722, 48.847222, 48.999722, 50.847222, 53.847222, 71.999722, 72.999722, 96.999722, 123.983333, 335.983333, 335.999444]\n",
      "\n",
      "\n",
      "   df2_missing ( 72 ): [-1.0, 0.0002777777777777778, 0.0033333333333333335, 0.008333333333333333, 0.016666666666666666, 0.03333333333333333, 0.06666666666666667, 0.08333333333333333, 0.11666666666666667, 0.13333333333333333, 0.16666666666666666, 0.21666666666666667, 0.2833333333333333, 0.3333333333333333, 0.36666666666666664, 0.38333333333333336, 0.4166666666666667, 0.4666666666666667, 0.5333333333333333, 0.5833333333333334, 0.6666666666666666, 0.8333333333333334, 0.9166666666666666, 0.9666666666666667, 1.0083333333333333, 1.0333333333333334, 1.1666666666666667, 1.3333333333333333, 1.5833333333333333, 1.6666666666666667, 2.0833333333333335, 2.3333333333333335, 2.8472222222222223, 3.9319444444444445, 4.111111111111111, 4.999722222222222, 5.999444444444444, 6.008333333333334, 6.083333333333333, 6.9319444444444445, 7.333333333333333, 8.033333333333333, 8.333333333333334, 10.033333333333333, 10.333333333333334, 10.983333333333333, 11.999722222222223, 12.333333333333334, 12.999722222222223, 15.999722222222223, 18.033333333333335, 19.99972222222222, 20.931944444444444, 22.333333333333332, 23.833333333333332, 23.84722222222222, 23.916666666666668, 23.931944444444444, 23.983333333333334, 23.999444444444446, 23.99972222222222, 24.99972222222222, 48.84722222222222, 48.999722222222225, 50.84722222222222, 53.84722222222222, 71.99972222222222, 72.99972222222222, 96.99972222222222, 123.98333333333333, 335.98333333333335, 335.99944444444446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['h_rt'])  # all fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- 72 extra, 72 missing and they look to be the same values except for rounding\n",
    "- The -1 vs 0 is diff ways of noting missing values\n",
    "- Fix: Round df_1 and df_2 to 6 places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['h_rt'] = df_1['h_rt'].astype(float).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_rt:\n",
      "   df2_extra ( 1 ): [0.0]\n",
      "\n",
      "\n",
      "   df2_missing ( 1 ): [-1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['h_rt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. h_vmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_vmem:\n",
      "   df2_extra ( 0 ): []\n",
      "\n",
      "\n",
      "   df2_missing ( 0 ): []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['h_vmem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2[df_2.h_vmem == -1.0])  # 130916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20410"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1[df_1.h_vmem == 0.0])  # 20410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110513 110513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_1[df_1.h_vmem == np.inf]), len(df_2[df_2.h_vmem == np.inf]))\n",
    "len(df_1[df_1.h_vmem == np.inf]) == len(df_2[df_2.h_vmem == np.inf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe:\n",
      "   df2_extra ( 1 ): ['none']\n",
      "\n",
      "\n",
      "   df2_missing ( 1 ): ['']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['pe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- Since adding 'none' when no pe value was found was part of the instructions, I'm guessing that missing pe values were handled differently in df_1 ??? **Doublecheck**\n",
    "- Perhaps they were (at least sometimes) handled by the empty string that is listed as missing\n",
    "\n",
    "**Inspect pe values in df_1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for 'none' strings\n",
    "print(len(df_1[df_1.pe == 'none']))  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for 'NONE' strings\n",
    "print(len(df_1[df_1.pe == 'NONE']))  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146890\n"
     ]
    }
   ],
   "source": [
    "# Check for empty strings\n",
    "print(len(df_1[df_1.pe == '']))  # 146890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n"
     ]
    }
   ],
   "source": [
    "# Check for '*'\n",
    "print(len(df_1[df_1.pe == '*']))  # 620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146888\n"
     ]
    }
   ],
   "source": [
    "# is this similar to num of 'none' values in df_2 ?\n",
    "print(len(df_2[df_2.pe == 'none']))  # 147508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, a difference of 2 which might be accounted for by 2 of the 10 dropped h_data values. \n",
    "- Instead of checking for equality, check for \"closeness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import isclose\n",
    "\n",
    "a = len(df_1[df_1.pe == ''])\n",
    "b = len(df_2[df_2.pe == 'none'])\n",
    "\n",
    "isclose(a, b, abs_tol = 0.00002 * a)  # tolerance of 2e-05 (0.002%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- There are still 2 rows. Which 2 rows and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None found\n",
      "None found\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(df_1.pe == '*'):\n",
    "    if i > 1:\n",
    "        break\n",
    "    if j:\n",
    "        print(df_1[i:i+1])\n",
    "        print()\n",
    "    else:\n",
    "        print('None found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at pe for this row in df_2 and at category in **pre- de-duped df_2**:\n",
    "\n",
    "```\n",
    "job_number     submission_time task_number\n",
    "3929734    2018-10-02 17:03:11 0\n",
    "```\n",
    "\n",
    "```\n",
    "       group owner  job_number     submission_time          start_time  \\\n",
    "145874  g96   u226  3929734    2018-10-02 17:03:11 2018-10-02 17:05:32   \n",
    "\n",
    "                  end_time  failed  exit_status         granted_pe  slots  \\\n",
    "145874 2018-10-02 17:06:04  100     0            dc_pod_qlogic_dc6  8       \n",
    "\n",
    "        task_number       maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \\\n",
    "145874  0            3.735654e+09  3.0     2.0   0      0          3.0      \n",
    "\n",
    "        gpu pe  slot  campus wait_time    wtime False  \n",
    "145874  0    *  8     1      00:02:21  00:00:32  none  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145874</th>\n",
       "      <td>nwhiteho</td>\n",
       "      <td>briedel</td>\n",
       "      <td>3929734</td>\n",
       "      <td>2018-10-02 17:03:11</td>\n",
       "      <td>2018-10-02 17:05:32</td>\n",
       "      <td>2018-10-02 17:06:04</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>dc_pod_qlogic_dc6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.735654e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>00:02:21</td>\n",
       "      <td>00:00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           group    owner  job_number     submission_time          start_time  \\\n",
       "145874  nwhiteho  briedel  3929734    2018-10-02 17:03:11 2018-10-02 17:05:32   \n",
       "\n",
       "                  end_time  failed  exit_status         granted_pe  slots  \\\n",
       "145874 2018-10-02 17:06:04  100     0            dc_pod_qlogic_dc6  8       \n",
       "\n",
       "        task_number       maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \\\n",
       "145874  0            3.735654e+09  3.0     2.0   0      0          3.0      \n",
       "\n",
       "        gpu pe  slot  campus wait_time    wtime  \n",
       "145874  0    *  8     1      00:02:21  00:00:32  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[(df_2.submission_time == '2018-10-02 17:03:11') \n",
    "     & (df_2.job_number == 3929734)\n",
    "     & (df_2.task_number == 0)]             # none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at pe in category in **pre- de-duped df_2**:\n",
    "\n",
    "> `-pe * 8`\n",
    "\n",
    "**Findings**:\n",
    "- I've been missing these. Fixed, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # compare \n",
    "# (df_1[(df_1.pe == '') | (df_1.pe == '*')]) VS df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = (df_1[(df_1.pe == '') | (df_1.pe == '*')])\n",
    "B = df_2[(df_2.pe == 'none')]\n",
    "\n",
    "# A.difference(B)  # AttributeError: 'DataFrame' object has no attribute 'difference'\n",
    "\n",
    "u = A.merge(B, how='outer', indicator=True)\n",
    "df3 = u.query('_merge == \"left_only\"').drop('_merge', 1)\n",
    "df4 = u.query('_merge == \"right_only\"').drop('_merge', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147510\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g6</td>\n",
       "      <td>u7</td>\n",
       "      <td>3919382</td>\n",
       "      <td>2018-10-01 07:05:51</td>\n",
       "      <td>2018-10-01 07:13:28</td>\n",
       "      <td>2018-10-01 08:01:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.714636e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:07:37</td>\n",
       "      <td>00:47:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g7</td>\n",
       "      <td>u8</td>\n",
       "      <td>3916181</td>\n",
       "      <td>2018-09-30 19:45:43</td>\n",
       "      <td>2018-09-30 19:47:14</td>\n",
       "      <td>2018-10-01 08:01:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.341556e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:31</td>\n",
       "      <td>12:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g8</td>\n",
       "      <td>u9</td>\n",
       "      <td>3919526</td>\n",
       "      <td>2018-10-01 07:18:46</td>\n",
       "      <td>2018-10-01 07:48:57</td>\n",
       "      <td>2018-10-01 08:01:25</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6.453185e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30:11</td>\n",
       "      <td>00:12:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group owner  job_number     submission_time          start_time  \\\n",
       "0  g6    u7    3919382    2018-10-01 07:05:51 2018-10-01 07:13:28   \n",
       "1  g7    u8    3916181    2018-09-30 19:45:43 2018-09-30 19:47:14   \n",
       "2  g8    u9    3919526    2018-10-01 07:18:46 2018-10-01 07:48:57   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:01:18  0       0            NONE       1      0             \n",
       "1 2018-10-01 08:01:03  0       0            NONE       1      6             \n",
       "2 2018-10-01 08:01:25  100     137          NONE       1      55            \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu pe  slot  campus  \\\n",
       "0  2.714636e+09  3.0     48.0  1      0          3.0     0       1     0        \n",
       "1  2.341556e+09  3.0     48.0  1      0          3.0     0       1     0        \n",
       "2  6.453185e+10  60.0    2.0   1      0          60.0    0       1     0        \n",
       "\n",
       "  wait_time    wtime  \n",
       "0 00:07:37  00:47:50  \n",
       "1 00:01:31  12:13:49  \n",
       "2 00:30:11  00:12:28  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df3))\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147510</th>\n",
       "      <td>houk</td>\n",
       "      <td>glee16</td>\n",
       "      <td>3919382</td>\n",
       "      <td>2018-10-01 07:05:51</td>\n",
       "      <td>2018-10-01 07:13:28</td>\n",
       "      <td>2018-10-01 08:01:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.714636e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:07:37</td>\n",
       "      <td>00:47:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147511</th>\n",
       "      <td>eeskin</td>\n",
       "      <td>cmarsden</td>\n",
       "      <td>3916181</td>\n",
       "      <td>2018-09-30 19:45:43</td>\n",
       "      <td>2018-09-30 19:47:14</td>\n",
       "      <td>2018-10-01 08:01:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.341556e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:31</td>\n",
       "      <td>12:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147512</th>\n",
       "      <td>sriram</td>\n",
       "      <td>alipazok</td>\n",
       "      <td>3919526</td>\n",
       "      <td>2018-10-01 07:18:46</td>\n",
       "      <td>2018-10-01 07:48:57</td>\n",
       "      <td>2018-10-01 08:01:25</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6.453185e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30:11</td>\n",
       "      <td>00:12:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group     owner  job_number     submission_time          start_time  \\\n",
       "147510  houk    glee16    3919382    2018-10-01 07:05:51 2018-10-01 07:13:28   \n",
       "147511  eeskin  cmarsden  3916181    2018-09-30 19:45:43 2018-09-30 19:47:14   \n",
       "147512  sriram  alipazok  3919526    2018-10-01 07:18:46 2018-10-01 07:48:57   \n",
       "\n",
       "                  end_time  failed  exit_status granted_pe  slots  \\\n",
       "147510 2018-10-01 08:01:18  0       0            NONE       1       \n",
       "147511 2018-10-01 08:01:03  0       0            NONE       1       \n",
       "147512 2018-10-01 08:01:25  100     137          NONE       1       \n",
       "\n",
       "        task_number       maxvmem  h_data  h_rt  highp  exclusive  h_vmem  \\\n",
       "147510  0            2.714636e+09  3.0     48.0  1      0          3.0      \n",
       "147511  6            2.341556e+09  3.0     48.0  1      0          3.0      \n",
       "147512  55           6.453185e+10  60.0    2.0   1      0          60.0     \n",
       "\n",
       "        gpu    pe  slot  campus wait_time    wtime  \n",
       "147510  1    none  1     0      00:07:37  00:47:50  \n",
       "147511  0    none  1     0      00:01:31  12:13:49  \n",
       "147512  0    none  1     0      00:30:11  00:12:28  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df4))\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['single', 'shared', 'dc*', '', 'node*', '*', 'matlab'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df_1_pe_NONE\n",
    "df_1_pe_NONE = df_1\n",
    "\n",
    "# List uniq values for pe col\n",
    "df_1_pe_NONE_uniq = df_1_pe_NONE.pe.unique()\n",
    "df_1_pe_NONE_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare again\n",
    "A = df_1[(df_1.pe == 'none')]\n",
    "B = df_2[(df_2.pe == 'none')]\n",
    "\n",
    "u = A.merge(B, how='outer', indicator=True)\n",
    "df3 = u.query('_merge == \"left_only\"').drop('_merge', 1)\n",
    "df4 = u.query('_merge == \"right_only\"').drop('_merge', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [group, owner, job_number, submission_time, start_time, end_time, failed, exit_status, granted_pe, slots, task_number, maxvmem, h_data, h_rt, highp, exclusive, h_vmem, gpu, pe, slot, campus, wait_time, wtime]\n",
       "Index: []"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df3))\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>job_number</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>failed</th>\n",
       "      <th>exit_status</th>\n",
       "      <th>granted_pe</th>\n",
       "      <th>slots</th>\n",
       "      <th>task_number</th>\n",
       "      <th>maxvmem</th>\n",
       "      <th>h_data</th>\n",
       "      <th>h_rt</th>\n",
       "      <th>highp</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>h_vmem</th>\n",
       "      <th>gpu</th>\n",
       "      <th>pe</th>\n",
       "      <th>slot</th>\n",
       "      <th>campus</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>houk</td>\n",
       "      <td>glee16</td>\n",
       "      <td>3919382</td>\n",
       "      <td>2018-10-01 07:05:51</td>\n",
       "      <td>2018-10-01 07:13:28</td>\n",
       "      <td>2018-10-01 08:01:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.714636e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:07:37</td>\n",
       "      <td>00:47:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eeskin</td>\n",
       "      <td>cmarsden</td>\n",
       "      <td>3916181</td>\n",
       "      <td>2018-09-30 19:45:43</td>\n",
       "      <td>2018-09-30 19:47:14</td>\n",
       "      <td>2018-10-01 08:01:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.341556e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:01:31</td>\n",
       "      <td>12:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sriram</td>\n",
       "      <td>alipazok</td>\n",
       "      <td>3919526</td>\n",
       "      <td>2018-10-01 07:18:46</td>\n",
       "      <td>2018-10-01 07:48:57</td>\n",
       "      <td>2018-10-01 08:01:25</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6.453185e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30:11</td>\n",
       "      <td>00:12:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group     owner  job_number     submission_time          start_time  \\\n",
       "0  houk    glee16    3919382    2018-10-01 07:05:51 2018-10-01 07:13:28   \n",
       "1  eeskin  cmarsden  3916181    2018-09-30 19:45:43 2018-09-30 19:47:14   \n",
       "2  sriram  alipazok  3919526    2018-10-01 07:18:46 2018-10-01 07:48:57   \n",
       "\n",
       "             end_time  failed  exit_status granted_pe  slots  task_number  \\\n",
       "0 2018-10-01 08:01:18  0       0            NONE       1      0             \n",
       "1 2018-10-01 08:01:03  0       0            NONE       1      6             \n",
       "2 2018-10-01 08:01:25  100     137          NONE       1      55            \n",
       "\n",
       "        maxvmem  h_data  h_rt  highp  exclusive  h_vmem  gpu    pe  slot  \\\n",
       "0  2.714636e+09  3.0     48.0  1      0          3.0     1    none  1      \n",
       "1  2.341556e+09  3.0     48.0  1      0          3.0     0    none  1      \n",
       "2  6.453185e+10  60.0    2.0   1      0          60.0    0    none  1      \n",
       "\n",
       "   campus wait_time    wtime  \n",
       "0  0      00:07:37  00:47:50  \n",
       "1  0      00:01:31  12:13:49  \n",
       "2  0      00:30:11  00:12:28  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df4))\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. wait_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait_time:\n",
      "   df2_extra ( 1 ): [numpy.timedelta64(8000000000,'ns')]\n",
      "\n",
      "\n",
      "   df2_missing ( 0 ): []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['wait_time'])  # 1 extra, 0 missing = 1 diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- df2_extra ( 1 ): [numpy.timedelta64(8000000000,'ns')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. wtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtime:\n",
      "   df2_extra ( 119 ): [numpy.timedelta64(18939000000000,'ns'), numpy.timedelta64(20793000000000,'ns'), numpy.timedelta64(21613000000000,'ns'), numpy.timedelta64(21942000000000,'ns'), numpy.timedelta64(25530000000000,'ns'), numpy.timedelta64(26735000000000,'ns'), numpy.timedelta64(26868000000000,'ns'), numpy.timedelta64(27752000000000,'ns'), numpy.timedelta64(28775000000000,'ns'), numpy.timedelta64(31929000000000,'ns'), numpy.timedelta64(32977000000000,'ns'), numpy.timedelta64(33385000000000,'ns'), numpy.timedelta64(34110000000000,'ns'), numpy.timedelta64(36635000000000,'ns'), numpy.timedelta64(37085000000000,'ns'), numpy.timedelta64(37944000000000,'ns'), numpy.timedelta64(38059000000000,'ns'), numpy.timedelta64(38089000000000,'ns'), numpy.timedelta64(39451000000000,'ns'), numpy.timedelta64(39654000000000,'ns'), numpy.timedelta64(41064000000000,'ns'), numpy.timedelta64(41801000000000,'ns'), numpy.timedelta64(42313000000000,'ns'), numpy.timedelta64(42376000000000,'ns'), numpy.timedelta64(44216000000000,'ns'), numpy.timedelta64(44304000000000,'ns'), numpy.timedelta64(45078000000000,'ns'), numpy.timedelta64(45289000000000,'ns'), numpy.timedelta64(48085000000000,'ns'), numpy.timedelta64(48089000000000,'ns'), numpy.timedelta64(48961000000000,'ns'), numpy.timedelta64(49519000000000,'ns'), numpy.timedelta64(50196000000000,'ns'), numpy.timedelta64(50216000000000,'ns'), numpy.timedelta64(50527000000000,'ns'), numpy.timedelta64(51837000000000,'ns'), numpy.timedelta64(52432000000000,'ns'), numpy.timedelta64(52889000000000,'ns'), numpy.timedelta64(52912000000000,'ns'), numpy.timedelta64(53308000000000,'ns'), numpy.timedelta64(53798000000000,'ns'), numpy.timedelta64(54297000000000,'ns'), numpy.timedelta64(54708000000000,'ns'), numpy.timedelta64(55625000000000,'ns'), numpy.timedelta64(55655000000000,'ns'), numpy.timedelta64(55768000000000,'ns'), numpy.timedelta64(56571000000000,'ns'), numpy.timedelta64(57180000000000,'ns'), numpy.timedelta64(57368000000000,'ns'), numpy.timedelta64(57982000000000,'ns'), numpy.timedelta64(58639000000000,'ns'), numpy.timedelta64(59017000000000,'ns'), numpy.timedelta64(59599000000000,'ns'), numpy.timedelta64(60280000000000,'ns'), numpy.timedelta64(60355000000000,'ns'), numpy.timedelta64(60531000000000,'ns'), numpy.timedelta64(60576000000000,'ns'), numpy.timedelta64(60832000000000,'ns'), numpy.timedelta64(61359000000000,'ns'), numpy.timedelta64(62058000000000,'ns'), numpy.timedelta64(62449000000000,'ns'), numpy.timedelta64(63966000000000,'ns'), numpy.timedelta64(64311000000000,'ns'), numpy.timedelta64(66587000000000,'ns'), numpy.timedelta64(70782000000000,'ns'), numpy.timedelta64(71074000000000,'ns'), numpy.timedelta64(72729000000000,'ns'), numpy.timedelta64(73059000000000,'ns'), numpy.timedelta64(73163000000000,'ns'), numpy.timedelta64(74359000000000,'ns'), numpy.timedelta64(74451000000000,'ns'), numpy.timedelta64(74934000000000,'ns'), numpy.timedelta64(75001000000000,'ns'), numpy.timedelta64(75677000000000,'ns'), numpy.timedelta64(76596000000000,'ns'), numpy.timedelta64(76802000000000,'ns'), numpy.timedelta64(78056000000000,'ns'), numpy.timedelta64(78488000000000,'ns'), numpy.timedelta64(79740000000000,'ns'), numpy.timedelta64(79825000000000,'ns'), numpy.timedelta64(81132000000000,'ns'), numpy.timedelta64(81959000000000,'ns'), numpy.timedelta64(82075000000000,'ns'), numpy.timedelta64(82191000000000,'ns'), numpy.timedelta64(82266000000000,'ns'), numpy.timedelta64(82792000000000,'ns'), numpy.timedelta64(82879000000000,'ns'), numpy.timedelta64(83483000000000,'ns'), numpy.timedelta64(83723000000000,'ns'), numpy.timedelta64(84579000000000,'ns'), numpy.timedelta64(84586000000000,'ns'), numpy.timedelta64(85125000000000,'ns'), numpy.timedelta64(85776000000000,'ns'), numpy.timedelta64(85800000000000,'ns'), numpy.timedelta64(85868000000000,'ns'), numpy.timedelta64(86016000000000,'ns'), numpy.timedelta64(86251000000000,'ns'), numpy.timedelta64(86265000000000,'ns'), numpy.timedelta64(86295000000000,'ns'), numpy.timedelta64(86297000000000,'ns'), numpy.timedelta64(86324000000000,'ns'), numpy.timedelta64(86365000000000,'ns'), numpy.timedelta64(90711000000000,'ns'), numpy.timedelta64(100100000000000,'ns'), numpy.timedelta64(130659000000000,'ns'), numpy.timedelta64(159039000000000,'ns'), numpy.timedelta64(165817000000000,'ns'), numpy.timedelta64(183689000000000,'ns'), numpy.timedelta64(216454000000000,'ns'), numpy.timedelta64(230864000000000,'ns'), numpy.timedelta64(235668000000000,'ns'), numpy.timedelta64(276045000000000,'ns'), numpy.timedelta64(322944000000000,'ns'), numpy.timedelta64(380214000000000,'ns'), numpy.timedelta64(487835000000000,'ns'), numpy.timedelta64(584680000000000,'ns'), numpy.timedelta64(650593000000000,'ns'), numpy.timedelta64(841677000000000,'ns'), numpy.timedelta64(1187999000000000,'ns')]\n",
      "\n",
      "\n",
      "   df2_missing ( 111 ): [numpy.timedelta64(14238000000000,'ns'), numpy.timedelta64(19463000000000,'ns'), numpy.timedelta64(19510000000000,'ns'), numpy.timedelta64(26339000000000,'ns'), numpy.timedelta64(27637000000000,'ns'), numpy.timedelta64(27690000000000,'ns'), numpy.timedelta64(28267000000000,'ns'), numpy.timedelta64(28667000000000,'ns'), numpy.timedelta64(29128000000000,'ns'), numpy.timedelta64(29948000000000,'ns'), numpy.timedelta64(30738000000000,'ns'), numpy.timedelta64(30847000000000,'ns'), numpy.timedelta64(31391000000000,'ns'), numpy.timedelta64(31599000000000,'ns'), numpy.timedelta64(32599000000000,'ns'), numpy.timedelta64(32945000000000,'ns'), numpy.timedelta64(33020000000000,'ns'), numpy.timedelta64(34106000000000,'ns'), numpy.timedelta64(37087000000000,'ns'), numpy.timedelta64(37945000000000,'ns'), numpy.timedelta64(39461000000000,'ns'), numpy.timedelta64(41065000000000,'ns'), numpy.timedelta64(41844000000000,'ns'), numpy.timedelta64(42304000000000,'ns'), numpy.timedelta64(43367000000000,'ns'), numpy.timedelta64(43972000000000,'ns'), numpy.timedelta64(44305000000000,'ns'), numpy.timedelta64(44407000000000,'ns'), numpy.timedelta64(45077000000000,'ns'), numpy.timedelta64(47840000000000,'ns'), numpy.timedelta64(48020000000000,'ns'), numpy.timedelta64(48086000000000,'ns'), numpy.timedelta64(48090000000000,'ns'), numpy.timedelta64(50217000000000,'ns'), numpy.timedelta64(50468000000000,'ns'), numpy.timedelta64(51980000000000,'ns'), numpy.timedelta64(52894000000000,'ns'), numpy.timedelta64(53309000000000,'ns'), numpy.timedelta64(53481000000000,'ns'), numpy.timedelta64(53800000000000,'ns'), numpy.timedelta64(54709000000000,'ns'), numpy.timedelta64(55771000000000,'ns'), numpy.timedelta64(56572000000000,'ns'), numpy.timedelta64(57181000000000,'ns'), numpy.timedelta64(57324000000000,'ns'), numpy.timedelta64(57689000000000,'ns'), numpy.timedelta64(57983000000000,'ns'), numpy.timedelta64(58505000000000,'ns'), numpy.timedelta64(60281000000000,'ns'), numpy.timedelta64(60357000000000,'ns'), numpy.timedelta64(60577000000000,'ns'), numpy.timedelta64(60831000000000,'ns'), numpy.timedelta64(61334000000000,'ns'), numpy.timedelta64(62060000000000,'ns'), numpy.timedelta64(62447000000000,'ns'), numpy.timedelta64(63965000000000,'ns'), numpy.timedelta64(64312000000000,'ns'), numpy.timedelta64(65476000000000,'ns'), numpy.timedelta64(68487000000000,'ns'), numpy.timedelta64(69716000000000,'ns'), numpy.timedelta64(70454000000000,'ns'), numpy.timedelta64(70781000000000,'ns'), numpy.timedelta64(71075000000000,'ns'), numpy.timedelta64(71600000000000,'ns'), numpy.timedelta64(71697000000000,'ns'), numpy.timedelta64(72730000000000,'ns'), numpy.timedelta64(73060000000000,'ns'), numpy.timedelta64(74450000000000,'ns'), numpy.timedelta64(74935000000000,'ns'), numpy.timedelta64(75002000000000,'ns'), numpy.timedelta64(75678000000000,'ns'), numpy.timedelta64(75827000000000,'ns'), numpy.timedelta64(76033000000000,'ns'), numpy.timedelta64(76766000000000,'ns'), numpy.timedelta64(78057000000000,'ns'), numpy.timedelta64(78489000000000,'ns'), numpy.timedelta64(78599000000000,'ns'), numpy.timedelta64(79310000000000,'ns'), numpy.timedelta64(79741000000000,'ns'), numpy.timedelta64(79826000000000,'ns'), numpy.timedelta64(81133000000000,'ns'), numpy.timedelta64(81960000000000,'ns'), numpy.timedelta64(82076000000000,'ns'), numpy.timedelta64(82211000000000,'ns'), numpy.timedelta64(82268000000000,'ns'), numpy.timedelta64(83486000000000,'ns'), numpy.timedelta64(83724000000000,'ns'), numpy.timedelta64(84580000000000,'ns'), numpy.timedelta64(84587000000000,'ns'), numpy.timedelta64(85128000000000,'ns'), numpy.timedelta64(85780000000000,'ns'), numpy.timedelta64(85869000000000,'ns'), numpy.timedelta64(86029000000000,'ns'), numpy.timedelta64(86252000000000,'ns'), numpy.timedelta64(86266000000000,'ns'), numpy.timedelta64(86279000000000,'ns'), numpy.timedelta64(86296000000000,'ns'), numpy.timedelta64(86298000000000,'ns'), numpy.timedelta64(86301000000000,'ns'), numpy.timedelta64(86323000000000,'ns'), numpy.timedelta64(86330000000000,'ns'), numpy.timedelta64(90724000000000,'ns'), numpy.timedelta64(130661000000000,'ns'), numpy.timedelta64(165818000000000,'ns'), numpy.timedelta64(181650000000000,'ns'), numpy.timedelta64(183691000000000,'ns'), numpy.timedelta64(216456000000000,'ns'), numpy.timedelta64(230865000000000,'ns'), numpy.timedelta64(235669000000000,'ns'), numpy.timedelta64(322946000000000,'ns'), numpy.timedelta64(584699000000000,'ns')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_extra_missing_values_in_df2(['wtime'])  # 119 extra, 111 missing = 8 diff\n",
    "\n",
    "# # Extra:\n",
    "#     numpy.timedelta64(18939000000000,'ns'), \n",
    "#     numpy.timedelta64(20793000000000,'ns'), \n",
    "#     numpy.timedelta64(21613000000000,'ns')\n",
    "\n",
    "# # missing:\n",
    "#     numpy.timedelta64(14238000000000,'ns'), \n",
    "#     numpy.timedelta64(19463000000000,'ns'), \n",
    "#     numpy.timedelta64(19510000000000,'ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- If there are differences in any of submit/start/end times they will carry thru to wait and wtime\n",
    "- But the difference between extras and missings is only 8 diffs, so maybe can nail them down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5. Change log: In original fxs above, capture the rows that are dropped at each step. \n",
    "- Then can see if/which rows in df_1 exist in df_droplog of df_2 drops; i.e., were rows in df_1 **not** dropped that I think should have been.\n",
    "- Should they have been dropped? Or did I mistakenly drop them in df_2?\n",
    "\n",
    "**Next**:\n",
    "- df_droplog still not updating at every drop operation\n",
    "\n",
    "**FIX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6. Check for duplicate rows in df_1\n",
    "- Are there any duplicate rows in df_1? That might account for extra rows.\n",
    "- Check and drop as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_1 = drop_duplicate_rows(df_1, col_names=['job_number', 'task_number', 'submission_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No dupes in df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.7. Use set notation to compare dfs\n",
    "- Create `df_1_uniq` and `df_2_uniq` by removing all rows that exist in both\n",
    "- This will show what is in 1 that is not in 2 and vice versa\n",
    "- Maybe related to Step 11.4 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_1 = df_1.drop_duplicates(col_names=['job_number', 'task_number', 'submission_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.8. Subtract df2 set of rows from df1 set of rows\n",
    "And vice versa\n",
    "\n",
    "- To compare sets of rows, first convert each row to a hashable object, e.g. tuple\n",
    "\n",
    "~1 hr 45 min. to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468061 4468051\n"
     ]
    }
   ],
   "source": [
    "df_1_uniq = set([tuple(x) for x in df_1.values]) - set([tuple(x) for x in df_2.values])\n",
    "df_2_uniq = set([tuple(x) for x in df_2.values]) - set([tuple(x) for x in df_1.values])\n",
    "\n",
    "print(len(df_1_uniq), len(df_2_uniq))  # 4468061 4468051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "- Every row in each df is unique. Not too useful since group and owner (user) columns differ between the 2 df's (wk1 is de-identified)\n",
    "- How modify this code to eval equality on only 3 cols? Evaluating only on 'job_number', 'task_number', 'submission_time' would fix this produce a useful result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.9a. `df.merge`  \n",
    "### `how='outer'`, `indicator=True`  \n",
    "### `query`, `_merge`, `.drop`\n",
    "\n",
    "~1 min run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dfs(df1,df2):\n",
    "    \"\"\"This function takes 2 df's, drops all rows that they have in common,\n",
    "    and returns each df with only the rows that are unique to it.\"\"\"\n",
    "    \n",
    "    u = df1.merge(df2, how='outer', \n",
    "                  on=['job_number', 'task_number', 'submission_time'], \n",
    "                  indicator=True)\n",
    "    df_1_uniqC = u.query('_merge == \"left_only\"').drop('_merge', 1)\n",
    "    df_2_uniqC = u.query('_merge == \"right_only\"').drop('_merge', 1)\n",
    "    return df_1_uniqC, df_2_uniqC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1_uniqC, df_2_uniqC = merge_dfs(df_1, df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_1_uniqC), len(df_2_uniqC))  # 10 0 Woohoo!\n",
    "len(df_1_uniqC) - len(df_2_uniqC)        # 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.9b. df.merge and preserve indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the index also needs to be preserved, you can first reset it before \n",
    "# merging, then you can set it after.\n",
    "\n",
    "def merge_dfs_preserve_indexes(df1, df2):\n",
    "    \"\"\"This function takes 2 df's, drops all rows common to both df's,\n",
    "    and returns each df with only the rows that are unique to it and \n",
    "    with the original indexes intact.\"\"\"\n",
    "    \n",
    "    u, v = df1.reset_index(), df2.reset_index()\n",
    "    w = (u.merge(v, \n",
    "                 how='outer', \n",
    "                 on=['job_number', 'task_number', 'submission_time'], \n",
    "                 indicator=True)  # TypeError: unhashable type: 'list'\n",
    "         .fillna({'index_x': -1, 'index_y': -1}, downcast='infer'))\n",
    "    \n",
    "    print('len(w):', len(w), '\\n\\n', w.head(10))  # See sample output below\n",
    "\n",
    "    df_1_uniq = (w.query('_merge == \"left_only\"')\n",
    "            .set_index('index_x')\n",
    "            .drop(['_merge', 'index_y'], 1)\n",
    "            .rename_axis([None], axis=0))\n",
    "    df_2_uniq = (w.query('_merge == \"right_only\"')\n",
    "            .set_index('index_y')\n",
    "            .drop(['_merge', 'index_x'], 1)\n",
    "            .rename_axis([None], axis=0))\n",
    "\n",
    "    return df_1_uniq, df_2_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(w): 4468061 \n",
      "\n",
      "    index_x group_x owner_x  job_number     submission_time  \\\n",
      "0  0        g1      u1      3912841    2018-09-29 16:03:49   \n",
      "1  1        g2      u2      3902779    2018-09-27 21:38:06   \n",
      "2  2        g1      u1      3912841    2018-09-29 16:03:49   \n",
      "3  3        g3      u3      3907911    2018-09-28 16:32:52   \n",
      "4  4        g3      u3      3907911    2018-09-28 16:32:52   \n",
      "5  5        g3      u3      3907911    2018-09-28 16:32:52   \n",
      "6  6        g2      u2      3902779    2018-09-27 21:38:06   \n",
      "7  7        g3      u3      3907911    2018-09-28 16:32:52   \n",
      "8  8        g2      u2      3902779    2018-09-27 21:38:06   \n",
      "9  9        g2      u2      3902779    2018-09-27 21:38:06   \n",
      "\n",
      "         start_time_x          end_time_x  failed_x  exit_status_x  \\\n",
      "0 2018-10-01 07:53:27 2018-10-01 08:00:18  0         0               \n",
      "1 2018-10-01 07:24:38 2018-10-01 08:00:42  0         0               \n",
      "2 2018-10-01 07:58:42 2018-10-01 08:00:56  0         0               \n",
      "3 2018-10-01 07:35:44 2018-10-01 08:00:44  0         0               \n",
      "4 2018-10-01 07:15:46 2018-10-01 08:00:53  0         0               \n",
      "5 2018-10-01 07:42:19 2018-10-01 08:00:20  0         0               \n",
      "6 2018-10-01 07:21:14 2018-10-01 08:00:53  0         0               \n",
      "7 2018-10-01 07:35:43 2018-10-01 08:00:53  0         0               \n",
      "8 2018-10-01 07:17:55 2018-10-01 08:00:17  0         0               \n",
      "9 2018-10-01 07:24:38 2018-10-01 08:00:31  0         0               \n",
      "\n",
      "  granted_pe_x  slots_x  task_number     maxvmem_x  h_data_x  h_rt_x  highp_x  \\\n",
      "0  single       1        1338         4.040196e+09  4.0       24.0    0         \n",
      "1  single       1        55696        6.098657e+08  4.0       6.0     0         \n",
      "2  single       1        1368         3.326935e+09  4.0       24.0    0         \n",
      "3  shared       1        1241         1.396154e+09  2.5       1.5     0         \n",
      "4  shared       1        972          1.118601e+09  2.5       1.5     0         \n",
      "5  shared       1        1324         1.272377e+09  2.5       1.5     0         \n",
      "6  single       1        55638        6.098944e+08  4.0       6.0     0         \n",
      "7  shared       1        1235         1.119089e+09  2.5       1.5     0         \n",
      "8  single       1        55618        6.103450e+08  4.0       6.0     0         \n",
      "9  single       1        55697        6.098575e+08  4.0       6.0     0         \n",
      "\n",
      "   exclusive_x  h_vmem_x  gpu_x    pe_x  slot_x  campus_x     wait_time_x  \\\n",
      "0  0            4.0       0      single  1       1        1 days 15:49:38   \n",
      "1  0            4.0       0      single  1       0        3 days 09:46:32   \n",
      "2  0            4.0       0      single  1       1        1 days 15:54:53   \n",
      "3  0            2.5       0      shared  1       0        2 days 15:02:52   \n",
      "4  0            2.5       0      shared  1       0        2 days 14:42:54   \n",
      "5  0            2.5       0      shared  1       0        2 days 15:09:27   \n",
      "6  0            4.0       0      single  1       0        3 days 09:43:08   \n",
      "7  0            2.5       0      shared  1       0        2 days 15:02:51   \n",
      "8  0            4.0       0      single  1       0        3 days 09:39:49   \n",
      "9  0            4.0       0      single  1       0        3 days 09:46:32   \n",
      "\n",
      "   wtime_x  index_y   group_y   owner_y        start_time_y  \\\n",
      "0 00:06:51  0        sudip     stevendu 2018-10-01 07:53:27   \n",
      "1 00:36:04  1        yxing     yidazhan 2018-10-01 07:24:38   \n",
      "2 00:02:14  2        sudip     stevendu 2018-10-01 07:58:42   \n",
      "3 00:25:00  3        hduquant  shuang92 2018-10-01 07:35:44   \n",
      "4 00:45:07  4        hduquant  shuang92 2018-10-01 07:15:46   \n",
      "5 00:18:01  5        hduquant  shuang92 2018-10-01 07:42:19   \n",
      "6 00:39:39  6        yxing     yidazhan 2018-10-01 07:21:14   \n",
      "7 00:25:10  7        hduquant  shuang92 2018-10-01 07:35:43   \n",
      "8 00:42:22  8        yxing     yidazhan 2018-10-01 07:17:55   \n",
      "9 00:35:53  9        yxing     yidazhan 2018-10-01 07:24:38   \n",
      "\n",
      "           end_time_y  failed_y  exit_status_y granted_pe_y  slots_y  \\\n",
      "0 2018-10-01 08:00:18  0.0       0.0            single       1.0       \n",
      "1 2018-10-01 08:00:42  0.0       0.0            single       1.0       \n",
      "2 2018-10-01 08:00:56  0.0       0.0            single       1.0       \n",
      "3 2018-10-01 08:00:44  0.0       0.0            shared       1.0       \n",
      "4 2018-10-01 08:00:53  0.0       0.0            shared       1.0       \n",
      "5 2018-10-01 08:00:20  0.0       0.0            shared       1.0       \n",
      "6 2018-10-01 08:00:53  0.0       0.0            single       1.0       \n",
      "7 2018-10-01 08:00:53  0.0       0.0            shared       1.0       \n",
      "8 2018-10-01 08:00:17  0.0       0.0            single       1.0       \n",
      "9 2018-10-01 08:00:31  0.0       0.0            single       1.0       \n",
      "\n",
      "      maxvmem_y  h_data_y  h_rt_y  highp_y  exclusive_y  h_vmem_y  gpu_y  \\\n",
      "0  4.040196e+09  4.0       24.0    0.0      0.0          4.0       0.0     \n",
      "1  6.098657e+08  4.0       6.0     0.0      0.0          4.0       0.0     \n",
      "2  3.326935e+09  4.0       24.0    0.0      0.0          4.0       0.0     \n",
      "3  1.396154e+09  2.5       1.5     0.0      0.0          2.5       0.0     \n",
      "4  1.118601e+09  2.5       1.5     0.0      0.0          2.5       0.0     \n",
      "5  1.272377e+09  2.5       1.5     0.0      0.0          2.5       0.0     \n",
      "6  6.098944e+08  4.0       6.0     0.0      0.0          4.0       0.0     \n",
      "7  1.119089e+09  2.5       1.5     0.0      0.0          2.5       0.0     \n",
      "8  6.103450e+08  4.0       6.0     0.0      0.0          4.0       0.0     \n",
      "9  6.098575e+08  4.0       6.0     0.0      0.0          4.0       0.0     \n",
      "\n",
      "     pe_y  slot_y  campus_y     wait_time_y  wtime_y _merge  \n",
      "0  single  1.0     1.0      1 days 15:49:38 00:06:51  both   \n",
      "1  single  1.0     0.0      3 days 09:46:32 00:36:04  both   \n",
      "2  single  1.0     1.0      1 days 15:54:53 00:02:14  both   \n",
      "3  shared  1.0     0.0      2 days 15:02:52 00:25:00  both   \n",
      "4  shared  1.0     0.0      2 days 14:42:54 00:45:07  both   \n",
      "5  shared  1.0     0.0      2 days 15:09:27 00:18:01  both   \n",
      "6  single  1.0     0.0      3 days 09:43:08 00:39:39  both   \n",
      "7  shared  1.0     0.0      2 days 15:02:51 00:25:10  both   \n",
      "8  single  1.0     0.0      3 days 09:39:49 00:42:22  both   \n",
      "9  single  1.0     0.0      3 days 09:46:32 00:35:53  both   \n"
     ]
    }
   ],
   "source": [
    "# col_names = ['job_number', 'task_number', 'submission_time']\n",
    "\n",
    "df_1_uniqB, df_2_uniqB = merge_dfs_preserve_indexes(df_1,df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_1_uniqB): 10 \n",
      "\n",
      "         group_x owner_x  job_number     submission_time        start_time_x  \\\n",
      "366018   g130    u343    3937422    2018-10-03 23:45:59 2018-10-03 23:48:35   \n",
      "396059   g24     u112    3939666    2018-10-04 05:22:22 2018-10-04 05:24:38   \n",
      "422616   g130    u343    3937432    2018-10-03 23:47:54 2018-10-03 23:49:40   \n",
      "937191   g22     u30     3971239    2018-10-08 23:18:35 2018-10-08 23:20:17   \n",
      "937192   g22     u30     3971238    2018-10-08 23:18:08 2018-10-08 23:20:17   \n",
      "1892248  g94     u551    4008009    2018-10-15 21:58:26 2018-10-15 22:00:12   \n",
      "1928516  g34     u452    4010169    2018-10-16 03:45:40 2018-10-16 03:46:22   \n",
      "3576109  g69     u486    4058455    2018-10-22 04:16:48 2018-10-22 04:17:32   \n",
      "3652308  g194    u640    4065298    2018-10-23 20:08:47 2018-10-23 22:20:22   \n",
      "3658409  g7      u132    4066046    2018-10-24 00:03:56 2018-10-24 00:04:45   \n",
      "\n",
      "                 end_time_x  failed_x  exit_status_x granted_pe_x  slots_x  \\\n",
      "366018  2018-10-03 23:48:35  100       0              shared       8         \n",
      "396059  2018-10-04 05:24:38  100       0              shared       4         \n",
      "422616  2018-10-04 12:20:01  37        0              shared       8         \n",
      "937191  2018-10-08 23:20:18  15        127            NONE         1         \n",
      "937192  2018-10-08 23:20:18  15        127            NONE         1         \n",
      "1892248 2018-10-15 22:00:13  0         0              single       1         \n",
      "1928516 2018-10-16 03:50:34  0         0              single       1         \n",
      "3576109 2018-10-22 06:20:03  37        0              single       1         \n",
      "3652308 2018-10-23 22:20:24  0         0              single       1         \n",
      "3658409 2018-10-24 00:04:46  100       0              single       1         \n",
      "\n",
      "         task_number   maxvmem_x  h_data_x  h_rt_x  highp_x  exclusive_x  \\\n",
      "366018   0            0.0         0.000015  12.0    0        0             \n",
      "396059   0            19251200.0  0.000023  24.0    0        0             \n",
      "422616   0            0.0         0.000015  12.0    0        0             \n",
      "937191   0            0.0         0.000004  24.0    1        0             \n",
      "937192   0            0.0         0.000004  24.0    1        0             \n",
      "1892248  0            0.0        -1.000000  2.0     0        0             \n",
      "1928516  0            0.0         0.000011  12.0    0        0             \n",
      "3576109  0            0.0         0.000004  2.0     0        0             \n",
      "3652308  0            0.0        -1.000000  2.0     0        0             \n",
      "3658409  0            0.0         0.000023  2.0     0        0             \n",
      "\n",
      "         h_vmem_x  gpu_x    pe_x  slot_x  campus_x wait_time_x  wtime_x  \\\n",
      "366018   0.0       0      shared  8       0        00:02:36    00:00:00   \n",
      "396059   24.0      0      shared  4       0        00:02:16    00:00:00   \n",
      "422616   0.0       0      shared  8       0        00:01:46    12:30:21   \n",
      "937191   4.0       0              1       0        00:01:42    00:00:01   \n",
      "937192   4.0       0              1       0        00:02:09    00:00:01   \n",
      "1892248  0.0       0      single  1       0        00:01:46    00:00:01   \n",
      "1928516  0.0       0      single  1       0        00:00:42    00:04:12   \n",
      "3576109  0.0       0      single  1       0        00:00:44    02:02:31   \n",
      "3652308  0.0       0      single  1       0        02:11:35    00:00:02   \n",
      "3658409  0.0       0      single  1       0        00:00:49    00:00:01   \n",
      "\n",
      "        group_y owner_y start_time_y end_time_y  failed_y  exit_status_y  \\\n",
      "366018   NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "396059   NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "422616   NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "937191   NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "937192   NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "1892248  NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "1928516  NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "3576109  NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "3652308  NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "3658409  NaN     NaN    NaT          NaT        NaN       NaN              \n",
      "\n",
      "        granted_pe_y  slots_y  maxvmem_y  h_data_y  h_rt_y  highp_y  \\\n",
      "366018   NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "396059   NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "422616   NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "937191   NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "937192   NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "1892248  NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "1928516  NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "3576109  NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "3652308  NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "3658409  NaN         NaN      NaN        NaN       NaN     NaN        \n",
      "\n",
      "         exclusive_y  h_vmem_y  gpu_y pe_y  slot_y  campus_y wait_time_y  \\\n",
      "366018  NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "396059  NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "422616  NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "937191  NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "937192  NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "1892248 NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "1928516 NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "3576109 NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "3652308 NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "3658409 NaN          NaN       NaN     NaN NaN     NaN       NaT           \n",
      "\n",
      "        wtime_y  \n",
      "366018  NaT      \n",
      "396059  NaT      \n",
      "422616  NaT      \n",
      "937191  NaT      \n",
      "937192  NaT      \n",
      "1892248 NaT      \n",
      "1928516 NaT      \n",
      "3576109 NaT      \n",
      "3652308 NaT      \n",
      "3658409 NaT      \n",
      "\n",
      "\n",
      "\n",
      "len(df_2_uniqB): 0 \n",
      "\n",
      " Empty DataFrame\n",
      "Columns: [group_x, owner_x, job_number, submission_time, start_time_x, end_time_x, failed_x, exit_status_x, granted_pe_x, slots_x, task_number, maxvmem_x, h_data_x, h_rt_x, highp_x, exclusive_x, h_vmem_x, gpu_x, pe_x, slot_x, campus_x, wait_time_x, wtime_x, group_y, owner_y, start_time_y, end_time_y, failed_y, exit_status_y, granted_pe_y, slots_y, maxvmem_y, h_data_y, h_rt_y, highp_y, exclusive_y, h_vmem_y, gpu_y, pe_y, slot_y, campus_y, wait_time_y, wtime_y]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print('len(df_1_uniqB):', len(df_1_uniqB), '\\n\\n', df_1_uniqB)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('len(df_2_uniqB):', len(df_2_uniqB), '\\n\\n', df_2_uniqB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I dropped these 10 rows** b/c the h_data strings were invalid. They might have made sense if they represented GB, but the G/g suffix was missing indicating that they should be considered KB. The result (probably incorrect) of retaining them in the week 1 df and dividing them by 1024\\*\\*2 to derive the value in GB is shown below:\n",
    "\n",
    "```\n",
    " h_data_x\n",
    " 0.000015\n",
    " 0.000023\n",
    " 0.000015\n",
    " 0.000004\n",
    " 0.000004\n",
    "-1.000000\n",
    " 0.000011\n",
    " 0.000004\n",
    "-1.000000\n",
    " 0.000023\n",
    "```\n",
    "\n",
    "This is the only difference between my cleaned week 2 df and the week 1 df, if \"duplicate\" rows are evaluated only on the group, user, and submit columns. \n",
    "\n",
    "Note, however, that there are differenes in other columns on a few dozen or more rows, as highlighted above. Some of these differences may result from rounding differences. The cause of the rest has not yet been determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "- How format like columns (e.g., slot_x, slot_y) side by side?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Resave as HDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2.to_hdf('accounting-2018-10_wk2_FINAL.h5', key='df', mode='w') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copy HDF and Assign2.ipynb to module3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "- Is HDF5 a binary file format?\n",
    "- Do h5 files save any data besides the data?\n",
    " - Metadata about history of changes, user, etc. that would make their file size suspect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare df differences side by side  \n",
    "https://stackoverflow.com/questions/17095101/outputting-difference-in-two-pandas-dataframes-side-by-side-highlighting-the-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
